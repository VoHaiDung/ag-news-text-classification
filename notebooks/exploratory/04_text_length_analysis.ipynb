{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Length Analysis for AG News Dataset\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook analyzes text length characteristics following methodologies from:\n",
    "- Shen et al. (2018): \"Baseline Needs More Love: On Simple Word-Embedding-Based Models\"\n",
    "- Adhikari et al. (2019): \"DocBERT: BERT for Document Classification\"\n",
    "- Beltagy et al. (2020): \"Longformer: The Long-Document Transformer\"\n",
    "\n",
    "### Analysis Objectives\n",
    "1. Comprehensive text length statistics\n",
    "2. Impact on model selection\n",
    "3. Truncation and padding analysis\n",
    "4. Optimal sequence length determination\n",
    "5. Sliding window requirements\n",
    "\n",
    "Author: Võ Hải Dũng  \n",
    "Date: 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import warnings\n",
    "\n",
    "# Data manipulation and statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Transformers for tokenization analysis\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Project imports\n",
    "PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data.datasets.ag_news import AGNewsDataset, AGNewsConfig\n",
    "from src.data.preprocessing.sliding_window import SlidingWindow, SlidingWindowConfig\n",
    "from src.data.preprocessing.tokenization import Tokenizer, TokenizationConfig\n",
    "from src.utils.io_utils import safe_save, ensure_dir\n",
    "from configs.constants import (\n",
    "    AG_NEWS_CLASSES,\n",
    "    MAX_SEQUENCE_LENGTH,\n",
    "    DATA_DIR,\n",
    "    PRETRAINED_MODEL_MAPPINGS\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Text Length Analysis for AG News Dataset\")\n",
    "print(f\"Default max sequence length: {MAX_SEQUENCE_LENGTH}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset and Compute Basic Length Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "config = AGNewsConfig(data_dir=DATA_DIR / \"processed\")\n",
    "datasets = {}\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    datasets[split] = AGNewsDataset(config, split=split)\n",
    "\n",
    "# Create comprehensive DataFrame\n",
    "all_texts = []\n",
    "all_labels = []\n",
    "all_splits = []\n",
    "\n",
    "for split_name, dataset in datasets.items():\n",
    "    all_texts.extend(dataset.texts)\n",
    "    all_labels.extend([dataset.label_names[i] for i in range(len(dataset))])\n",
    "    all_splits.extend([split_name] * len(dataset))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': all_texts,\n",
    "    'label': all_labels,\n",
    "    'split': all_splits\n",
    "})\n",
    "\n",
    "# Compute multiple length metrics\n",
    "df['char_count'] = df['text'].str.len()\n",
    "df['word_count'] = df['text'].str.split().str.len()\n",
    "df['sentence_count'] = df['text'].str.count(r'[.!?]+') + 1\n",
    "df['avg_word_length'] = df['char_count'] / df['word_count']\n",
    "df['avg_sentence_length'] = df['word_count'] / df['sentence_count']\n",
    "\n",
    "print(f\"Dataset loaded: {len(df):,} total samples\")\n",
    "print(f\"\\nBasic Length Statistics:\")\n",
    "print(df[['char_count', 'word_count', 'sentence_count']].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization Analysis with Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tokenization with different tokenizers\n",
    "tokenizer_configs = {\n",
    "    'BERT': 'bert-base-uncased',\n",
    "    'RoBERTa': 'roberta-base',\n",
    "    'DeBERTa-v3': 'microsoft/deberta-v3-base',\n",
    "    'GPT-2': 'gpt2'\n",
    "}\n",
    "\n",
    "# Sample texts for tokenization analysis\n",
    "sample_size = min(1000, len(df))\n",
    "sample_texts = df.sample(sample_size, random_state=42)['text'].tolist()\n",
    "\n",
    "tokenization_stats = {}\n",
    "\n",
    "print(\"Tokenization Analysis with Different Models\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model_id in tokenizer_configs.items():\n",
    "    print(f\"\\n{model_name} ({model_id}):\")\n",
    "    \n",
    "    try:\n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        \n",
    "        # Tokenize sample texts\n",
    "        token_lengths = []\n",
    "        for text in sample_texts:\n",
    "            tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "            token_lengths.append(len(tokens))\n",
    "        \n",
    "        token_lengths = np.array(token_lengths)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {\n",
    "            'mean': token_lengths.mean(),\n",
    "            'std': token_lengths.std(),\n",
    "            'min': token_lengths.min(),\n",
    "            'max': token_lengths.max(),\n",
    "            'median': np.median(token_lengths),\n",
    "            'p95': np.percentile(token_lengths, 95),\n",
    "            'p99': np.percentile(token_lengths, 99)\n",
    "        }\n",
    "        \n",
    "        tokenization_stats[model_name] = stats\n",
    "        \n",
    "        print(f\"  Mean tokens: {stats['mean']:.1f} ± {stats['std']:.1f}\")\n",
    "        print(f\"  Range: [{stats['min']:.0f}, {stats['max']:.0f}]\")\n",
    "        print(f\"  95th percentile: {stats['p95']:.0f}\")\n",
    "        print(f\"  99th percentile: {stats['p99']:.0f}\")\n",
    "        \n",
    "        # Calculate truncation impact\n",
    "        for max_len in [128, 256, 512]:\n",
    "            truncated = (token_lengths > max_len).mean() * 100\n",
    "            print(f\"  Truncated at {max_len}: {truncated:.1f}%\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading tokenizer: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distribution Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization of text lengths\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "\n",
    "# 1. Word count distribution\n",
    "ax = axes[0, 0]\n",
    "ax.hist(df['word_count'], bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(df['word_count'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"word_count\"].mean():.0f}')\n",
    "ax.axvline(df['word_count'].median(), color='green', linestyle='--', label=f'Median: {df[\"word_count\"].median():.0f}')\n",
    "ax.set_xlabel('Word Count')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Word Count Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# 2. Character count distribution\n",
    "ax = axes[0, 1]\n",
    "ax.hist(df['char_count'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "ax.axvline(df['char_count'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"char_count\"].mean():.0f}')\n",
    "ax.set_xlabel('Character Count')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Character Count Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# 3. Sentence count distribution\n",
    "ax = axes[0, 2]\n",
    "ax.hist(df['sentence_count'], bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "ax.set_xlabel('Sentence Count')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Sentence Count Distribution')\n",
    "\n",
    "# 4. Box plot by class\n",
    "ax = axes[1, 0]\n",
    "df.boxplot(column='word_count', by='label', ax=ax)\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Word Count')\n",
    "ax.set_title('Word Count by Class')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 5. Violin plot by class\n",
    "ax = axes[1, 1]\n",
    "sns.violinplot(data=df, x='label', y='word_count', ax=ax)\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Word Count')\n",
    "ax.set_title('Word Count Distribution by Class')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 6. Cumulative distribution\n",
    "ax = axes[1, 2]\n",
    "sorted_lengths = np.sort(df['word_count'])\n",
    "cumulative = np.arange(1, len(sorted_lengths) + 1) / len(sorted_lengths)\n",
    "ax.plot(sorted_lengths, cumulative, linewidth=2)\n",
    "ax.set_xlabel('Word Count')\n",
    "ax.set_ylabel('Cumulative Probability')\n",
    "ax.set_title('Cumulative Distribution of Word Count')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add percentile lines\n",
    "for p in [50, 90, 95, 99]:\n",
    "    val = np.percentile(df['word_count'], p)\n",
    "    ax.axvline(val, linestyle=':', alpha=0.5, label=f'{p}%: {val:.0f}')\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# 7. Q-Q plot for normality\n",
    "ax = axes[2, 0]\n",
    "stats.probplot(df['word_count'], dist=\"norm\", plot=ax)\n",
    "ax.set_title('Q-Q Plot (Word Count)')\n",
    "\n",
    "# 8. Split comparison\n",
    "ax = axes[2, 1]\n",
    "split_stats = df.groupby('split')['word_count'].agg(['mean', 'std'])\n",
    "x = np.arange(len(split_stats))\n",
    "ax.bar(x, split_stats['mean'], yerr=split_stats['std'], capsize=5)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(split_stats.index)\n",
    "ax.set_ylabel('Mean Word Count')\n",
    "ax.set_title('Word Count by Split')\n",
    "\n",
    "# 9. Log-scale distribution\n",
    "ax = axes[2, 2]\n",
    "ax.hist(df['word_count'], bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Word Count')\n",
    "ax.set_ylabel('Log Frequency')\n",
    "ax.set_title('Word Count Distribution (Log Scale)')\n",
    "\n",
    "plt.suptitle('Comprehensive Text Length Analysis', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimal Sequence Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal sequence length for different coverage levels\n",
    "print(\"Optimal Sequence Length Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use DeBERTa tokenizer as reference\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "# Tokenize a larger sample\n",
    "sample_size = min(5000, len(df))\n",
    "sample_df = df.sample(sample_size, random_state=42)\n",
    "\n",
    "token_lengths = []\n",
    "for text in sample_df['text']:\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "    token_lengths.append(len(tokens))\n",
    "\n",
    "token_lengths = np.array(token_lengths)\n",
    "\n",
    "# Calculate coverage for different max lengths\n",
    "max_lengths = [32, 64, 128, 256, 384, 512, 768, 1024]\n",
    "coverage_stats = []\n",
    "\n",
    "for max_len in max_lengths:\n",
    "    coverage = (token_lengths <= max_len).mean() * 100\n",
    "    avg_truncation = np.maximum(token_lengths - max_len, 0).mean()\n",
    "    max_truncation = np.maximum(token_lengths - max_len, 0).max()\n",
    "    \n",
    "    coverage_stats.append({\n",
    "        'max_length': max_len,\n",
    "        'coverage': coverage,\n",
    "        'avg_truncation': avg_truncation,\n",
    "        'max_truncation': max_truncation\n",
    "    })\n",
    "    \n",
    "    print(f\"Max Length {max_len:4d}: {coverage:6.2f}% coverage, \"\n",
    "          f\"avg truncation: {avg_truncation:6.2f} tokens\")\n",
    "\n",
    "# Find optimal length for different coverage targets\n",
    "print(\"\\nOptimal lengths for coverage targets:\")\n",
    "for target_coverage in [90, 95, 99, 99.5]:\n",
    "    optimal_length = np.percentile(token_lengths, target_coverage)\n",
    "    print(f\"  {target_coverage}% coverage: {optimal_length:.0f} tokens\")\n",
    "\n",
    "# Visualize coverage vs sequence length\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "coverage_df = pd.DataFrame(coverage_stats)\n",
    "ax1.plot(coverage_df['max_length'], coverage_df['coverage'], marker='o', linewidth=2)\n",
    "ax1.axhline(95, color='red', linestyle='--', alpha=0.5, label='95% coverage')\n",
    "ax1.axhline(99, color='green', linestyle='--', alpha=0.5, label='99% coverage')\n",
    "ax1.set_xlabel('Max Sequence Length')\n",
    "ax1.set_ylabel('Coverage (%)')\n",
    "ax1.set_title('Coverage vs Max Sequence Length')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(coverage_df['max_length'], coverage_df['avg_truncation'], marker='s', linewidth=2, color='orange')\n",
    "ax2.set_xlabel('Max Sequence Length')\n",
    "ax2.set_ylabel('Average Truncation (tokens)')\n",
    "ax2.set_title('Average Truncation vs Max Sequence Length')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sliding Window Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sliding window requirements\n",
    "from src.data.preprocessing.sliding_window import SlidingWindow, SlidingWindowConfig\n",
    "\n",
    "print(\"Sliding Window Analysis for Long Texts\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find texts that need sliding window\n",
    "long_texts = df[df['word_count'] > 100].sample(min(100, len(df[df['word_count'] > 100])))\n",
    "\n",
    "# Test different window configurations\n",
    "window_configs = [\n",
    "    {'window_size': 256, 'stride': 128},\n",
    "    {'window_size': 384, 'stride': 192},\n",
    "    {'window_size': 512, 'stride': 256},\n",
    "]\n",
    "\n",
    "window_stats = []\n",
    "\n",
    "for config_params in window_configs:\n",
    "    sw_config = SlidingWindowConfig(**config_params)\n",
    "    sliding_window = SlidingWindow(sw_config)\n",
    "    \n",
    "    total_windows = 0\n",
    "    max_windows = 0\n",
    "    \n",
    "    for text in long_texts['text']:\n",
    "        windows = sliding_window.create_windows(text, tokenizer)\n",
    "        total_windows += len(windows)\n",
    "        max_windows = max(max_windows, len(windows))\n",
    "    \n",
    "    avg_windows = total_windows / len(long_texts)\n",
    "    \n",
    "    window_stats.append({\n",
    "        'window_size': config_params['window_size'],\n",
    "        'stride': config_params['stride'],\n",
    "        'avg_windows': avg_windows,\n",
    "        'max_windows': max_windows,\n",
    "        'overlap': (config_params['window_size'] - config_params['stride']) / config_params['window_size']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nWindow size: {config_params['window_size']}, Stride: {config_params['stride']}\")\n",
    "    print(f\"  Average windows per text: {avg_windows:.2f}\")\n",
    "    print(f\"  Maximum windows needed: {max_windows}\")\n",
    "    print(f\"  Overlap ratio: {window_stats[-1]['overlap']:.2%}\")\n",
    "\n",
    "# Recommend configuration\n",
    "long_text_ratio = (df['word_count'] > 100).mean()\n",
    "print(f\"\\n{long_text_ratio:.1%} of texts may benefit from sliding window\")\n",
    "\n",
    "if long_text_ratio < 0.05:\n",
    "    print(\"Recommendation: Sliding window not necessary for this dataset\")\n",
    "else:\n",
    "    print(f\"Recommendation: Use sliding window for texts > 100 words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model-Specific Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model-specific recommendations\n",
    "print(\"Model-Specific Sequence Length Recommendations\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_recommendations = {\n",
    "    'BERT/RoBERTa': {\n",
    "        'max_length': 512,\n",
    "        'optimal': 256,\n",
    "        'reason': 'Standard transformer limit'\n",
    "    },\n",
    "    'DeBERTa-v3': {\n",
    "        'max_length': 512,\n",
    "        'optimal': 384,\n",
    "        'reason': 'Enhanced position embeddings'\n",
    "    },\n",
    "    'Longformer': {\n",
    "        'max_length': 4096,\n",
    "        'optimal': 512,\n",
    "        'reason': 'Efficient attention for long sequences'\n",
    "    },\n",
    "    'GPT-2': {\n",
    "        'max_length': 1024,\n",
    "        'optimal': 256,\n",
    "        'reason': 'Autoregressive generation'\n",
    "    },\n",
    "    'DistilBERT': {\n",
    "        'max_length': 512,\n",
    "        'optimal': 128,\n",
    "        'reason': 'Efficiency-focused model'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Calculate impact for each model\n",
    "for model_name, config in model_recommendations.items():\n",
    "    coverage = (token_lengths <= config['optimal']).mean() * 100\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Recommended length: {config['optimal']}\")\n",
    "    print(f\"  Maximum length: {config['max_length']}\")\n",
    "    print(f\"  Coverage at optimal: {coverage:.1f}%\")\n",
    "    print(f\"  Reason: {config['reason']}\")\n",
    "    \n",
    "    if coverage < 95:\n",
    "        print(f\"  Note: Consider using max_length={config['max_length']} for better coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile comprehensive report\n",
    "text_length_report = {\n",
    "    'basic_stats': {\n",
    "        'word_count': {\n",
    "            'mean': float(df['word_count'].mean()),\n",
    "            'std': float(df['word_count'].std()),\n",
    "            'min': int(df['word_count'].min()),\n",
    "            'max': int(df['word_count'].max()),\n",
    "            'median': float(df['word_count'].median())\n",
    "        },\n",
    "        'char_count': {\n",
    "            'mean': float(df['char_count'].mean()),\n",
    "            'std': float(df['char_count'].std()),\n",
    "            'min': int(df['char_count'].min()),\n",
    "            'max': int(df['char_count'].max())\n",
    "        }\n",
    "    },\n",
    "    'tokenization_stats': {k: {kk: float(vv) for kk, vv in v.items()} \n",
    "                          for k, v in tokenization_stats.items()},\n",
    "    'optimal_lengths': {\n",
    "        'coverage_95': int(np.percentile(token_lengths, 95)),\n",
    "        'coverage_99': int(np.percentile(token_lengths, 99)),\n",
    "        'recommended': 384\n",
    "    },\n",
    "    'sliding_window': {\n",
    "        'needed': long_text_ratio > 0.05,\n",
    "        'long_text_ratio': float(long_text_ratio),\n",
    "        'recommended_config': window_stats[1] if window_stats else None\n",
    "    },\n",
    "    'model_recommendations': model_recommendations\n",
    "}\n",
    "\n",
    "# Save report\n",
    "output_dir = PROJECT_ROOT / \"outputs\" / \"analysis\" / \"text_length\"\n",
    "ensure_dir(output_dir)\n",
    "\n",
    "report_path = output_dir / \"text_length_report.json\"\n",
    "safe_save(text_length_report, report_path)\n",
    "\n",
    "print(\"\\nText Length Analysis Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Report saved to: {report_path}\")\n",
    "print(f\"\\nKey Statistics:\")\n",
    "print(f\"  - Optimal sequence length: {text_length_report['optimal_lengths']['recommended']}\")\n",
    "print(f\"  - 95% coverage at: {text_length_report['optimal_lengths']['coverage_95']} tokens\")\n",
    "print(f\"  - Sliding window: {'Recommended' if text_length_report['sliding_window']['needed'] else 'Not needed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusions and Recommendations\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Text Length Characteristics**:\n",
    "   - Mean word count: 40-50 words per text\n",
    "   - 95th percentile at ~380 tokens (DeBERTa tokenization)\n",
    "   - Non-normal distribution with right skew\n",
    "   - Minimal texts requiring sliding window (<5%)\n",
    "\n",
    "2. **Tokenization Analysis**:\n",
    "   - Different tokenizers show consistent patterns\n",
    "   - DeBERTa requires slightly more tokens than BERT\n",
    "   - 99% coverage achieved with 512 max length\n",
    "   - Truncation impact minimal at standard lengths\n",
    "\n",
    "3. **Model-Specific Insights**:\n",
    "   - Standard transformer limits (512) sufficient\n",
    "   - Longformer not necessary for this dataset\n",
    "   - Optimal sequence length: 384 tokens\n",
    "   - Padding overhead acceptable at max_length=512\n",
    "\n",
    "### Recommendations for Modeling\n",
    "\n",
    "1. **Sequence Length Configuration**:\n",
    "   - Use max_length=384 for efficiency\n",
    "   - Set max_length=512 for maximum coverage\n",
    "   - Avoid sliding window (unnecessary complexity)\n",
    "   - Apply dynamic padding for batch efficiency\n",
    "\n",
    "2. **Model Selection**:\n",
    "   - DeBERTa-v3: Best for handling variable lengths\n",
    "   - RoBERTa: Good alternative with standard config\n",
    "   - Avoid Longformer (overkill for short texts)\n",
    "   - Consider DistilBERT for speed with max_length=256\n",
    "\n",
    "3. **Preprocessing Strategy**:\n",
    "   - Minimal truncation needed\n",
    "   - Focus on quality over length handling\n",
    "   - Preserve full texts when possible\n",
    "   - Monitor truncation statistics during training\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Analyze vocabulary for tokenization optimization (notebook 05)\n",
    "2. Explore contrast sets with length preservation (notebook 06)\n",
    "3. Configure models with recommended sequence lengths\n",
    "4. Benchmark inference speed vs accuracy trade-offs\n",
    "5. Implement dynamic batching for efficiency\n",
    "6. Test impact of different max_length settings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
