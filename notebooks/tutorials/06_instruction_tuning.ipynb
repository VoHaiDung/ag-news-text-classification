{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction Tuning for AG News Classification\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates instruction tuning techniques following methodologies from:\n",
    "- Wei et al. (2022): \"Finetuned Language Models Are Zero-Shot Learners\"\n",
    "- Chung et al. (2022): \"Scaling Instruction-Finetuned Language Models\"\n",
    "- Wang et al. (2022): \"Self-Instruct: Aligning Language Models with Self-Generated Instructions\"\n",
    "\n",
    "### Tutorial Objectives\n",
    "1. Create instruction-following datasets\n",
    "2. Design effective instruction formats\n",
    "3. Fine-tune models with instructions\n",
    "4. Implement multi-task instruction learning\n",
    "5. Evaluate instruction-following capabilities\n",
    "6. Deploy instruction-tuned models\n",
    "\n",
    "Author: Võ Hải Dũng  \n",
    "Email: vohaidung.work@gmail.com  \n",
    "Date: 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any, Union\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "\n",
    "# Data and ML imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    T5ForConditionalGeneration,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Project imports\n",
    "PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data.datasets.ag_news import AGNewsDataset, AGNewsConfig\n",
    "from src.data.datasets.prompted_dataset import PromptedDataset\n",
    "from src.models.prompt_based.instruction_model import InstructionTunedModel\n",
    "from src.training.trainers.instruction_trainer import InstructionTrainer\n",
    "from src.training.strategies.distillation.gpt4_distill import GPT4DistillationStrategy\n",
    "from src.utils.reproducibility import set_seed\n",
    "from src.utils.logging_config import setup_logging\n",
    "from configs.config_loader import ConfigLoader\n",
    "from configs.constants import (\n",
    "    AG_NEWS_CLASSES,\n",
    "    AG_NEWS_NUM_CLASSES,\n",
    "    DATA_DIR,\n",
    "    MODEL_DIR,\n",
    "    OUTPUT_DIR\n",
    ")\n",
    "\n",
    "# Setup\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "set_seed(42)\n",
    "logger = setup_logging('instruction_tuning_tutorial')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load instruction tuning configuration\n",
    "config_loader = ConfigLoader()\n",
    "\n",
    "# Load instruction tuning config\n",
    "instruction_config = config_loader.load_config('training/advanced/instruction_tuning.yaml')\n",
    "\n",
    "# Tutorial configuration\n",
    "tutorial_config = {\n",
    "    'max_samples': 1000,\n",
    "    'batch_size': 4,\n",
    "    'num_epochs': 3,\n",
    "    'learning_rate': 5e-5,\n",
    "    'max_source_length': 512,\n",
    "    'max_target_length': 64,\n",
    "    'model_name': 't5-base',  # Using T5 for instruction tuning\n",
    "    'instruction_templates': 10,\n",
    "    'task_diversity': 5,\n",
    "    'use_explanations': True\n",
    "}\n",
    "\n",
    "print(\"Instruction Tuning Configuration:\")\n",
    "print(\"=\"*50)\n",
    "for key, value in tutorial_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AG News dataset\n",
    "data_config = AGNewsConfig(\n",
    "    data_dir=DATA_DIR / \"processed\",\n",
    "    max_samples=tutorial_config['max_samples'],\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset = AGNewsDataset(data_config, split=\"train\")\n",
    "val_dataset = AGNewsDataset(data_config, split=\"validation\")\n",
    "\n",
    "print(f\"\\nDataset loaded:\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Sample data\n",
    "sample_idx = 0\n",
    "sample_text = train_dataset.texts[sample_idx]\n",
    "sample_label = train_dataset.labels[sample_idx]\n",
    "\n",
    "print(f\"\\nSample data:\")\n",
    "print(f\"  Label: {sample_label} ({AG_NEWS_CLASSES[sample_label]})\")\n",
    "print(f\"  Text: {sample_text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Instruction Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class InstructionExample:\n",
    "    \"\"\"\n",
    "    Data structure for instruction-tuning examples.\n",
    "    \n",
    "    Following instruction format from:\n",
    "        Longpre et al. (2023): \"The Flan Collection: Designing Data and Methods for Effective Instruction Tuning\"\n",
    "    \"\"\"\n",
    "    instruction: str\n",
    "    input_text: str\n",
    "    output: str\n",
    "    explanation: Optional[str] = None\n",
    "    task_type: str = \"classification\"\n",
    "\n",
    "\n",
    "class InstructionDatasetCreator:\n",
    "    \"\"\"\n",
    "    Create diverse instruction-tuning datasets.\n",
    "    \n",
    "    Following dataset creation strategies from:\n",
    "        Wang et al. (2022): \"Super-NaturalInstructions: Generalization via Declarative Instructions\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_dataset: AGNewsDataset):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.instruction_templates = self._create_instruction_templates()\n",
    "        self.task_variations = self._create_task_variations()\n",
    "    \n",
    "    def _create_instruction_templates(self) -> List[str]:\n",
    "        \"\"\"Create diverse instruction templates.\"\"\"\n",
    "        return [\n",
    "            \"Classify the following news article into one of four categories: {categories}.\",\n",
    "            \"Determine which category this news article belongs to. Options: {categories}.\",\n",
    "            \"Read the article and identify its news category from: {categories}.\",\n",
    "            \"What type of news is this? Choose from: {categories}.\",\n",
    "            \"Categorize this news article. Available categories are: {categories}.\",\n",
    "            \"Given a news article, classify it as {categories}.\",\n",
    "            \"Identify the topic of this news article: {categories}.\",\n",
    "            \"Label this news article with the appropriate category: {categories}.\",\n",
    "            \"Assign this article to one of these sections: {categories}.\",\n",
    "            \"Based on the content, this article should be classified as: {categories}.\"\n",
    "        ]\n",
    "    \n",
    "    def _create_task_variations(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Create task variations for multi-task learning.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                'name': 'standard_classification',\n",
    "                'format': 'category_only',\n",
    "                'requires_explanation': False\n",
    "            },\n",
    "            {\n",
    "                'name': 'explained_classification',\n",
    "                'format': 'category_with_reason',\n",
    "                'requires_explanation': True\n",
    "            },\n",
    "            {\n",
    "                'name': 'binary_verification',\n",
    "                'format': 'yes_no',\n",
    "                'requires_explanation': False\n",
    "            },\n",
    "            {\n",
    "                'name': 'topic_extraction',\n",
    "                'format': 'keywords',\n",
    "                'requires_explanation': False\n",
    "            },\n",
    "            {\n",
    "                'name': 'confidence_classification',\n",
    "                'format': 'category_with_confidence',\n",
    "                'requires_explanation': False\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def create_instruction_example(\n",
    "        self,\n",
    "        idx: int,\n",
    "        task_variation: Optional[str] = None\n",
    "    ) -> InstructionExample:\n",
    "        \"\"\"Create a single instruction example.\"\"\"\n",
    "        text = self.base_dataset.texts[idx]\n",
    "        label = self.base_dataset.labels[idx]\n",
    "        category = AG_NEWS_CLASSES[label]\n",
    "        \n",
    "        # Select random instruction template\n",
    "        instruction_template = random.choice(self.instruction_templates)\n",
    "        instruction = instruction_template.format(\n",
    "            categories=\"World, Sports, Business, Science/Technology\"\n",
    "        )\n",
    "        \n",
    "        # Select task variation\n",
    "        if task_variation is None:\n",
    "            task = random.choice(self.task_variations)\n",
    "        else:\n",
    "            task = next(t for t in self.task_variations if t['name'] == task_variation)\n",
    "        \n",
    "        # Format output based on task\n",
    "        if task['format'] == 'category_only':\n",
    "            output = category\n",
    "            explanation = None\n",
    "        elif task['format'] == 'category_with_reason':\n",
    "            output = category\n",
    "            explanation = self._generate_explanation(text, category)\n",
    "        elif task['format'] == 'yes_no':\n",
    "            target_category = random.choice(AG_NEWS_CLASSES)\n",
    "            instruction = f\"Is this a {target_category} article? Answer yes or no.\"\n",
    "            output = \"yes\" if category == target_category else \"no\"\n",
    "            explanation = None\n",
    "        elif task['format'] == 'keywords':\n",
    "            instruction = \"Extract the main topic keywords from this news article.\"\n",
    "            output = self._extract_keywords(text, category)\n",
    "            explanation = None\n",
    "        else:  # category_with_confidence\n",
    "            output = f\"{category} (confidence: high)\"\n",
    "            explanation = None\n",
    "        \n",
    "        return InstructionExample(\n",
    "            instruction=instruction,\n",
    "            input_text=text[:500],  # Truncate for efficiency\n",
    "            output=output,\n",
    "            explanation=explanation,\n",
    "            task_type=task['name']\n",
    "        )\n",
    "    \n",
    "    def _generate_explanation(self, text: str, category: str) -> str:\n",
    "        \"\"\"Generate explanation for classification.\"\"\"\n",
    "        explanations = {\n",
    "            'World': \"This article discusses international events, politics, or global affairs.\",\n",
    "            'Sports': \"This article covers athletic competitions, sports teams, or athletes.\",\n",
    "            'Business': \"This article focuses on companies, markets, economy, or finance.\",\n",
    "            'Science/Technology': \"This article reports on scientific research, technology, or innovations.\"\n",
    "        }\n",
    "        return explanations.get(category, \"Based on the content and context.\")\n",
    "    \n",
    "    def _extract_keywords(self, text: str, category: str) -> str:\n",
    "        \"\"\"Extract keywords based on category.\"\"\"\n",
    "        # Simplified keyword extraction\n",
    "        category_keywords = {\n",
    "            'World': \"politics, international, government, country\",\n",
    "            'Sports': \"game, team, player, championship\",\n",
    "            'Business': \"company, market, revenue, investment\",\n",
    "            'Science/Technology': \"research, technology, innovation, discovery\"\n",
    "        }\n",
    "        return category_keywords.get(category, \"news, article, report\")\n",
    "\n",
    "\n",
    "# Create instruction dataset\n",
    "instruction_creator = InstructionDatasetCreator(train_dataset)\n",
    "\n",
    "# Generate examples\n",
    "print(\"Creating Instruction Examples:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "instruction_examples = []\n",
    "for i in range(5):  # Create 5 examples for demonstration\n",
    "    example = instruction_creator.create_instruction_example(i)\n",
    "    instruction_examples.append(example)\n",
    "    \n",
    "    if i == 0:  # Display first example\n",
    "        print(f\"\\nExample 1:\")\n",
    "        print(f\"  Instruction: {example.instruction}\")\n",
    "        print(f\"  Input: {example.input_text[:100]}...\")\n",
    "        print(f\"  Output: {example.output}\")\n",
    "        if example.explanation:\n",
    "            print(f\"  Explanation: {example.explanation}\")\n",
    "        print(f\"  Task type: {example.task_type}\")\n",
    "\n",
    "# Task distribution\n",
    "task_types = [ex.task_type for ex in instruction_examples]\n",
    "print(f\"\\nTask type distribution:\")\n",
    "for task_type in set(task_types):\n",
    "    count = task_types.count(task_type)\n",
    "    print(f\"  {task_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Instruction-Tuning Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionTuningDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch dataset for instruction tuning.\n",
    "    \n",
    "    Following dataset design from:\n",
    "        Iyer et al. (2022): \"OPT-IML: Scaling Language Model Instruction Meta Learning\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        examples: List[InstructionExample],\n",
    "        tokenizer,\n",
    "        max_source_length: int = 512,\n",
    "        max_target_length: int = 64\n",
    "    ):\n",
    "        self.examples = examples\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        example = self.examples[idx]\n",
    "        \n",
    "        # Format input\n",
    "        if example.explanation and random.random() < 0.5:  # Include explanation 50% of time\n",
    "            source_text = f\"{example.instruction}\\n\\nText: {example.input_text}\\n\\nExplanation: {example.explanation}\"\n",
    "        else:\n",
    "            source_text = f\"{example.instruction}\\n\\nText: {example.input_text}\"\n",
    "        \n",
    "        # Tokenize input\n",
    "        source_encoding = self.tokenizer(\n",
    "            source_text,\n",
    "            max_length=self.max_source_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize target\n",
    "        target_encoding = self.tokenizer(\n",
    "            example.output,\n",
    "            max_length=self.max_target_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Prepare labels (set padding tokens to -100 for loss calculation)\n",
    "        labels = target_encoding['input_ids'].squeeze()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return {\n",
    "            'input_ids': source_encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': source_encoding['attention_mask'].squeeze(),\n",
    "            'labels': labels,\n",
    "            'task_type': example.task_type\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tutorial_config['model_name'])\n",
    "\n",
    "# Create full instruction dataset\n",
    "print(\"\\nCreating full instruction dataset...\")\n",
    "all_instruction_examples = []\n",
    "for i in tqdm(range(min(len(train_dataset), tutorial_config['max_samples']))):\n",
    "    example = instruction_creator.create_instruction_example(i)\n",
    "    all_instruction_examples.append(example)\n",
    "\n",
    "# Split into train and validation\n",
    "split_idx = int(0.9 * len(all_instruction_examples))\n",
    "train_examples = all_instruction_examples[:split_idx]\n",
    "val_examples = all_instruction_examples[split_idx:]\n",
    "\n",
    "# Create datasets\n",
    "train_instruction_dataset = InstructionTuningDataset(\n",
    "    train_examples,\n",
    "    tokenizer,\n",
    "    max_source_length=tutorial_config['max_source_length'],\n",
    "    max_target_length=tutorial_config['max_target_length']\n",
    ")\n",
    "\n",
    "val_instruction_dataset = InstructionTuningDataset(\n",
    "    val_examples,\n",
    "    tokenizer,\n",
    "    max_source_length=tutorial_config['max_source_length'],\n",
    "    max_target_length=tutorial_config['max_target_length']\n",
    ")\n",
    "\n",
    "print(f\"\\nInstruction datasets created:\")\n",
    "print(f\"  Train examples: {len(train_instruction_dataset)}\")\n",
    "print(f\"  Validation examples: {len(val_instruction_dataset)}\")\n",
    "\n",
    "# Test dataset\n",
    "sample_batch = train_instruction_dataset[0]\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "for key, value in sample_batch.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: {value.shape}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Initialization and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model for instruction tuning\n",
    "print(\"Initializing model for instruction tuning...\")\n",
    "\n",
    "# Load pre-trained T5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained(tutorial_config['model_name'])\n",
    "model = model.to(device)\n",
    "\n",
    "# Model information\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel Information:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Model: {tutorial_config['model_name']}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / 1024**2:.1f} MB (fp32)\")\n",
    "\n",
    "\n",
    "class InstructionTuningConfig:\n",
    "    \"\"\"\n",
    "    Configuration for instruction tuning.\n",
    "    \n",
    "    Following configuration patterns from:\n",
    "        Sanh et al. (2022): \"Multitask Prompted Training\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.learning_rate = tutorial_config['learning_rate']\n",
    "        self.num_epochs = tutorial_config['num_epochs']\n",
    "        self.batch_size = tutorial_config['batch_size']\n",
    "        self.gradient_accumulation_steps = 4\n",
    "        self.warmup_ratio = 0.1\n",
    "        self.weight_decay = 0.01\n",
    "        self.max_grad_norm = 1.0\n",
    "        self.label_smoothing = 0.1\n",
    "        self.evaluation_strategy = \"steps\"\n",
    "        self.eval_steps = 50\n",
    "        self.save_steps = 100\n",
    "        self.logging_steps = 10\n",
    "        self.save_total_limit = 2\n",
    "        self.load_best_model_at_end = True\n",
    "        self.metric_for_best_model = \"eval_loss\"\n",
    "        self.greater_is_better = False\n",
    "\n",
    "\n",
    "# Create configuration\n",
    "it_config = InstructionTuningConfig()\n",
    "\n",
    "print(\"\\nTraining Configuration:\")\n",
    "print(f\"  Learning rate: {it_config.learning_rate}\")\n",
    "print(f\"  Batch size: {it_config.batch_size}\")\n",
    "print(f\"  Gradient accumulation: {it_config.gradient_accumulation_steps}\")\n",
    "print(f\"  Effective batch size: {it_config.batch_size * it_config.gradient_accumulation_steps}\")\n",
    "print(f\"  Number of epochs: {it_config.num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_instruction_dataset,\n",
    "    batch_size=it_config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_instruction_dataset,\n",
    "    batch_size=it_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# Setup optimizer\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=it_config.learning_rate,\n",
    "    weight_decay=it_config.weight_decay\n",
    ")\n",
    "\n",
    "# Setup scheduler\n",
    "num_training_steps = len(train_dataloader) * it_config.num_epochs\n",
    "num_warmup_steps = int(num_training_steps * it_config.warmup_ratio)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "print(\"Training Setup:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Number of training steps: {num_training_steps}\")\n",
    "print(f\"Number of warmup steps: {num_warmup_steps}\")\n",
    "print(f\"Number of training batches: {len(train_dataloader)}\")\n",
    "print(f\"Number of validation batches: {len(val_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: Any,\n",
    "    device: torch.device,\n",
    "    epoch: int\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Train model for one epoch.\n",
    "    \n",
    "    Following training practices from:\n",
    "        Raffel et al. (2020): \"Exploring the Limits of Transfer Learning\"\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), it_config.max_grad_norm)\n",
    "        \n",
    "        # Optimizer step\n",
    "        if (batch_idx + 1) % it_config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Update metrics\n",
    "        total_loss += loss.item()\n",
    "        total_steps += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'avg_loss': f'{total_loss / total_steps:.4f}'\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / total_steps\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate model on validation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            total_loss += outputs.loss.item()\n",
    "            total_steps += 1\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / total_steps\n",
    "    }\n",
    "\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "print(\"\\nStarting Instruction Tuning:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(it_config.num_epochs):\n",
    "    # Train\n",
    "    train_metrics = train_epoch(\n",
    "        model, train_dataloader, optimizer, scheduler, device, epoch\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_metrics = evaluate(model, val_dataloader, device)\n",
    "    \n",
    "    # Store metrics\n",
    "    history['train_loss'].append(train_metrics['loss'])\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['learning_rate'].append(scheduler.get_last_lr()[0])\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nEpoch {epoch + 1}/{it_config.num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_metrics['loss']:.4f}\")\n",
    "    print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"  Learning Rate: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['loss'] < best_val_loss:\n",
    "        best_val_loss = val_metrics['loss']\n",
    "        print(f\"  New best model! Val Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Inference and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(\n",
    "    model: nn.Module,\n",
    "    tokenizer,\n",
    "    instruction: str,\n",
    "    input_text: str,\n",
    "    device: torch.device,\n",
    "    max_length: int = 64\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate response for instruction-tuned model.\n",
    "    \n",
    "    Following generation strategies from:\n",
    "        Holtzman et al. (2020): \"The Curious Case of Neural Text Degeneration\"\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Format input\n",
    "    prompt = f\"{instruction}\\n\\nText: {input_text}\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_length=max_length,\n",
    "            num_beams=4,\n",
    "            temperature=0.7,\n",
    "            do_sample=False,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    \n",
    "    # Decode\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "# Test generation with different instructions\n",
    "test_text = val_dataset.texts[0][:300]\n",
    "test_label = val_dataset.labels[0]\n",
    "\n",
    "test_instructions = [\n",
    "    \"Classify this news article into World, Sports, Business, or Science/Technology.\",\n",
    "    \"What category does this news article belong to?\",\n",
    "    \"Is this a Sports article? Answer yes or no.\",\n",
    "    \"Extract the main topic keywords from this article.\",\n",
    "    \"Summarize the category and confidence level.\"\n",
    "]\n",
    "\n",
    "print(\"Model Generation Examples:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTest article (true label: {AG_NEWS_CLASSES[test_label]}):\")\n",
    "print(f\"{test_text}\\n\")\n",
    "\n",
    "for instruction in test_instructions[:3]:  # Test first 3 instructions\n",
    "    response = generate_response(\n",
    "        model, tokenizer, instruction, test_text, device\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nInstruction: {instruction}\")\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_instruction_following(\n",
    "    model: nn.Module,\n",
    "    tokenizer,\n",
    "    dataset: AGNewsDataset,\n",
    "    instruction_creator: InstructionDatasetCreator,\n",
    "    device: torch.device,\n",
    "    num_samples: int = 100\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate instruction-following capabilities.\n",
    "    \n",
    "    Following evaluation protocols from:\n",
    "        Ouyang et al. (2022): \"Training language models to follow instructions\"\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in tqdm(range(min(num_samples, len(dataset))), desc=\"Evaluating\"):\n",
    "        text = dataset.texts[i]\n",
    "        true_label = dataset.labels[i]\n",
    "        true_category = AG_NEWS_CLASSES[true_label]\n",
    "        \n",
    "        # Test different task variations\n",
    "        for task_variation in ['standard_classification', 'binary_verification']:\n",
    "            example = instruction_creator.create_instruction_example(i, task_variation)\n",
    "            \n",
    "            # Generate response\n",
    "            response = generate_response(\n",
    "                model, tokenizer, example.instruction, text[:300], device\n",
    "            )\n",
    "            \n",
    "            # Evaluate correctness\n",
    "            if task_variation == 'standard_classification':\n",
    "                correct = true_category.lower() in response.lower()\n",
    "            else:  # binary_verification\n",
    "                expected = example.output\n",
    "                correct = expected.lower() in response.lower()\n",
    "            \n",
    "            results.append({\n",
    "                'sample_id': i,\n",
    "                'task_type': task_variation,\n",
    "                'true_label': true_category,\n",
    "                'response': response[:50],\n",
    "                'correct': correct\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Evaluating Instruction-Following Performance:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "eval_results = evaluate_instruction_following(\n",
    "    model, tokenizer, val_dataset, instruction_creator, device, num_samples=20\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "task_performance = eval_results.groupby('task_type')['correct'].agg(['mean', 'count'])\n",
    "task_performance.columns = ['Accuracy', 'Samples']\n",
    "\n",
    "print(\"\\nPerformance by Task Type:\")\n",
    "print(task_performance)\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = eval_results['correct'].mean()\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy:.3f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Training history\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training History')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Task performance\n",
    "task_performance['Accuracy'].plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_xlabel('Task Type')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Performance by Task Type')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusions and Next Steps\n",
    "\n",
    "### Instruction Tuning Summary\n",
    "\n",
    "This tutorial demonstrated fundamental instruction tuning concepts:\n",
    "\n",
    "1. **Instruction Dataset Creation**: Built diverse instruction-following examples\n",
    "2. **Task Variations**: Implemented multiple task formats for robustness\n",
    "3. **Model Fine-tuning**: Trained T5 model with instruction-response pairs\n",
    "4. **Generation Strategies**: Applied beam search and sampling techniques\n",
    "5. **Evaluation Protocol**: Assessed instruction-following capabilities\n",
    "6. **Multi-task Learning**: Trained on various instruction types\n",
    "7. **Performance Analysis**: Evaluated task-specific performance\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Instruction Diversity**: Varied instructions improve generalization\n",
    "2. **Task Mixing**: Training on multiple tasks enhances robustness\n",
    "3. **Explanation Integration**: Including explanations improves interpretability\n",
    "4. **Model Size**: Larger models generally follow instructions better\n",
    "5. **Data Quality**: High-quality instructions crucial for performance\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Advanced Techniques**:\n",
    "   - Implement reinforcement learning from human feedback (RLHF)\n",
    "   - Try constitutional AI approaches\n",
    "   - Explore chain-of-thought instruction tuning\n",
    "\n",
    "2. **Data Enhancement**:\n",
    "   - Generate synthetic instructions with GPT-4\n",
    "   - Implement data augmentation strategies\n",
    "   - Create cross-lingual instructions\n",
    "\n",
    "3. **Model Optimization**:\n",
    "   - Apply LoRA for efficient tuning\n",
    "   - Implement quantization-aware training\n",
    "   - Try adapter-based approaches\n",
    "\n",
    "4. **Production Deployment**:\n",
    "   - Build instruction routing system\n",
    "   - Implement response caching\n",
    "   - Monitor instruction-following metrics\n",
    "\n",
    "### References\n",
    "\n",
    "For deeper understanding, consult:\n",
    "- API usage: `notebooks/tutorials/07_api_usage.ipynb`\n",
    "- Service integration: `notebooks/tutorials/08_service_integration.ipynb`\n",
    "- Advanced training: `docs/user_guide/advanced_techniques.md`\n",
    "- Production deployment: `docs/user_guide/deployment.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
