{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup for AG News Text Classification\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial guides through complete environment setup following best practices from:\n",
    "- Tatman et al. (2018): \"A Practical Guide to Training Restricted Boltzmann Machines\"\n",
    "- Sculley et al. (2015): \"Hidden Technical Debt in Machine Learning Systems\"\n",
    "\n",
    "### Tutorial Objectives\n",
    "1. Verify Python environment and dependencies\n",
    "2. Configure GPU support for deep learning\n",
    "3. Setup data directories and paths\n",
    "4. Validate project installation\n",
    "5. Configure logging and monitoring\n",
    "\n",
    "Author: Võ Hải Dũng  \n",
    "Email: vohaidung.work@gmail.com  \n",
    "Date: 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python Environment Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "\n",
    "# Check Python version\n",
    "print(\"System Information\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Operating System: {platform.system()} {platform.release()}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Python Executable: {sys.executable}\")\n",
    "\n",
    "# Verify Python version meets requirements\n",
    "required_version = (3, 8)\n",
    "current_version = sys.version_info[:2]\n",
    "\n",
    "if current_version < required_version:\n",
    "    raise SystemError(f\"Python {required_version[0]}.{required_version[1]}+ required. \"\n",
    "                     f\"Current: {current_version[0]}.{current_version[1]}\")\n",
    "else:\n",
    "    print(f\"\\n✓ Python version check passed: {current_version[0]}.{current_version[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Dependencies Installation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_package_installation(packages: Dict[str, str]) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Check installation status of required packages.\n",
    "    \n",
    "    Following dependency management practices from:\n",
    "    - McMahan & Streeter (2014): \"Delay-Tolerant Algorithms for Asynchronous Distributed Online Learning\"\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for package_name, import_name in packages.items():\n",
    "        try:\n",
    "            if import_name:\n",
    "                module = __import__(import_name)\n",
    "                version = getattr(module, '__version__', 'unknown')\n",
    "            else:\n",
    "                # For packages without direct import\n",
    "                import importlib.metadata\n",
    "                version = importlib.metadata.version(package_name)\n",
    "            \n",
    "            results[package_name] = {\n",
    "                'status': 'installed',\n",
    "                'version': version\n",
    "            }\n",
    "        except (ImportError, importlib.metadata.PackageNotFoundError):\n",
    "            results[package_name] = {\n",
    "                'status': 'missing',\n",
    "                'version': None\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define core packages\n",
    "core_packages = {\n",
    "    'numpy': 'numpy',\n",
    "    'pandas': 'pandas',\n",
    "    'scikit-learn': 'sklearn',\n",
    "    'torch': 'torch',\n",
    "    'transformers': 'transformers',\n",
    "    'datasets': 'datasets',\n",
    "    'tokenizers': 'tokenizers',\n",
    "    'accelerate': 'accelerate',\n",
    "    'peft': 'peft',\n",
    "    'fastapi': 'fastapi',\n",
    "    'uvicorn': 'uvicorn',\n",
    "    'grpcio': 'grpc',\n",
    "    'protobuf': 'google.protobuf',\n",
    "    'pydantic': 'pydantic'\n",
    "}\n",
    "\n",
    "print(\"\\nCore Package Installation Status\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "installation_status = check_package_installation(core_packages)\n",
    "missing_packages = []\n",
    "\n",
    "for package, info in installation_status.items():\n",
    "    if info['status'] == 'installed':\n",
    "        print(f\"✓ {package:20} : {info['version']}\")\n",
    "    else:\n",
    "        print(f\"✗ {package:20} : NOT INSTALLED\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n⚠ Missing packages: {', '.join(missing_packages)}\")\n",
    "    print(f\"Install with: pip install {' '.join(missing_packages)}\")\n",
    "else:\n",
    "    print(\"\\n✓ All core packages installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GPU Configuration and CUDA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu_availability() -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Check GPU availability and CUDA configuration.\n",
    "    \n",
    "    Following GPU setup guidelines from:\n",
    "    - Jouppi et al. (2017): \"In-Datacenter Performance Analysis of a Tensor Processing Unit\"\n",
    "    \"\"\"\n",
    "    gpu_info = {\n",
    "        'available': False,\n",
    "        'cuda_version': None,\n",
    "        'device_count': 0,\n",
    "        'devices': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        \n",
    "        gpu_info['available'] = torch.cuda.is_available()\n",
    "        \n",
    "        if gpu_info['available']:\n",
    "            gpu_info['cuda_version'] = torch.version.cuda\n",
    "            gpu_info['device_count'] = torch.cuda.device_count()\n",
    "            \n",
    "            for i in range(gpu_info['device_count']):\n",
    "                device_props = torch.cuda.get_device_properties(i)\n",
    "                gpu_info['devices'].append({\n",
    "                    'index': i,\n",
    "                    'name': device_props.name,\n",
    "                    'memory': f\"{device_props.total_memory / 1e9:.2f} GB\",\n",
    "                    'capability': f\"{device_props.major}.{device_props.minor}\"\n",
    "                })\n",
    "    except ImportError:\n",
    "        print(\"PyTorch not installed. Cannot check GPU availability.\")\n",
    "    \n",
    "    return gpu_info\n",
    "\n",
    "print(\"\\nGPU Configuration\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "gpu_info = check_gpu_availability()\n",
    "\n",
    "if gpu_info['available']:\n",
    "    print(f\"✓ CUDA Available: {gpu_info['cuda_version']}\")\n",
    "    print(f\"✓ GPU Count: {gpu_info['device_count']}\")\n",
    "    \n",
    "    for device in gpu_info['devices']:\n",
    "        print(f\"\\nGPU {device['index']}:\")\n",
    "        print(f\"  Name: {device['name']}\")\n",
    "        print(f\"  Memory: {device['memory']}\")\n",
    "        print(f\"  Compute Capability: {device['capability']}\")\n",
    "else:\n",
    "    print(\"✗ No GPU available. Training will use CPU.\")\n",
    "    print(\"\\nFor GPU support:\")\n",
    "    print(\"  1. Install CUDA Toolkit\")\n",
    "    print(\"  2. Install PyTorch with CUDA support\")\n",
    "    print(\"  3. Verify GPU drivers are installed\")\n",
    "\n",
    "# Set device for future use\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nDefault device set to: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Project Structure Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup project paths\n",
    "PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project Structure Verification\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Define required directories\n",
    "required_dirs = [\n",
    "    'data/raw',\n",
    "    'data/processed',\n",
    "    'data/augmented',\n",
    "    'data/external',\n",
    "    'data/cache',\n",
    "    'outputs/models',\n",
    "    'outputs/results',\n",
    "    'outputs/logs',\n",
    "    'outputs/analysis',\n",
    "    'configs',\n",
    "    'src'\n",
    "]\n",
    "\n",
    "# Check and create directories\n",
    "print(\"\\nDirectory Structure:\")\n",
    "for dir_path in required_dirs:\n",
    "    full_path = PROJECT_ROOT / dir_path\n",
    "    if full_path.exists():\n",
    "        print(f\"✓ {dir_path}\")\n",
    "    else:\n",
    "        full_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"✓ {dir_path} (created)\")\n",
    "\n",
    "# Verify critical files\n",
    "critical_files = [\n",
    "    'setup.py',\n",
    "    'requirements/base.txt',\n",
    "    'configs/constants.py',\n",
    "    'src/__init__.py'\n",
    "]\n",
    "\n",
    "print(\"\\nCritical Files:\")\n",
    "missing_files = []\n",
    "for file_path in critical_files:\n",
    "    full_path = PROJECT_ROOT / file_path\n",
    "    if full_path.exists():\n",
    "        print(f\"✓ {file_path}\")\n",
    "    else:\n",
    "        print(f\"✗ {file_path} (missing)\")\n",
    "        missing_files.append(file_path)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\n⚠ Missing critical files: {', '.join(missing_files)}\")\n",
    "else:\n",
    "    print(\"\\n✓ All critical files present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Import Project Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Project Module Imports\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test critical imports\n",
    "test_imports = [\n",
    "    ('Core Registry', 'src.core.registry'),\n",
    "    ('Core Factory', 'src.core.factory'),\n",
    "    ('Data Module', 'src.data'),\n",
    "    ('Models Module', 'src.models'),\n",
    "    ('Training Module', 'src.training'),\n",
    "    ('Evaluation Module', 'src.evaluation'),\n",
    "    ('API Module', 'src.api'),\n",
    "    ('Services Module', 'src.services'),\n",
    "    ('Utils Module', 'src.utils'),\n",
    "    ('Config Loader', 'configs.config_loader')\n",
    "]\n",
    "\n",
    "import_errors = []\n",
    "\n",
    "for module_name, import_path in test_imports:\n",
    "    try:\n",
    "        module = __import__(import_path, fromlist=[''])\n",
    "        print(f\"✓ {module_name:20} : {import_path}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"✗ {module_name:20} : {str(e)}\")\n",
    "        import_errors.append((module_name, str(e)))\n",
    "\n",
    "if import_errors:\n",
    "    print(\"\\n⚠ Import Errors Detected:\")\n",
    "    for name, error in import_errors:\n",
    "        print(f\"  {name}: {error}\")\n",
    "else:\n",
    "    print(\"\\n✓ All project modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configuration Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and validate configurations\n",
    "from configs.constants import (\n",
    "    AG_NEWS_CLASSES,\n",
    "    AG_NEWS_NUM_CLASSES,\n",
    "    LABEL_TO_ID,\n",
    "    ID_TO_LABEL,\n",
    "    DATA_DIR,\n",
    "    MODEL_DIR,\n",
    "    LOG_DIR\n",
    ")\n",
    "from configs.config_loader import ConfigLoader\n",
    "\n",
    "print(\"Configuration Validation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Validate constants\n",
    "print(\"AG News Configuration:\")\n",
    "print(f\"  Classes: {AG_NEWS_CLASSES}\")\n",
    "print(f\"  Number of Classes: {AG_NEWS_NUM_CLASSES}\")\n",
    "print(f\"  Label Mapping: {LABEL_TO_ID}\")\n",
    "\n",
    "# Validate paths\n",
    "print(\"\\nPath Configuration:\")\n",
    "print(f\"  Data Directory: {DATA_DIR}\")\n",
    "print(f\"  Model Directory: {MODEL_DIR}\")\n",
    "print(f\"  Log Directory: {LOG_DIR}\")\n",
    "\n",
    "# Test configuration loading\n",
    "try:\n",
    "    config_loader = ConfigLoader()\n",
    "    \n",
    "    # Test loading different config types\n",
    "    test_configs = [\n",
    "        'environments/dev.yaml',\n",
    "        'models/single/deberta_v3_xlarge.yaml',\n",
    "        'training/standard/base_training.yaml'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting Configuration Files:\")\n",
    "    for config_path in test_configs:\n",
    "        try:\n",
    "            config = config_loader.load_config(config_path)\n",
    "            print(f\"✓ {config_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {config_path}: {str(e)}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠ Configuration loading error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Memory and Resource Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def get_system_resources() -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Get system resource information.\n",
    "    \n",
    "    Following resource monitoring practices from:\n",
    "    - Dean et al. (2012): \"Large Scale Distributed Deep Networks\"\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'cpu': {\n",
    "            'count': psutil.cpu_count(logical=False),\n",
    "            'count_logical': psutil.cpu_count(logical=True),\n",
    "            'percent': psutil.cpu_percent(interval=1),\n",
    "            'freq': psutil.cpu_freq().current if psutil.cpu_freq() else None\n",
    "        },\n",
    "        'memory': {\n",
    "            'total': psutil.virtual_memory().total / (1024**3),\n",
    "            'available': psutil.virtual_memory().available / (1024**3),\n",
    "            'percent': psutil.virtual_memory().percent\n",
    "        },\n",
    "        'disk': {\n",
    "            'total': psutil.disk_usage('/').total / (1024**3),\n",
    "            'free': psutil.disk_usage('/').free / (1024**3),\n",
    "            'percent': psutil.disk_usage('/').percent\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"System Resources\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "resources = get_system_resources()\n",
    "\n",
    "print(\"CPU:\")\n",
    "print(f\"  Physical Cores: {resources['cpu']['count']}\")\n",
    "print(f\"  Logical Cores: {resources['cpu']['count_logical']}\")\n",
    "print(f\"  Current Usage: {resources['cpu']['percent']:.1f}%\")\n",
    "if resources['cpu']['freq']:\n",
    "    print(f\"  Frequency: {resources['cpu']['freq']:.0f} MHz\")\n",
    "\n",
    "print(\"\\nMemory:\")\n",
    "print(f\"  Total: {resources['memory']['total']:.2f} GB\")\n",
    "print(f\"  Available: {resources['memory']['available']:.2f} GB\")\n",
    "print(f\"  Usage: {resources['memory']['percent']:.1f}%\")\n",
    "\n",
    "print(\"\\nDisk:\")\n",
    "print(f\"  Total: {resources['disk']['total']:.2f} GB\")\n",
    "print(f\"  Free: {resources['disk']['free']:.2f} GB\")\n",
    "print(f\"  Usage: {resources['disk']['percent']:.1f}%\")\n",
    "\n",
    "# Check if resources are sufficient\n",
    "print(\"\\nResource Adequacy Check:\")\n",
    "min_memory = 8  # GB\n",
    "min_disk = 10  # GB\n",
    "\n",
    "if resources['memory']['available'] >= min_memory:\n",
    "    print(f\"✓ Memory: Sufficient ({resources['memory']['available']:.1f} GB available)\")\n",
    "else:\n",
    "    print(f\"⚠ Memory: May be insufficient ({resources['memory']['available']:.1f} GB < {min_memory} GB)\")\n",
    "\n",
    "if resources['disk']['free'] >= min_disk:\n",
    "    print(f\"✓ Disk: Sufficient ({resources['disk']['free']:.1f} GB free)\")\n",
    "else:\n",
    "    print(f\"⚠ Disk: May be insufficient ({resources['disk']['free']:.1f} GB < {min_disk} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Network and API Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import socket\n",
    "\n",
    "print(\"Network Connectivity Check\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check internet connectivity\n",
    "def check_internet_connection() -> bool:\n",
    "    \"\"\"Check basic internet connectivity.\"\"\"\n",
    "    try:\n",
    "        socket.create_connection((\"8.8.8.8\", 53), timeout=3)\n",
    "        return True\n",
    "    except OSError:\n",
    "        return False\n",
    "\n",
    "if check_internet_connection():\n",
    "    print(\"✓ Internet connection available\")\n",
    "else:\n",
    "    print(\"✗ No internet connection\")\n",
    "\n",
    "# Check access to key services\n",
    "services_to_check = [\n",
    "    ('Hugging Face Hub', 'https://huggingface.co'),\n",
    "    ('PyTorch Hub', 'https://pytorch.org'),\n",
    "    ('GitHub', 'https://github.com'),\n",
    "    ('Google Colab', 'https://colab.research.google.com')\n",
    "]\n",
    "\n",
    "print(\"\\nService Accessibility:\")\n",
    "for service_name, url in services_to_check:\n",
    "    try:\n",
    "        response = requests.head(url, timeout=5)\n",
    "        if response.status_code < 400:\n",
    "            print(f\"✓ {service_name:20} : Accessible\")\n",
    "        else:\n",
    "            print(f\"⚠ {service_name:20} : Status {response.status_code}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"✗ {service_name:20} : Not accessible\")\n",
    "\n",
    "# Check Hugging Face model access\n",
    "print(\"\\nHugging Face Model Access:\")\n",
    "test_models = [\n",
    "    'microsoft/deberta-v3-base',\n",
    "    'roberta-base',\n",
    "    'google/electra-base-discriminator'\n",
    "]\n",
    "\n",
    "for model_name in test_models:\n",
    "    url = f\"https://huggingface.co/{model_name}\"\n",
    "    try:\n",
    "        response = requests.head(url, timeout=5)\n",
    "        if response.status_code < 400:\n",
    "            print(f\"✓ {model_name}\")\n",
    "        else:\n",
    "            print(f\"⚠ {model_name} : Status {response.status_code}\")\n",
    "    except:\n",
    "        print(f\"✗ {model_name} : Not accessible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Environment Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Environment Setup Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compile status\n",
    "setup_status = {\n",
    "    'python': current_version >= required_version,\n",
    "    'packages': len(missing_packages) == 0,\n",
    "    'gpu': gpu_info['available'],\n",
    "    'project_structure': len(missing_files) == 0,\n",
    "    'imports': len(import_errors) == 0,\n",
    "    'memory': resources['memory']['available'] >= min_memory,\n",
    "    'disk': resources['disk']['free'] >= min_disk,\n",
    "    'internet': check_internet_connection()\n",
    "}\n",
    "\n",
    "# Overall status\n",
    "all_ready = all(setup_status.values())\n",
    "critical_ready = setup_status['python'] and setup_status['packages'] and setup_status['project_structure']\n",
    "\n",
    "print(\"Status Overview:\")\n",
    "for component, status in setup_status.items():\n",
    "    icon = \"✓\" if status else \"✗\"\n",
    "    print(f\"{icon} {component.replace('_', ' ').title():20} : {'Ready' if status else 'Issues Detected'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_ready:\n",
    "    print(\"✓ ENVIRONMENT FULLY CONFIGURED\")\n",
    "    print(\"\\nYou are ready to proceed with:\")\n",
    "    print(\"  1. Data loading and preprocessing\")\n",
    "    print(\"  2. Model training and evaluation\")\n",
    "    print(\"  3. API deployment and testing\")\n",
    "elif critical_ready:\n",
    "    print(\"⚠ ENVIRONMENT PARTIALLY CONFIGURED\")\n",
    "    print(\"\\nCritical components are ready, but some optimizations missing:\")\n",
    "    if not setup_status['gpu']:\n",
    "        print(\"  - GPU not available (training will be slower)\")\n",
    "    if not setup_status['memory']:\n",
    "        print(\"  - Limited memory (may affect batch sizes)\")\n",
    "else:\n",
    "    print(\"✗ ENVIRONMENT SETUP INCOMPLETE\")\n",
    "    print(\"\\nPlease resolve critical issues before proceeding.\")\n",
    "\n",
    "# Save environment report\n",
    "from src.utils.io_utils import safe_save, ensure_dir\n",
    "\n",
    "output_dir = PROJECT_ROOT / \"outputs\" / \"setup\"\n",
    "ensure_dir(output_dir)\n",
    "\n",
    "environment_report = {\n",
    "    'timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'system': {\n",
    "        'platform': platform.platform(),\n",
    "        'python_version': f\"{current_version[0]}.{current_version[1]}\",\n",
    "        'cuda_available': gpu_info['available'],\n",
    "        'gpu_count': gpu_info['device_count']\n",
    "    },\n",
    "    'resources': resources,\n",
    "    'status': setup_status,\n",
    "    'ready': all_ready\n",
    "}\n",
    "\n",
    "report_path = output_dir / \"environment_report.json\"\n",
    "safe_save(environment_report, report_path)\n",
    "print(f\"\\nEnvironment report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "### Recommended Tutorial Progression\n",
    "\n",
    "Based on your environment setup, proceed with the following tutorials:\n",
    "\n",
    "1. **01_data_loading_basics.ipynb**\n",
    "   - Learn to load and explore AG News dataset\n",
    "   - Understand data structures and formats\n",
    "   - Practice basic data operations\n",
    "\n",
    "2. **02_preprocessing_tutorial.ipynb**\n",
    "   - Apply text cleaning techniques\n",
    "   - Implement tokenization strategies\n",
    "   - Create feature representations\n",
    "\n",
    "3. **03_model_training_basics.ipynb**\n",
    "   - Train baseline models\n",
    "   - Understand training loops\n",
    "   - Monitor training progress\n",
    "\n",
    "4. **04_evaluation_tutorial.ipynb**\n",
    "   - Evaluate model performance\n",
    "   - Generate comprehensive reports\n",
    "   - Compare different models\n",
    "\n",
    "### Troubleshooting Resources\n",
    "\n",
    "If you encounter issues:\n",
    "- Check `TROUBLESHOOTING.md` for common problems\n",
    "- Review logs in `outputs/logs/`\n",
    "- Consult project documentation in `docs/`\n",
    "- Submit issues to project repository\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "For optimal performance:\n",
    "- Use GPU acceleration when available\n",
    "- Enable mixed precision training\n",
    "- Implement gradient accumulation for large models\n",
    "- Utilize caching for preprocessed data\n",
    "- Monitor memory usage during training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
