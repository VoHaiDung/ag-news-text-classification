{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup for AG News Text Classification\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial provides comprehensive setup instructions for the AG News Text Classification project following best practices from:\n",
    "- Sculley et al. (2015): \"Hidden Technical Debt in Machine Learning Systems\"\n",
    "- Amershi et al. (2019): \"Software Engineering for Machine Learning: A Case Study\"\n",
    "\n",
    "### Learning Objectives\n",
    "1. Set up development environment with proper dependencies\n",
    "2. Verify system requirements and GPU availability\n",
    "3. Configure project paths and environment variables\n",
    "4. Validate installation with basic tests\n",
    "\n",
    "Author: Võ Hải Dũng  \n",
    "Email: vohaidung.work@gmail.com  \n",
    "Date: 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "# Display system information\n",
    "print(\"System Information\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Machine: {platform.machine()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"CPU cores: {os.cpu_count()}\")\n",
    "\n",
    "# Memory information\n",
    "try:\n",
    "    import psutil\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"\\nMemory Information:\")\n",
    "    print(f\"  Total: {mem.total / (1024**3):.2f} GB\")\n",
    "    print(f\"  Available: {mem.available / (1024**3):.2f} GB\")\n",
    "    print(f\"  Used: {mem.percent:.1f}%\")\n",
    "except ImportError:\n",
    "    print(\"\\nNote: Install psutil for memory information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Structure Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project root and verify structure\n",
    "PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Verify essential directories exist\n",
    "required_dirs = [\n",
    "    \"src\",\n",
    "    \"configs\", \n",
    "    \"data\",\n",
    "    \"scripts\",\n",
    "    \"tests\",\n",
    "    \"notebooks\"\n",
    "]\n",
    "\n",
    "print(\"\\nVerifying project structure:\")\n",
    "missing_dirs = []\n",
    "for dir_name in required_dirs:\n",
    "    dir_path = PROJECT_ROOT / dir_name\n",
    "    exists = dir_path.exists()\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"  {status} {dir_name}/\")\n",
    "    if not exists:\n",
    "        missing_dirs.append(dir_name)\n",
    "\n",
    "if missing_dirs:\n",
    "    print(f\"\\nWarning: Missing directories: {', '.join(missing_dirs)}\")\n",
    "    print(\"Creating missing directories...\")\n",
    "    for dir_name in missing_dirs:\n",
    "        (PROJECT_ROOT / dir_name).mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Directories created successfully.\")\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "    print(f\"\\nAdded {PROJECT_ROOT} to Python path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Environment Variables Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "def load_env_file(env_path: Path) -> Dict[str, str]:\n",
    "    \"\"\"Load environment variables from .env file.\"\"\"\n",
    "    env_vars = {}\n",
    "    if env_path.exists():\n",
    "        with open(env_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#') and '=' in line:\n",
    "                    key, value = line.split('=', 1)\n",
    "                    env_vars[key.strip()] = value.strip()\n",
    "    return env_vars\n",
    "\n",
    "# Check for .env file\n",
    "env_file = PROJECT_ROOT / \".env\"\n",
    "env_example = PROJECT_ROOT / \".env.example\"\n",
    "\n",
    "if not env_file.exists() and env_example.exists():\n",
    "    print(\"Creating .env file from .env.example...\")\n",
    "    import shutil\n",
    "    shutil.copy(env_example, env_file)\n",
    "    print(\"Please update .env file with your configuration.\")\n",
    "\n",
    "# Load environment variables\n",
    "if env_file.exists():\n",
    "    env_vars = load_env_file(env_file)\n",
    "    print(f\"Loaded {len(env_vars)} environment variables from .env\")\n",
    "    \n",
    "    # Set environment variables\n",
    "    for key, value in env_vars.items():\n",
    "        os.environ[key] = value\n",
    "else:\n",
    "    print(\"No .env file found. Using default configuration.\")\n",
    "\n",
    "# Display important environment variables (without sensitive values)\n",
    "print(\"\\nEnvironment Configuration:\")\n",
    "important_vars = [\n",
    "    \"PROJECT_NAME\",\n",
    "    \"ENVIRONMENT\", \n",
    "    \"LOG_LEVEL\",\n",
    "    \"CUDA_VISIBLE_DEVICES\"\n",
    "]\n",
    "\n",
    "for var in important_vars:\n",
    "    value = os.environ.get(var, \"Not set\")\n",
    "    # Mask sensitive values\n",
    "    if \"KEY\" in var or \"SECRET\" in var:\n",
    "        value = \"***\" if value != \"Not set\" else value\n",
    "    print(f\"  {var}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dependencies Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and install required packages\n",
    "import subprocess\n",
    "import importlib.util\n",
    "\n",
    "def check_package(package_name: str) -> bool:\n",
    "    \"\"\"Check if a package is installed.\"\"\"\n",
    "    spec = importlib.util.find_spec(package_name)\n",
    "    return spec is not None\n",
    "\n",
    "# Define package groups\n",
    "package_groups = {\n",
    "    \"Core\": [\"numpy\", \"pandas\", \"scipy\", \"scikit-learn\"],\n",
    "    \"Deep Learning\": [\"torch\", \"transformers\", \"datasets\", \"tokenizers\"],\n",
    "    \"Visualization\": [\"matplotlib\", \"seaborn\", \"plotly\"],\n",
    "    \"Utilities\": [\"tqdm\", \"pyyaml\", \"python-dotenv\", \"requests\"]\n",
    "}\n",
    "\n",
    "print(\"Package Installation Status:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "missing_packages = []\n",
    "for group, packages in package_groups.items():\n",
    "    print(f\"\\n{group}:\")\n",
    "    for package in packages:\n",
    "        # Handle special cases for import names\n",
    "        import_name = package\n",
    "        if package == \"scikit-learn\":\n",
    "            import_name = \"sklearn\"\n",
    "        elif package == \"python-dotenv\":\n",
    "            import_name = \"dotenv\"\n",
    "        elif package == \"pyyaml\":\n",
    "            import_name = \"yaml\"\n",
    "            \n",
    "        installed = check_package(import_name)\n",
    "        status = \"✓\" if installed else \"✗\"\n",
    "        print(f\"  {status} {package}\")\n",
    "        \n",
    "        if not installed:\n",
    "            missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\nMissing packages: {', '.join(missing_packages)}\")\n",
    "    print(\"\\nTo install missing packages, run:\")\n",
    "    print(f\"pip install {' '.join(missing_packages)}\")\n",
    "else:\n",
    "    print(\"\\nAll required packages are installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GPU/CUDA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "print(\"GPU/CUDA Configuration\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {cuda_available}\")\n",
    "    \n",
    "    if cuda_available:\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "        print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            print(f\"\\nGPU {i}: {props.name}\")\n",
    "            print(f\"  Memory: {props.total_memory / (1024**3):.2f} GB\")\n",
    "            print(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "            \n",
    "            # Current memory usage\n",
    "            if torch.cuda.is_available():\n",
    "                allocated = torch.cuda.memory_allocated(i) / (1024**3)\n",
    "                reserved = torch.cuda.memory_reserved(i) / (1024**3)\n",
    "                print(f\"  Current Usage: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "    else:\n",
    "        print(\"\\nNo GPU detected. Training will use CPU.\")\n",
    "        print(\"For GPU support:\")\n",
    "        print(\"  1. Ensure NVIDIA GPU is available\")\n",
    "        print(\"  2. Install CUDA Toolkit\")\n",
    "        print(\"  3. Install PyTorch with CUDA support\")\n",
    "        \n",
    "    # Test tensor operations\n",
    "    device = \"cuda\" if cuda_available else \"cpu\"\n",
    "    test_tensor = torch.randn(100, 100).to(device)\n",
    "    result = torch.matmul(test_tensor, test_tensor.t())\n",
    "    print(f\"\\nTensor operations on {device}: Success\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed. Install with:\")\n",
    "    print(\"  pip install torch torchvision torchaudio\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking GPU: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Project Dependencies Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify project-specific imports\n",
    "print(\"Project Module Verification\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test critical imports\n",
    "test_imports = [\n",
    "    (\"src.core.registry\", \"Registry\"),\n",
    "    (\"src.core.factory\", \"Factory\"),\n",
    "    (\"src.data.datasets.ag_news\", \"AGNewsDataset\"),\n",
    "    (\"src.utils.logging_config\", \"setup_logging\"),\n",
    "    (\"configs.config_loader\", \"ConfigLoader\")\n",
    "]\n",
    "\n",
    "import_status = {}\n",
    "for module_path, component in test_imports:\n",
    "    try:\n",
    "        module = __import__(module_path, fromlist=[component])\n",
    "        obj = getattr(module, component, None)\n",
    "        if obj:\n",
    "            import_status[module_path] = True\n",
    "            print(f\"✓ {module_path}.{component}\")\n",
    "        else:\n",
    "            import_status[module_path] = False\n",
    "            print(f\"✗ {module_path}.{component} - Component not found\")\n",
    "    except ImportError as e:\n",
    "        import_status[module_path] = False\n",
    "        print(f\"✗ {module_path} - {str(e)}\")\n",
    "    except Exception as e:\n",
    "        import_status[module_path] = False\n",
    "        print(f\"✗ {module_path} - Unexpected error: {str(e)}\")\n",
    "\n",
    "# Summary\n",
    "success_count = sum(import_status.values())\n",
    "total_count = len(import_status)\n",
    "print(f\"\\nImport Success Rate: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\")\n",
    "\n",
    "if success_count < total_count:\n",
    "    print(\"\\nSome modules failed to import. Check error messages above.\")\n",
    "else:\n",
    "    print(\"\\nAll project modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data directories\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\"\n",
    "\n",
    "# Define data directory structure\n",
    "data_dirs = {\n",
    "    \"raw\": [\"ag_news\"],\n",
    "    \"processed\": [\"train\", \"validation\", \"test\", \"stratified_folds\"],\n",
    "    \"augmented\": [\"back_translated\", \"paraphrased\", \"synthetic\", \"mixup\"],\n",
    "    \"external\": [\"news_corpus\", \"pretrain_data\"],\n",
    "    \"cache\": [\"model_cache\", \"api_cache\", \"service_cache\"]\n",
    "}\n",
    "\n",
    "print(\"Data Directory Setup\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for parent_dir, subdirs in data_dirs.items():\n",
    "    parent_path = DATA_ROOT / parent_dir\n",
    "    print(f\"\\n{parent_dir}/\")\n",
    "    \n",
    "    # Create parent directory\n",
    "    parent_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create subdirectories\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = parent_path / subdir\n",
    "        subdir_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  ✓ {subdir}/\")\n",
    "\n",
    "# Check available space\n",
    "try:\n",
    "    import shutil\n",
    "    stat = shutil.disk_usage(DATA_ROOT)\n",
    "    print(f\"\\nDisk Space:\")\n",
    "    print(f\"  Total: {stat.total / (1024**3):.2f} GB\")\n",
    "    print(f\"  Free: {stat.free / (1024**3):.2f} GB\")\n",
    "    print(f\"  Used: {(stat.used / stat.total) * 100:.1f}%\")\n",
    "    \n",
    "    if stat.free < 10 * (1024**3):  # Less than 10GB free\n",
    "        print(\"\\nWarning: Low disk space. Consider freeing up space for model training.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not check disk space: {e}\")\n",
    "\n",
    "print(f\"\\nData root directory: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Configuration Files Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify configuration files\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "CONFIG_ROOT = PROJECT_ROOT / \"configs\"\n",
    "\n",
    "print(\"Configuration Files Verification\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check for key configuration files\n",
    "config_categories = [\n",
    "    (\"environments\", [\"dev.yaml\", \"staging.yaml\", \"prod.yaml\"]),\n",
    "    (\"models/single\", [\"deberta_v3_xlarge.yaml\", \"roberta_large.yaml\"]),\n",
    "    (\"training/standard\", [\"base_training.yaml\"]),\n",
    "    (\"data/preprocessing\", [\"standard.yaml\", \"advanced.yaml\"]),\n",
    "    (\"api\", [\"rest_config.yaml\", \"auth_config.yaml\"])\n",
    "]\n",
    "\n",
    "valid_configs = []\n",
    "invalid_configs = []\n",
    "\n",
    "for category, files in config_categories:\n",
    "    print(f\"\\n{category}:\")\n",
    "    category_path = CONFIG_ROOT / category\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = category_path / file_name\n",
    "        \n",
    "        if file_path.exists():\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    config_data = yaml.safe_load(f)\n",
    "                    if config_data:\n",
    "                        print(f\"  ✓ {file_name} (valid)\")\n",
    "                        valid_configs.append(str(file_path))\n",
    "                    else:\n",
    "                        print(f\"  ⚠ {file_name} (empty)\")\n",
    "            except yaml.YAMLError as e:\n",
    "                print(f\"  ✗ {file_name} (invalid YAML)\")\n",
    "                invalid_configs.append(str(file_path))\n",
    "        else:\n",
    "            print(f\"  ✗ {file_name} (not found)\")\n",
    "\n",
    "print(f\"\\n\\nSummary:\")\n",
    "print(f\"  Valid configs: {len(valid_configs)}\")\n",
    "print(f\"  Invalid configs: {len(invalid_configs)}\")\n",
    "\n",
    "if invalid_configs:\n",
    "    print(f\"\\nInvalid configuration files need attention:\")\n",
    "    for config in invalid_configs:\n",
    "        print(f\"  - {config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Basic Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic functionality\n",
    "print(\"Basic Functionality Test\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test 1: Logging\n",
    "print(\"\\n1. Testing logging system...\")\n",
    "try:\n",
    "    from src.utils.logging_config import setup_logging, get_logger\n",
    "    \n",
    "    logger = setup_logging(\n",
    "        name=\"test_logger\",\n",
    "        log_level=\"INFO\",\n",
    "        log_file=None  # Console only for testing\n",
    "    )\n",
    "    logger.info(\"Logging system working correctly\")\n",
    "    print(\"   ✓ Logging system functional\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Logging error: {e}\")\n",
    "\n",
    "# Test 2: Configuration loading\n",
    "print(\"\\n2. Testing configuration loader...\")\n",
    "try:\n",
    "    from configs.config_loader import ConfigLoader\n",
    "    \n",
    "    config_loader = ConfigLoader(CONFIG_ROOT)\n",
    "    test_config = config_loader.load_config(\"environments/dev.yaml\")\n",
    "    if test_config:\n",
    "        print(f\"   ✓ Configuration loaded: {len(test_config)} keys\")\n",
    "    else:\n",
    "        print(\"   ⚠ Configuration empty\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Configuration error: {e}\")\n",
    "\n",
    "# Test 3: Registry pattern\n",
    "print(\"\\n3. Testing registry pattern...\")\n",
    "try:\n",
    "    from src.core.registry import Registry\n",
    "    \n",
    "    registry = Registry(\"test\")\n",
    "    \n",
    "    @registry.register(\"test_component\")\n",
    "    class TestComponent:\n",
    "        pass\n",
    "    \n",
    "    component = registry.get(\"test_component\")\n",
    "    if component:\n",
    "        print(\"   ✓ Registry pattern functional\")\n",
    "    else:\n",
    "        print(\"   ✗ Registry pattern failed\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Registry error: {e}\")\n",
    "\n",
    "# Test 4: Reproducibility utilities\n",
    "print(\"\\n4. Testing reproducibility utilities...\")\n",
    "try:\n",
    "    from src.utils.reproducibility import set_seed, get_reproducible_config\n",
    "    \n",
    "    set_seed(42)\n",
    "    config = get_reproducible_config()\n",
    "    print(f\"   ✓ Reproducibility utilities functional (seed: {config['seed']})\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Reproducibility error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Setup verification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Environment Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate environment summary\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Collect environment information\n",
    "env_summary = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"python_version\": sys.version,\n",
    "    \"platform\": platform.platform(),\n",
    "    \"project_root\": str(PROJECT_ROOT),\n",
    "    \"gpu_available\": torch.cuda.is_available() if 'torch' in sys.modules else False,\n",
    "    \"configurations\": {\n",
    "        \"valid\": len(valid_configs),\n",
    "        \"invalid\": len(invalid_configs)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_path = PROJECT_ROOT / \"outputs\" / \"setup_summary.json\"\n",
    "summary_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(env_summary, f, indent=2)\n",
    "\n",
    "print(\"Environment Setup Summary\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Setup completed at: {env_summary['timestamp']}\")\n",
    "print(f\"Summary saved to: {summary_path}\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Review and update .env file with your specific settings\")\n",
    "print(\"2. Download AG News dataset using scripts/setup/download_all_data.py\")\n",
    "print(\"3. Proceed to 01_data_loading_basics.ipynb tutorial\")\n",
    "print(\"4. Explore model training with 03_model_training_basics.ipynb\")\n",
    "\n",
    "print(\"\\nUseful Commands:\")\n",
    "print(\"  Download data: python scripts/setup/download_all_data.py\")\n",
    "print(\"  Verify setup: python scripts/setup/verify_installation.py\")\n",
    "print(\"  Quick start: python quickstart/minimal_example.py\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Environment setup complete! Ready for AG News classification.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
