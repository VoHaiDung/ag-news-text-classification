{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup for AG News Classification\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides comprehensive guidance for setting up the development environment following best practices from:\n",
    "- Python Packaging Authority (PyPA) guidelines\n",
    "- TensorFlow and PyTorch installation recommendations\n",
    "- MLOps best practices for reproducible environments\n",
    "\n",
    "### Objectives\n",
    "1. Verify Python environment and dependencies\n",
    "2. Configure GPU support for deep learning\n",
    "3. Test all major components\n",
    "4. Validate data pipeline and model loading\n",
    "\n",
    "Author: Võ Hải Dũng  \n",
    "Email: vohaidung.work@gmail.com  \n",
    "Date: 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python Environment Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for clean output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# System information\n",
    "print(\"System Information\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Timestamp: {datetime.now().isoformat()}\")\n",
    "\n",
    "# Check Python version requirement\n",
    "python_version = sys.version_info\n",
    "required_version = (3, 8)\n",
    "\n",
    "if python_version >= required_version:\n",
    "    print(f\"\\nPython version check: PASSED (>= {required_version[0]}.{required_version[1]})\")\n",
    "else:\n",
    "    print(f\"\\nPython version check: FAILED\")\n",
    "    print(f\"Required: Python {required_version[0]}.{required_version[1]} or higher\")\n",
    "    print(f\"Current: Python {python_version.major}.{python_version.minor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Structure Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify project structure\n",
    "PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Essential directories\n",
    "essential_dirs = [\n",
    "    \"src\",\n",
    "    \"configs\", \n",
    "    \"data\",\n",
    "    \"scripts\",\n",
    "    \"tests\",\n",
    "    \"notebooks\",\n",
    "    \"requirements\"\n",
    "]\n",
    "\n",
    "print(\"\\nProject Structure Check:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "missing_dirs = []\n",
    "for dir_name in essential_dirs:\n",
    "    dir_path = PROJECT_ROOT / dir_name\n",
    "    if dir_path.exists():\n",
    "        print(f\"  {dir_name}: Found\")\n",
    "    else:\n",
    "        print(f\"  {dir_name}: Missing\")\n",
    "        missing_dirs.append(dir_name)\n",
    "\n",
    "if missing_dirs:\n",
    "    print(f\"\\nWarning: Missing directories: {', '.join(missing_dirs)}\")\n",
    "    print(\"Creating missing directories...\")\n",
    "    for dir_name in missing_dirs:\n",
    "        dir_path = PROJECT_ROOT / dir_name\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  Created: {dir_path}\")\n",
    "else:\n",
    "    print(\"\\nAll essential directories present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core Dependencies Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_package(package_name: str, import_name: str = None):\n",
    "    \"\"\"\n",
    "    Check if a package is installed and get its version.\n",
    "    \n",
    "    Args:\n",
    "        package_name: Name of the package\n",
    "        import_name: Import name if different from package name\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (is_installed, version)\n",
    "    \"\"\"\n",
    "    import_name = import_name or package_name\n",
    "    \n",
    "    try:\n",
    "        module = __import__(import_name)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        return True, version\n",
    "    except ImportError:\n",
    "        return False, None\n",
    "\n",
    "# Core packages to check\n",
    "core_packages = [\n",
    "    ('numpy', None),\n",
    "    ('pandas', None),\n",
    "    ('torch', None),\n",
    "    ('transformers', None),\n",
    "    ('datasets', None),\n",
    "    ('scikit-learn', 'sklearn'),\n",
    "    ('matplotlib', None),\n",
    "    ('seaborn', None),\n",
    "    ('tqdm', None),\n",
    "    ('pydantic', None),\n",
    "    ('fastapi', None),\n",
    "    ('uvicorn', None)\n",
    "]\n",
    "\n",
    "print(\"Core Dependencies Check:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Package':<20} {'Status':<15} {'Version':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "missing_packages = []\n",
    "for package_name, import_name in core_packages:\n",
    "    is_installed, version = check_package(package_name, import_name)\n",
    "    \n",
    "    if is_installed:\n",
    "        status = \"Installed\"\n",
    "        version_str = version\n",
    "    else:\n",
    "        status = \"Missing\"\n",
    "        version_str = \"-\"\n",
    "        missing_packages.append(package_name)\n",
    "    \n",
    "    print(f\"{package_name:<20} {status:<15} {version_str:<15}\")\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\nMissing packages detected: {', '.join(missing_packages)}\")\n",
    "    print(\"Install missing packages with:\")\n",
    "    print(f\"  pip install {' '.join(missing_packages)}\")\n",
    "else:\n",
    "    print(\"\\nAll core dependencies are installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GPU/CUDA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "print(\"GPU/CUDA Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {cuda_available}\")\n",
    "    \n",
    "    if cuda_available:\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "        print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            print(f\"\\nGPU {i}: {props.name}\")\n",
    "            print(f\"  Memory: {props.total_memory / 1024**3:.1f} GB\")\n",
    "            print(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "            \n",
    "        # Test GPU computation\n",
    "        print(\"\\nTesting GPU computation...\")\n",
    "        device = torch.device('cuda:0')\n",
    "        x = torch.randn(1000, 1000).to(device)\n",
    "        y = torch.randn(1000, 1000).to(device)\n",
    "        z = torch.matmul(x, y)\n",
    "        print(f\"GPU computation test: PASSED\")\n",
    "        print(f\"Result shape: {z.shape}\")\n",
    "    else:\n",
    "        print(\"\\nNo GPU detected. Training will use CPU.\")\n",
    "        print(\"For GPU support, ensure:\")\n",
    "        print(\"  1. NVIDIA GPU with CUDA support is available\")\n",
    "        print(\"  2. CUDA toolkit is installed\")\n",
    "        print(\"  3. PyTorch is installed with CUDA support\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed. Cannot check GPU configuration.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking GPU: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Import Project Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Testing Project Module Imports:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test imports\n",
    "test_imports = [\n",
    "    \"src.data.datasets.ag_news\",\n",
    "    \"src.data.preprocessing.text_cleaner\",\n",
    "    \"src.models.base.base_model\",\n",
    "    \"src.training.trainers.base_trainer\",\n",
    "    \"src.evaluation.metrics.classification_metrics\",\n",
    "    \"src.utils.logging_config\",\n",
    "    \"src.utils.reproducibility\",\n",
    "    \"configs.config_loader\",\n",
    "    \"configs.constants\"\n",
    "]\n",
    "\n",
    "import_errors = []\n",
    "for module_path in test_imports:\n",
    "    try:\n",
    "        module = __import__(module_path, fromlist=[''])\n",
    "        print(f\"  {module_path}: SUCCESS\")\n",
    "    except ImportError as e:\n",
    "        print(f\"  {module_path}: FAILED - {str(e)}\")\n",
    "        import_errors.append((module_path, str(e)))\n",
    "\n",
    "if import_errors:\n",
    "    print(\"\\nImport errors detected:\")\n",
    "    for module_path, error in import_errors:\n",
    "        print(f\"  {module_path}: {error}\")\n",
    "else:\n",
    "    print(\"\\nAll project modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configuration Loading Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test configuration loading\n",
    "print(\"Configuration Loading Test:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from configs.config_loader import ConfigLoader\n",
    "    from configs.constants import (\n",
    "        AG_NEWS_CLASSES,\n",
    "        AG_NEWS_NUM_CLASSES,\n",
    "        DATA_DIR,\n",
    "        MODEL_DIR\n",
    "    )\n",
    "    \n",
    "    # Load configuration\n",
    "    config_loader = ConfigLoader()\n",
    "    \n",
    "    # Test loading different configs\n",
    "    config_files = [\n",
    "        \"models/single/deberta_v3_xlarge.yaml\",\n",
    "        \"training/standard/base_training.yaml\",\n",
    "        \"data/preprocessing/standard.yaml\"\n",
    "    ]\n",
    "    \n",
    "    for config_file in config_files:\n",
    "        try:\n",
    "            config = config_loader.load_config(config_file)\n",
    "            print(f\"  {config_file}: Loaded successfully\")\n",
    "            if config:\n",
    "                print(f\"    Keys: {list(config.keys())[:5]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {config_file}: Failed - {str(e)}\")\n",
    "    \n",
    "    # Display constants\n",
    "    print(\"\\nProject Constants:\")\n",
    "    print(f\"  AG News Classes: {AG_NEWS_CLASSES}\")\n",
    "    print(f\"  Number of Classes: {AG_NEWS_NUM_CLASSES}\")\n",
    "    print(f\"  Data Directory: {DATA_DIR}\")\n",
    "    print(f\"  Model Directory: {MODEL_DIR}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Failed to import configuration modules: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Configuration test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Pipeline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data pipeline\n",
    "print(\"Data Pipeline Test:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from src.data.datasets.ag_news import AGNewsDataset, AGNewsConfig\n",
    "    from src.data.preprocessing.text_cleaner import TextCleaner, CleaningConfig\n",
    "    \n",
    "    # Test text cleaning\n",
    "    print(\"\\nTesting text cleaner...\")\n",
    "    cleaner_config = CleaningConfig(\n",
    "        lowercase=True,\n",
    "        remove_punctuation=False,\n",
    "        remove_numbers=False\n",
    "    )\n",
    "    cleaner = TextCleaner(cleaner_config)\n",
    "    \n",
    "    test_text = \"This is a TEST text with Numbers 123 and Punctuation!!!\"\n",
    "    cleaned_text = cleaner.clean(test_text)\n",
    "    print(f\"  Original: {test_text}\")\n",
    "    print(f\"  Cleaned: {cleaned_text}\")\n",
    "    \n",
    "    # Test dataset loading\n",
    "    print(\"\\nTesting dataset loading...\")\n",
    "    dataset_config = AGNewsConfig(\n",
    "        data_dir=DATA_DIR / \"processed\",\n",
    "        max_samples=100,  # Load only 100 samples for testing\n",
    "        use_cache=False\n",
    "    )\n",
    "    \n",
    "    # Try to load a small sample\n",
    "    try:\n",
    "        dataset = AGNewsDataset(dataset_config, split=\"train\")\n",
    "        print(f\"  Dataset loaded successfully\")\n",
    "        print(f\"  Number of samples: {len(dataset)}\")\n",
    "        \n",
    "        # Test getting a sample\n",
    "        sample = dataset[0]\n",
    "        print(f\"  Sample keys: {list(sample.keys())}\")\n",
    "        print(f\"  Sample text (truncated): {sample['text'][:100]}...\")\n",
    "        print(f\"  Sample label: {sample['label']}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"  Dataset files not found. Run data preparation scripts first.\")\n",
    "        print(\"  Use: python scripts/data_preparation/prepare_ag_news.py\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Failed to import data modules: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Data pipeline test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Loading Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model loading\n",
    "print(\"Model Loading Test:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    \n",
    "    # Test loading a small model\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    print(f\"\\nTesting loading of {model_name}...\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    print(\"  Loading tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    print(f\"    Tokenizer loaded: {type(tokenizer).__name__}\")\n",
    "    print(f\"    Vocab size: {tokenizer.vocab_size}\")\n",
    "    \n",
    "    # Test tokenization\n",
    "    test_text = \"This is a test sentence for tokenization.\"\n",
    "    tokens = tokenizer(test_text, return_tensors=\"pt\")\n",
    "    print(f\"    Tokenization test: SUCCESS\")\n",
    "    print(f\"    Input IDs shape: {tokens['input_ids'].shape}\")\n",
    "    \n",
    "    # Load model (only if sufficient memory)\n",
    "    print(\"  Loading model architecture...\")\n",
    "    try:\n",
    "        model = AutoModel.from_pretrained(model_name)\n",
    "        print(f\"    Model loaded: {type(model).__name__}\")\n",
    "        print(f\"    Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        \n",
    "        # Test forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokens)\n",
    "            print(f\"    Forward pass: SUCCESS\")\n",
    "            print(f\"    Output shape: {outputs.last_hidden_state.shape}\")\n",
    "            \n",
    "    except MemoryError:\n",
    "        print(\"    Insufficient memory to load model\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Model loading failed: {e}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"Transformers library not installed.\")\n",
    "    print(\"Install with: pip install transformers\")\n",
    "except Exception as e:\n",
    "    print(f\"Model test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Memory and Resource Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system resources\n",
    "print(\"System Resources:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "    \n",
    "    # CPU information\n",
    "    print(\"\\nCPU Information:\")\n",
    "    print(f\"  Physical cores: {psutil.cpu_count(logical=False)}\")\n",
    "    print(f\"  Logical cores: {psutil.cpu_count(logical=True)}\")\n",
    "    print(f\"  Current usage: {psutil.cpu_percent(interval=1)}%\")\n",
    "    \n",
    "    # Memory information\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(\"\\nMemory Information:\")\n",
    "    print(f\"  Total: {memory.total / (1024**3):.1f} GB\")\n",
    "    print(f\"  Available: {memory.available / (1024**3):.1f} GB\")\n",
    "    print(f\"  Used: {memory.used / (1024**3):.1f} GB ({memory.percent}%)\")\n",
    "    \n",
    "    # Disk information\n",
    "    disk = psutil.disk_usage('/')\n",
    "    print(\"\\nDisk Information:\")\n",
    "    print(f\"  Total: {disk.total / (1024**3):.1f} GB\")\n",
    "    print(f\"  Available: {disk.free / (1024**3):.1f} GB\")\n",
    "    print(f\"  Used: {disk.used / (1024**3):.1f} GB ({disk.percent}%)\")\n",
    "    \n",
    "    # Recommendations based on resources\n",
    "    print(\"\\nRecommendations:\")\n",
    "    if memory.available / (1024**3) < 8:\n",
    "        print(\"  - Limited memory available. Consider using smaller models or batch sizes.\")\n",
    "    else:\n",
    "        print(\"  - Sufficient memory for most transformer models.\")\n",
    "    \n",
    "    if disk.free / (1024**3) < 20:\n",
    "        print(\"  - Limited disk space. May need to clean up cached models.\")\n",
    "    else:\n",
    "        print(\"  - Sufficient disk space for model storage.\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"psutil not installed. Cannot check system resources.\")\n",
    "    print(\"Install with: pip install psutil\")\n",
    "except Exception as e:\n",
    "    print(f\"Resource check failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Environment Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate environment summary\n",
    "print(\"Environment Setup Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Collect status\n",
    "checks = {\n",
    "    \"Python Version\": python_version >= required_version,\n",
    "    \"Project Structure\": len(missing_dirs) == 0,\n",
    "    \"Core Dependencies\": len(missing_packages) == 0,\n",
    "    \"GPU Available\": 'cuda_available' in locals() and cuda_available,\n",
    "    \"Project Imports\": len(import_errors) == 0,\n",
    "    \"Configuration\": 'config_loader' in locals(),\n",
    "    \"Data Pipeline\": 'dataset' in locals(),\n",
    "    \"Model Loading\": 'tokenizer' in locals()\n",
    "}\n",
    "\n",
    "print(\"\\nStatus Report:\")\n",
    "for check_name, passed in checks.items():\n",
    "    status = \"READY\" if passed else \"NEEDS ATTENTION\"\n",
    "    print(f\"  {check_name:<20}: {status}\")\n",
    "\n",
    "# Overall readiness\n",
    "all_passed = all(checks.values())\n",
    "critical_passed = checks[\"Python Version\"] and checks[\"Core Dependencies\"]\n",
    "\n",
    "print(\"\\nOverall Status:\")\n",
    "if all_passed:\n",
    "    print(\"  Environment is fully configured and ready for development.\")\n",
    "elif critical_passed:\n",
    "    print(\"  Critical components are ready. Some optional features may need configuration.\")\n",
    "else:\n",
    "    print(\"  Environment needs configuration. Please address the issues above.\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. If any dependencies are missing, install them using pip\")\n",
    "print(\"  2. Run data preparation scripts to download and process AG News dataset\")\n",
    "print(\"  3. Configure GPU support if available for faster training\")\n",
    "print(\"  4. Review the project documentation in docs/ directory\")\n",
    "print(\"  5. Start with the data exploration notebook (01_data_exploration.ipynb)\")\n",
    "\n",
    "# Save environment report\n",
    "from datetime import datetime\n",
    "report = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"python_version\": f\"{python_version.major}.{python_version.minor}.{python_version.micro}\",\n",
    "    \"platform\": platform.platform(),\n",
    "    \"checks\": {k: bool(v) for k, v in checks.items()},\n",
    "    \"gpu_available\": 'cuda_available' in locals() and cuda_available\n",
    "}\n",
    "\n",
    "import json\n",
    "report_path = PROJECT_ROOT / \"outputs\" / \"setup\" / \"environment_report.json\"\n",
    "report_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"\\nEnvironment report saved to: {report_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
