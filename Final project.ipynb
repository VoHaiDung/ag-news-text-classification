{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Transfer Learning with VGG16\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TASK 1: Print the version of TensorFlow =====\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and hyperparameters\n",
    "\n",
    "train_dir      = 'data/train'\n",
    "validation_dir = 'data/validation'\n",
    "test_dir       = 'data/test'\n",
    "\n",
    "IMG_HEIGHT  = 224\n",
    "IMG_WIDTH   = 224\n",
    "BATCH_SIZE  = 32\n",
    "NUM_CLASSES = len(os.listdir(train_dir))\n",
    "EPOCHS      = 10\n",
    "\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generators\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen       = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TASK 2: Create test_generator using test_datagen =====\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "print(\"test_generator created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TASK 3: Print the length of train_generator =====\n",
    "\n",
    "print(\"Length of train_generator:\", len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Extract-Features Model (VGG16 frozen)\n",
    "\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "extract_feat_model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TASK 4: Print the summary of the model =====\n",
    "\n",
    "extract_feat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TASK 5: Compile the model =====\n",
    "\n",
    "extract_feat_model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"Model compiled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Extract-Features Model\n",
    "\n",
    "extract_feat_history = extract_feat_model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TASK 6: Plot accuracy curves for training and validation (extract_feat_model) =====\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(extract_feat_history.history['accuracy'],    label='Training Accuracy')\n",
    "plt.plot(extract_feat_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Extract Features Model — Accuracy Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build & Train Fine-Tuned Model\n",
    "\n",
    "fine_tune_model = tf.keras.models.clone_model(extract_feat_model)\n",
    "fine_tune_model.set_weights(extract_feat_model.get_weights())\n",
    "\n",
    "for layer in fine_tune_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "for layer in fine_tune_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "fine_tune_model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "fine_tune_history = fine_tune_model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TASK 7: Plot loss curves for training and validation (fine_tune_model) =====\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(fine_tune_history.history['loss'],     label='Training Loss')\n",
    "plt.plot(fine_tune_history.history['val_loss'],  label='Validation Loss')\n",
    "plt.title('Fine-Tuned Model — Loss Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TASK 8: Plot accuracy curves for training and validation (fine_tune_model) =====\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(fine_tune_history.history['accuracy'],    label='Training Accuracy')\n",
    "plt.plot(fine_tune_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Fine-Tuned Model — Accuracy Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: predict & plot a single test image\n",
    "\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "def plot_test_image(model, model_name, index_to_plot=1):\n",
    "    test_generator.reset()\n",
    "    imgs, labels = next(test_generator)\n",
    "    while index_to_plot >= len(imgs):\n",
    "        more_imgs, more_labels = next(test_generator)\n",
    "        imgs   = np.concatenate([imgs,   more_imgs])\n",
    "        labels = np.concatenate([labels, more_labels])\n",
    "\n",
    "    img   = imgs[index_to_plot]\n",
    "    label = labels[index_to_plot]\n",
    "\n",
    "    pred       = model.predict(np.expand_dims(img, axis=0))\n",
    "    pred_class = class_labels[np.argmax(pred)]\n",
    "    true_class = class_labels[np.argmax(label)]\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{model_name}\\nTrue: {true_class}  |  Predicted: {pred_class}\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TASK 9: Plot a test image using Extract Features Model (index_to_plot = 1) =====\n",
    "\n",
    "plot_test_image(extract_feat_model,\n",
    "                model_name='Extract Features Model',\n",
    "                index_to_plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TASK 10: Plot a test image using Fine-Tuned Model (index_to_plot = 1) =====\n",
    "\n",
    "plot_test_image(fine_tune_model,\n",
    "                model_name='Fine-Tuned Model',\n",
    "                index_to_plot=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
