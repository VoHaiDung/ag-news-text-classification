{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Data Loading and Augmentation Using Keras\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing packages if needed\n",
    "!pip install scikit-learn pillow matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './images_dataSAT/'\n",
    "dir_non_agri = os.path.join(base_dir, 'class_0_non_agri')\n",
    "dir_agri = os.path.join(base_dir, 'class_1_agri')\n",
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Create the list all_image_paths containing the full file paths of all images from both class_0_non_agri and class_1_agri directories in the base directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Create all_image_paths\n",
    "non_agri_paths = sorted(glob.glob(os.path.join(dir_non_agri, '*')))\n",
    "agri_paths = sorted(glob.glob(os.path.join(dir_agri, '*')))\n",
    "\n",
    "all_image_paths = non_agri_paths + agri_paths\n",
    "\n",
    "# Create corresponding labels: 0 for non-agri, 1 for agri\n",
    "non_agri_labels = [0] * len(non_agri_paths)\n",
    "agri_labels = [1] * len(agri_paths)\n",
    "all_labels = non_agri_labels + agri_labels\n",
    "\n",
    "print('Total non-agricultural images:', len(non_agri_paths))\n",
    "print('Total agricultural images:', len(agri_paths))\n",
    "print('Total images in all_image_paths:', len(all_image_paths))\n",
    "print('Total labels:', len(all_labels))\n",
    "print('First 3 paths:', all_image_paths[:3])\n",
    "print('Last 3 paths:', all_image_paths[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Create a temporary list temp by binding the image paths and labels using the zip function. Next, randomly select and print 5 image paths and their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Create temp list using zip and randomly display 5 samples\n",
    "temp = list(zip(all_image_paths, all_labels))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(temp)\n",
    "\n",
    "random_samples = random.sample(temp, 5)\n",
    "\n",
    "print('5 Randomly Selected Image Paths and Labels:')\n",
    "print('=' * 60)\n",
    "for i, (path, label) in enumerate(random_samples):\n",
    "    label_name = 'Agricultural' if label == 1 else 'Non-Agricultural'\n",
    "    print(f'{i+1}. Path: {path}')\n",
    "    print(f'   Label: {label} ({label_name})')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip shuffled data and split into train/validation\n",
    "all_image_paths_shuffled, all_labels_shuffled = zip(*temp)\n",
    "all_image_paths_shuffled = list(all_image_paths_shuffled)\n",
    "all_labels_shuffled = list(all_labels_shuffled)\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    all_image_paths_shuffled, all_labels_shuffled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print('Training samples:', len(train_paths))\n",
    "print('Validation samples:', len(val_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load and resize image using PIL (replaces tensorflow load_img/img_to_array)\n",
    "def load_and_preprocess_image(image_path, target_size=(64, 64)):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize(target_size)\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Define the custom_data_generator function\n",
    "def custom_data_generator(image_paths, labels, batch_size, img_size=(64, 64), augment=False):\n",
    "    num_samples = len(image_paths)\n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "            for idx in batch_indices:\n",
    "                img_array = load_and_preprocess_image(image_paths[idx], target_size=img_size)\n",
    "                if augment:\n",
    "                    if np.random.random() > 0.5:\n",
    "                        img_array = np.fliplr(img_array)\n",
    "                    if np.random.random() > 0.5:\n",
    "                        img_array = np.flipud(img_array)\n",
    "                batch_images.append(img_array)\n",
    "                batch_labels.append(labels[idx])\n",
    "            yield np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "print('custom_data_generator function defined successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Generate a data batch of size 8 using the custom_data_generator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Generate a batch of training data with batch_size = 8\n",
    "train_generator = custom_data_generator(train_paths, train_labels, batch_size=8, img_size=(64, 64), augment=True)\n",
    "\n",
    "batch_images, batch_labels = next(train_generator)\n",
    "\n",
    "print('Batch images shape:', batch_images.shape)\n",
    "print('Batch labels shape:', batch_labels.shape)\n",
    "print('Batch labels:', batch_labels)\n",
    "\n",
    "fig, axes = plt.subplots(1, 8, figsize=(20, 4))\n",
    "for i in range(8):\n",
    "    axes[i].imshow(batch_images[i])\n",
    "    label_name = 'Agri' if batch_labels[i] == 1 else 'Non-Agri'\n",
    "    axes[i].set_title(f'Label: {batch_labels[i]}\\n({label_name})')\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle('Training Batch (batch_size=8)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Create the validation data using a batch size of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Create validation data with batch_size = 8\n",
    "val_generator = custom_data_generator(val_paths, val_labels, batch_size=8, img_size=(64, 64), augment=False)\n",
    "\n",
    "val_batch_images, val_batch_labels = next(val_generator)\n",
    "\n",
    "print('Validation batch images shape:', val_batch_images.shape)\n",
    "print('Validation batch labels shape:', val_batch_labels.shape)\n",
    "print('Validation batch labels:', val_batch_labels)\n",
    "\n",
    "fig, axes = plt.subplots(1, 8, figsize=(20, 4))\n",
    "for i in range(8):\n",
    "    axes[i].imshow(val_batch_images[i])\n",
    "    label_name = 'Agri' if val_batch_labels[i] == 1 else 'Non-Agri'\n",
    "    axes[i].set_title(f'Label: {val_batch_labels[i]}\\n({label_name})')\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle('Validation Batch (batch_size=8)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## All 4 tasks completed successfully."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
