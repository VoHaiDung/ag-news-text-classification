{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AG News Text Classification","text":"[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE) [![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/) [![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/) [![Transformers](https://img.shields.io/badge/\ud83e\udd17_Transformers-4.30+-yellow.svg)](https://huggingface.co/transformers/) [![arXiv](https://img.shields.io/badge/arXiv-2025.xxxxx-b31b1b.svg)](https://arxiv.org/) [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)"},{"location":"#introduction","title":"Introduction","text":""},{"location":"#1-theoretical-foundations-and-problem-formulation","title":"1. Theoretical Foundations and Problem Formulation","text":""},{"location":"#11-text-classification-as-supervised-learning","title":"1.1 Text Classification as Supervised Learning","text":"<p>Text classification constitutes a fundamental supervised learning problem where the objective is to learn a mapping function from textual inputs to predefined categorical labels, optimizing for generalization to unseen instances drawn from the same underlying distribution.</p> <p>Formal Problem Definition</p> <p>Let \\(\\mathcal{X}\\) denote the space of all possible text documents, and \\(\\mathcal{Y} = \\{y_1, y_2, \\ldots, y_K\\}\\) represent a finite set of \\(K\\) predefined classes. We are provided with a training dataset:</p> \\[ \\mathcal{D} = \\{(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)\\} \\] <p>consisting of \\(N\\) labeled examples, where each \\(x_i \\in \\mathcal{X}\\) is a text document and \\(y_i \\in \\mathcal{Y}\\) is its corresponding class label.</p> <p>The learning objective is to find a function \\(f: \\mathcal{X} \\rightarrow \\mathcal{Y}\\) that minimizes the expected risk (generalization error):</p> \\[ R(f) = \\mathbb{E}_{(x,y) \\sim P} [\\ell(f(x), y)] \\] <p>where: - \\(P\\) is the unknown joint probability distribution over \\(\\mathcal{X} \\times \\mathcal{Y}\\) from which data are sampled - \\(\\ell: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}^+\\) is a loss function measuring prediction error - \\(\\mathbb{E}\\) denotes the expectation over the data distribution</p> <p>Commonly used loss functions:</p> <ul> <li> <p>0-1 Loss (classification accuracy):   \\(\\(\\ell_{0-1}(f(x), y) = \\mathbb{I}[f(x) \\neq y] = \\begin{cases} 0 &amp; \\text{if } f(x) = y \\\\ 1 &amp; \\text{if } f(x) \\neq y \\end{cases}\\)\\)</p> </li> <li> <p>Cross-Entropy Loss (for probabilistic predictions):   \\(\\(\\ell_{CE}(f(x), y) = -\\log P(y \\mid x; f)\\)\\)</p> </li> </ul> <p>Since the true distribution \\(P\\) is unknown and inaccessible, we instead minimize the empirical risk (training error) computed on the observed dataset:</p> \\[ R_{\\text{emp}}(f) = \\frac{1}{N} \\sum_{i=1}^{N} \\ell(f(x_i), y_i) \\] <p>The Fundamental Challenge: Overfitting</p> <p>The core tension in supervised learning is the bias-variance-covariance decomposition. For squared loss in regression, the expected error decomposes as:</p> \\[ \\mathbb{E}[(f(x) - y)^2] = \\text{Bias}^2 + \\text{Variance} + \\text{Irreducible Error} \\] <p>where: - Bias: Error from incorrect assumptions in the learning algorithm (underfitting) - Variance: Error from sensitivity to small fluctuations in training data (overfitting) - Irreducible Error: Noise inherent in the problem (Bayes error)</p> <p>A model may achieve zero empirical risk (perfect memorization of training data) yet exhibit high expected risk (poor generalization)\u2014the phenomenon of overfitting. This occurs when:</p> \\[ R_{\\text{emp}}(f) \\ll R(f) \\] <p>Quantifying Generalization Gap:</p> <p>Define the generalization gap as:</p> \\[ \\Delta(f) = R(f) - R_{\\text{emp}}(f) \\] <p>Statistical learning theory (Vapnik-Chervonenkis theory) provides upper bounds:</p> \\[ R(f) \\leq R_{\\text{emp}}(f) + \\sqrt{\\frac{d \\log(N/d) + \\log(1/\\delta)}{N}} \\] <p>with probability \\(1-\\delta\\), where \\(d\\) is the VC dimension (model complexity measure). This bound reveals the trade-off: - High capacity (large \\(d\\)): Can fit training data well (low \\(R_{\\text{emp}}\\)) but large generalization gap - Low capacity (small \\(d\\)): Tight bound but may have high \\(R_{\\text{emp}}\\) (underfitting)</p> <p>This work systematically addresses overfitting through: 1. Architectural constraints: Parameter-efficient methods limiting effective capacity 2. Regularization strategies: Explicit penalties on model complexity 3. Ensemble diversity: Reducing variance through model averaging 4. Automated monitoring: Real-time detection of train-validation divergence 5. Test set protection: Rigorous protocols preventing data leakage</p>"},{"location":"#12-unique-challenges-in-text-classification","title":"1.2 Unique Challenges in Text Classification","text":"<p>Text classification poses distinctive challenges differentiating it from other supervised learning domains:</p> <p>Challenge 1: High Dimensionality and Sparsity</p> <p>Natural language exists in an extremely high-dimensional space. For a vocabulary of size \\(|\\mathcal{V}|\\) (typically 30,000-100,000 unique tokens), even the simplest bag-of-words representation creates a \\(|\\mathcal{V}|\\)-dimensional feature vector.</p> <p>Mathematical Representation: For document \\(d\\) containing words \\(w_1, w_2, \\ldots, w_m\\), the bag-of-words vector is:</p> \\[ \\mathbf{x} = [c_1, c_2, \\ldots, c_{|\\mathcal{V}|}]^\\top \\in \\mathbb{R}^{|\\mathcal{V}|} \\] <p>where \\(c_i\\) is the count of word \\(w_i\\) in document \\(d\\).</p> <p>However, any individual document utilizes only a small fraction of the vocabulary, resulting in sparse representations where 95-99% of features are zero.</p> <p>Sparsity Measure: Define document sparsity as:</p> \\[ \\text{Sparsity}(d) = 1 - \\frac{|\\{i : c_i &gt; 0\\}|}{|\\mathcal{V}|} = 1 - \\frac{|d|}{|\\mathcal{V}|} \\] <p>where \\(|d|\\) is the number of unique words in document \\(d\\).</p> <p>Example: A 100-word news article from a 50,000-word vocabulary: - Unique words in document: ~80 (after removing duplicates) - Sparsity: \\(1 - 80/50000 = 0.9984\\) (99.84% zeros)</p> <p>Implications:</p> <ol> <li> <p>Curse of Dimensionality: In high-dimensional spaces, distances become less meaningful. For random points in \\(\\mathbb{R}^d\\), the ratio of maximum to minimum distance approaches 1 as \\(d \\rightarrow \\infty\\):    \\(\\(\\lim_{d \\rightarrow \\infty} \\frac{\\max_i \\|\\mathbf{x}_i - \\mathbf{x}_0\\|}{\\min_i \\|\\mathbf{x}_i - \\mathbf{x}_0\\|} = 1\\)\\)</p> </li> <li> <p>Sample Complexity: Number of samples required to learn grows exponentially with dimensionality. For uniform coverage of feature space with resolution \\(r\\), need \\(O(r^d)\\) samples.</p> </li> <li> <p>Computational Challenges: Matrix operations on 50,000-dimensional vectors require specialized sparse data structures.</p> </li> </ol> <p>Solutions: - Dimensionality Reduction: PCA, LSA project to low-dimensional subspace - Dense Embeddings: Word2Vec, BERT map discrete tokens to continuous \\(\\mathbb{R}^d\\) with \\(d=100-1024\\) - Sparse Operations: Efficient implementations (CSR matrices, sparse attention)</p> <p>Challenge 2: Variable-Length Sequential Structure</p> <p>Unlike fixed-size inputs in image classification (e.g., 224\u00d7224 pixels), text documents vary dramatically in length\u2014from short social media posts (10-20 tokens) to long articles (1,000+ tokens).</p> <p>Sequence Modeling Requirements:</p> <ol> <li> <p>Handle arbitrary length: Architecture must process sequences \\(\\mathbf{x} = [x_1, x_2, \\ldots, x_n]\\) where \\(n\\) varies</p> </li> <li> <p>Capture local patterns: Phrases and n-grams like \"not good\", \"very happy\", \"absolutely terrible\"</p> </li> <li> <p>Model long-range dependencies: Subject-verb agreement across clauses, coreference resolution (pronouns to antecedents)</p> </li> </ol> <p>Approaches:</p> <p>Padding/Truncation: Standardize to fixed length \\(L\\): $$ \\mathbf{x}' = \\begin{cases} [\\mathbf{x}; \\mathbf{0}{L-n}] &amp; \\text{if } n &lt; L \\text{ (pad)} \\ \\mathbf{x} \\end{cases} $$} &amp; \\text{if } n &gt; L \\text{ (truncate)</p> <p>Limitation: Padding introduces noise, truncation loses information.</p> <p>Recurrent Neural Networks: Process sequences step-by-step with hidden state: $$ \\mathbf{h}t = f(\\mathbf{h}_t; \\theta) $$}, \\mathbf{x</p> <p>Limitation: Vanishing gradients for long sequences (gradient magnitude decays as \\(\\gamma^t\\) where \\(\\gamma &lt; 1\\)).</p> <p>Attention Mechanisms: Allow direct connections between all positions (Section 1.3).</p> <p>Challenge 3: Semantic Ambiguity and Context-Dependency</p> <p>Natural language exhibits profound ambiguity at multiple linguistic levels:</p> <p>1. Polysemy: Words with multiple meanings depending on context</p> <p>Example: \"bank\" - Financial institution: \"I deposited money at the bank\" - Land alongside river: \"We sat by the river bank\"</p> <p>2. Synonymy: Different words with identical or near-identical meanings</p> \\[\\text{Synonyms}(\\text{\"quick\"}) = \\{\\text{\"fast\"}, \\text{\"rapid\"}, \\text{\"swift\"}, \\text{\"speedy\"}\\}\\] <p>Traditional models treating words as atomic units cannot recognize semantic equivalence.</p> <p>3. Compositionality: Meaning emerges from word combinations</p> <p>Negation: \"not good\" \u2260 \"good\" (sentiment polarity flip)</p> <p>Modifier effects: \"incredibly boring\" vs. \"incredibly exciting\" (same intensifier, opposite results)</p> <p>Mathematical Framework for Contextualized Representations:</p> <p>Traditional word embeddings assign fixed vectors: \\(\\(w \\mapsto \\mathbf{v}_w \\in \\mathbb{R}^d\\)\\)</p> <p>Contextualized embeddings compute representations dynamically: $$ w_i \\text{ in context } [w_1, \\ldots, w_n] \\mapsto \\mathbf{h}_i = f(w_1, \\ldots, w_n, i; \\theta) \\in \\mathbb{R}^d $$</p> <p>Example: In BERT, \"bank\" receives different representations: - \\(\\mathbf{h}_{\\text{bank}}^{\\text{(financial)}} \\approx \\mathbf{v}_{\\text{money}}, \\mathbf{v}_{\\text{loan}}\\) (cosine similarity &gt; 0.7) - \\(\\mathbf{h}_{\\text{bank}}^{\\text{(river)}} \\approx \\mathbf{v}_{\\text{water}}, \\mathbf{v}_{\\text{shore}}\\) (cosine similarity &gt; 0.7) - \\(\\cos(\\mathbf{h}_{\\text{bank}}^{\\text{(financial)}}, \\mathbf{h}_{\\text{bank}}^{\\text{(river)}}) &lt; 0.3\\) (distinct representations)</p> <p>Challenge 4: Limited Labeled Data vs. Model Capacity</p> <p>State-of-the-art models contain hundreds of millions to billions of parameters: - DeBERTa-v3-XLarge: 710M parameters - Llama 2-70B: 70B parameters</p> <p>while supervised datasets typically contain \\(10^3\\) to \\(10^5\\) labeled examples.</p> <p>Parameter-to-Sample Ratio:</p> \\[ \\rho = \\frac{\\text{Model Parameters}}{\\text{Training Samples}} \\] <p>Critical Threshold: When \\(\\rho &gt; 1\\), severe overfitting risk\u2014model has enough capacity to memorize all training data.</p> <p>Examples: - DeBERTa-v3-XLarge on AG News: \\(\\rho = 710M / 120K \\approx 5917\\) (each parameter sees &lt;0.0002 samples!) - Llama 2-70B on AG News: \\(\\rho = 70B / 120K \\approx 583,333\\)</p> <p>Classical Statistical Learning Theory (Vapnik) suggests sample complexity:</p> \\[ N = O\\left(\\frac{d}{\\epsilon^2}\\right) \\] <p>to achieve error within \\(\\epsilon\\) of optimal, where \\(d\\) is VC dimension (roughly proportional to parameters). For \\(d=710M\\), would need billions of labeled samples for reliable learning!</p> <p>Modern Solutions:</p> <p>1. Transfer Learning: Pre-train on massive unlabeled corpus (billions of tokens), then fine-tune:</p> \\[ \\theta^* = \\arg\\min_{\\theta} \\mathcal{L}_{\\text{downstream}}(\\theta; \\mathcal{D}_{\\text{labeled}}) \\] <p>subject to initialization \\(\\theta_0 = \\theta_{\\text{pretrained}}\\)</p> <p>Intuition: Pre-training learns general language understanding (syntax, semantics, world knowledge); fine-tuning specializes to task.</p> <p>2. Parameter-Efficient Fine-Tuning (PEFT): Update only small subset of parameters:</p> \\[ \\theta_{\\text{trainable}} \\subset \\theta, \\quad |\\theta_{\\text{trainable}}| \\ll |\\theta| \\] <p>Examples:  - LoRA: 0.1-1% of parameters trainable - Adapters: 0.5-3% trainable - Prompt tuning: 0.001-0.1% trainable</p> <p>This dramatically reduces effective capacity, mitigating overfitting.</p> <p>3. Regularization: Explicit complexity penalties:</p> \\[ \\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{task}} + \\lambda \\Omega(\\theta) \\] <p>where \\(\\Omega(\\theta)\\) is regularizer (L2 norm, dropout, etc.).</p> <p>4. Data Augmentation: Synthetically expand training set while preserving label:</p> \\[ |\\mathcal{D}_{\\text{augmented}}| = \\alpha \\cdot |\\mathcal{D}_{\\text{original}}|, \\quad \\alpha \\in [2, 10] \\] <p>through back-translation, paraphrasing, controlled generation.</p>"},{"location":"#2-evolution-of-text-classification-paradigms","title":"2. Evolution of Text Classification Paradigms","text":"<p>The field has progressed through five distinct eras, each introducing fundamental innovations in representation learning and model architectures.</p>"},{"location":"#phase-1-classical-machine-learning-1990s-2010","title":"Phase 1: Classical Machine Learning (1990s-2010)","text":"<p>Core Paradigm: Transform text into fixed-dimensional feature vectors through manual engineering, then apply traditional classifiers.</p> <p>Representation Method 1: Bag-of-Words (BoW)</p> <p>Represent document as unordered collection of word counts, completely ignoring grammar, word order, and syntax.</p> <p>Mathematical Formulation: For document \\(d\\) with vocabulary \\(\\mathcal{V} = \\{w_1, w_2, \\ldots, w_{|\\mathcal{V}|}\\}\\):</p> \\[ \\text{BoW}(d) = [c(w_1, d), c(w_2, d), \\ldots, c(w_{|\\mathcal{V}|}, d)]^\\top \\in \\mathbb{R}^{|\\mathcal{V}|} \\] <p>where \\(c(w_i, d)\\) is the count of word \\(w_i\\) in document \\(d\\).</p> <p>Example: - Document: \"The cat sat on the mat\" - Vocabulary: \\(\\mathcal{V} = \\{\\text{the, cat, sat, on, mat, dog}\\}\\) - BoW vector: \\([2, 1, 1, 1, 1, 0]^\\top\\) (word \"the\" appears twice)</p> <p>Normalization Variants:</p> <p>Binary BoW (presence/absence): \\(\\(\\text{BoW}_{\\text{binary}}(d) = [\\mathbb{I}[c(w_1, d) &gt; 0], \\ldots, \\mathbb{I}[c(w_{|\\mathcal{V}|}, d) &gt; 0]]^\\top\\)\\)</p> <p>Normalized BoW (term frequency): \\(\\(\\text{BoW}_{\\text{norm}}(d) = \\left[\\frac{c(w_1, d)}{|d|}, \\ldots, \\frac{c(w_{|\\mathcal{V}|}, d)}{|d|}\\right]^\\top\\)\\)</p> <p>where \\(|d| = \\sum_i c(w_i, d)\\) is total word count.</p> <p>Critical Limitation: Word order is completely lost. The sentences: - \"The cat sat on the mat\" - \"The mat sat on the cat\"</p> <p>produce identical BoW representations \\([2, 1, 1, 1, 1, 0]^\\top\\), despite having completely different meanings.</p> <p>Representation Method 2: TF-IDF (Term Frequency-Inverse Document Frequency)</p> <p>Weight words by importance\u2014frequent in this document but rare across corpus\u2014to identify discriminative terms.</p> <p>Mathematical Formulation: For term \\(t\\) in document \\(d\\) from corpus \\(\\mathcal{C}\\) of \\(N\\) documents:</p> \\[ \\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t) \\] <p>where:</p> <p>Term Frequency (normalized count): $$ \\text{TF}(t, d) = \\frac{c(t, d)}{\\sum_{t' \\in d} c(t', d)} = \\frac{c(t, d)}{|d|} $$</p> <p>Inverse Document Frequency (logarithmic scaling): $$ \\text{IDF}(t) = \\log \\frac{N}{\\text{DF}(t)} = \\log \\frac{N}{|{d \\in \\mathcal{C} : t \\in d}|} $$</p> <p>where \\(\\text{DF}(t)\\) is the number of documents containing term \\(t\\).</p> <p>Intuition Behind IDF:</p> <ul> <li>High IDF (\\(\\text{DF}(t)\\) small): Term appears in few documents \u2192 discriminative power</li> <li>Example: \"photosynthesis\" appears in 50 out of 10,000 documents</li> <li> <p>\\(\\text{IDF}(\\text{\"photosynthesis\"}) = \\log(10000/50) = \\log(200) \\approx 5.3\\)</p> </li> <li> <p>Low IDF (\\(\\text{DF}(t)\\) large): Term appears in most documents \u2192 little discriminative power</p> </li> <li>Example: \"the\" appears in 9,950 out of 10,000 documents</li> <li>\\(\\text{IDF}(\\text{\"the\"}) = \\log(10000/9950) \\approx 0.005\\)</li> </ul> <p>Complete TF-IDF Example:</p> <p>Corpus: 10,000 news articles Document A (500 words): \"election\" appears 50 times, appears in 100 documents total</p> \\[ \\begin{aligned} \\text{TF}(\\text{\"election\"}, A) &amp;= \\frac{50}{500} = 0.1 \\\\ \\text{IDF}(\\text{\"election\"}) &amp;= \\log\\frac{10000}{100} = \\log(100) \\approx 4.605 \\\\ \\text{TF-IDF}(\\text{\"election\"}, A) &amp;= 0.1 \\times 4.605 = 0.461 \\end{aligned} \\] <p>Document Vector: Full TF-IDF representation:</p> \\[ \\mathbf{x}_d = [\\text{TF-IDF}(w_1, d), \\ldots, \\text{TF-IDF}(w_{|\\mathcal{V}|}, d)]^\\top \\in \\mathbb{R}^{|\\mathcal{V}|} \\] <p>Variants:</p> <p>Sublinear TF Scaling (dampen effect of very frequent terms): \\(\\(\\text{TF}_{\\text{log}}(t, d) = 1 + \\log c(t, d)\\)\\)</p> <p>Smoothed IDF (prevent division by zero): \\(\\(\\text{IDF}_{\\text{smooth}}(t) = \\log \\frac{N + 1}{\\text{DF}(t) + 1} + 1\\)\\)</p> <p>Classification Algorithm 1: Naive Bayes Classifier</p> <p>Core Assumption: Features (words) are conditionally independent given the class label\u2014a \"naive\" assumption severely violated in natural language.</p> <p>Theoretical Foundation (Bayes' Theorem):</p> \\[ P(y \\mid \\mathbf{x}) = \\frac{P(\\mathbf{x} \\mid y) \\cdot P(y)}{P(\\mathbf{x})} \\] <p>where: - \\(P(y \\mid \\mathbf{x})\\): Posterior probability of class \\(y\\) given features \\(\\mathbf{x}\\) - \\(P(\\mathbf{x} \\mid y)\\): Likelihood of observing features \\(\\mathbf{x}\\) in class \\(y\\) - \\(P(y)\\): Prior probability of class \\(y\\) - \\(P(\\mathbf{x})\\): Evidence (constant for all classes)</p> <p>Naive Independence Assumption:</p> <p>For features \\(\\mathbf{x} = [x_1, x_2, \\ldots, x_n]\\):</p> \\[ P(\\mathbf{x} \\mid y) = P(x_1, x_2, \\ldots, x_n \\mid y) \\stackrel{\\text{naive}}{=} \\prod_{i=1}^{n} P(x_i \\mid y) \\] <p>This assumes features are independent given class label: \\(\\(P(x_i \\mid x_j, y) = P(x_i \\mid y) \\quad \\forall i \\neq j\\)\\)</p> <p>Classification Decision Rule:</p> <p>Since \\(P(\\mathbf{x})\\) is constant, maximize posterior probability:</p> \\[ \\hat{y} = \\arg\\max_{y \\in \\mathcal{Y}} P(y) \\prod_{i=1}^{n} P(x_i \\mid y) \\] <p>Taking logarithm for numerical stability:</p> \\[ \\hat{y} = \\arg\\max_{y \\in \\mathcal{Y}} \\left[ \\log P(y) + \\sum_{i=1}^{n} \\log P(x_i \\mid y) \\right] \\] <p>Parameter Estimation from Training Data:</p> <p>Prior Probability (class frequency): $$ P(y) = \\frac{\\text{Number of documents in class } y}{\\text{Total number of documents}} = \\frac{N_y}{N} $$</p> <p>Likelihood (word frequency in class): $$ P(x_i \\mid y) = \\frac{\\text{Count of feature } x_i \\text{ in class } y}{\\text{Total features in class } y} = \\frac{c(x_i, y)}{\\sum_{x' \\in \\mathcal{V}} c(x', y)} $$</p> <p>Laplace Smoothing (handle zero counts):</p> \\[ P(x_i \\mid y) = \\frac{c(x_i, y) + \\alpha}{\\sum_{x' \\in \\mathcal{V}} [c(x', y) + \\alpha]} = \\frac{c(x_i, y) + \\alpha}{N_y + \\alpha |\\mathcal{V}|} \\] <p>where \\(\\alpha &gt; 0\\) is smoothing parameter (typically \\(\\alpha = 1\\)).</p> <p>Concrete Example:</p> <p>Training data: - 100 sports articles, 100 politics articles - Word \"goal\" appears 50 times in sports, 5 times in politics - Total words in sports: 10,000; in politics: 10,000</p> <p>Probability Calculations:</p> \\[ \\begin{aligned} P(\\text{sports}) &amp;= \\frac{100}{200} = 0.5 \\\\ P(\\text{politics}) &amp;= \\frac{100}{200} = 0.5 \\\\ P(\\text{\"goal\"} \\mid \\text{sports}) &amp;= \\frac{50}{10000} = 0.005 \\\\ P(\\text{\"goal\"} \\mid \\text{politics}) &amp;= \\frac{5}{10000} = 0.0005 \\end{aligned} \\] <p>Likelihood Ratio: \\(\\(\\frac{P(\\text{\"goal\"} \\mid \\text{sports})}{P(\\text{\"goal\"} \\mid \\text{politics})} = \\frac{0.005}{0.0005} = 10\\)\\)</p> <p>The word \"goal\" is 10\u00d7 more likely in sports articles\u2014strong discriminative signal.</p> <p>Advantages: 1. Computational Efficiency: Training is \\(O(N \\cdot |\\mathcal{V}|)\\) (simple counting) 2. Low Sample Complexity: Works with small datasets (few parameters: \\(K \\times |\\mathcal{V}|\\) probabilities) 3. Interpretable: Can inspect \\(P(word \\mid class)\\) to understand decisions 4. Probabilistic Outputs: Provides confidence scores, not just hard classifications</p> <p>Limitations: 1. Independence Assumption Violated: Words are highly correlated in natural language    - \"New York\" treated as independent \"New\" and \"York\"    - Cannot capture phrases like \"not good\" 2. No Word Order: \"dog bites man\" vs. \"man bites dog\" have identical representation 3. Zero-Frequency Problem: If word never appears in class during training, \\(P(word \\mid class) = 0\\) makes entire probability zero</p> <p>Classification Algorithm 2: Support Vector Machines (SVM)</p> <p>Core Idea: Find the hyperplane that maximally separates classes in feature space, maximizing the margin (distance to nearest points).</p> <p>Binary Classification Formulation:</p> <p>For linearly separable data \\(\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N\\) where \\(y_i \\in \\{-1, +1\\}\\), find hyperplane:</p> \\[ \\mathbf{w}^\\top \\mathbf{x} + b = 0 \\] <p>that satisfies: $$ y_i(\\mathbf{w}^\\top \\mathbf{x}_i + b) \\geq 1 \\quad \\forall i $$</p> <p>Geometric Margin: Distance from hyperplane to nearest point:</p> \\[ \\gamma = \\min_i \\frac{|\\ \\mathbf{w}^\\top \\mathbf{x}_i + b|}{|\\mathbf{w}|} = \\frac{1}{|\\mathbf{w}|} \\] <p>Optimization Objective: Maximize margin \\(\\Leftrightarrow\\) Minimize \\(|\\mathbf{w}|\\):</p> \\[ \\begin{aligned} \\min_{\\mathbf{w}, b} \\quad &amp; \\frac{1}{2} \\|\\mathbf{w}\\|^2 \\\\ \\text{subject to} \\quad &amp; y_i(\\mathbf{w}^\\top \\mathbf{x}_i + b) \\geq 1, \\quad i = 1, \\ldots, N \\end{aligned} \\] <p>Soft-Margin SVM (allow misclassifications for non-separable data):</p> <p>Introduce slack variables \\(\\xi_i \\geq 0\\) measuring constraint violations:</p> \\[ \\begin{aligned} \\min_{\\mathbf{w}, b, \\boldsymbol{\\xi}} \\quad &amp; \\frac{1}{2} \\|\\mathbf{w}\\|^2 + C \\sum_{i=1}^N \\xi_i \\\\ \\text{subject to} \\quad &amp; y_i(\\mathbf{w}^\\top \\mathbf{x}_i + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0, \\quad i = 1, \\ldots, N \\end{aligned} \\] <p>where: - \\(C &gt; 0\\): Regularization parameter balancing margin maximization vs. training error   - Large \\(C\\): Penalize violations heavily (small margin, low training error, high risk of overfitting)   - Small \\(C\\): Allow more violations (large margin, higher training error, better generalization)</p> <p>Dual Formulation (enables kernel trick):</p> <p>Using Lagrange multipliers \\(\\alpha_i \\geq 0\\):</p> \\[ \\begin{aligned} \\max_{\\boldsymbol{\\alpha}} \\quad &amp; \\sum_{i=1}^N \\alpha_i - \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j \\mathbf{x}_i^\\top \\mathbf{x}_j \\\\ \\text{subject to} \\quad &amp; 0 \\leq \\alpha_i \\leq C, \\quad \\sum_{i=1}^N \\alpha_i y_i = 0 \\end{aligned} \\] <p>Decision Function:</p> \\[ f(\\mathbf{x}) = \\text{sign}\\left(\\sum_{i=1}^N \\alpha_i y_i \\mathbf{x}_i^\\top \\mathbf{x} + b\\right) \\] <p>Support Vectors: Training points with \\(\\alpha_i &gt; 0\\) (lie on margin boundary or violate it). Only these points determine the decision boundary\u2014most training data can be discarded!</p> <p>The Kernel Trick: Map data to higher-dimensional space where linear separation is possible, without explicitly computing the mapping.</p> <p>Kernel Function:  \\(\\(K(\\mathbf{x}, \\mathbf{x}') = \\langle \\phi(\\mathbf{x}), \\phi(\\mathbf{x}') \\rangle\\)\\)</p> <p>where \\(\\phi: \\mathbb{R}^d \\rightarrow \\mathbb{R}^D\\) maps to (possibly infinite-dimensional) feature space.</p> <p>Decision Function with Kernels:</p> \\[ f(\\mathbf{x}) = \\text{sign}\\left(\\sum_{i=1}^N \\alpha_i y_i K(\\mathbf{x}_i, \\mathbf{x}) + b\\right) \\] <p>Common Kernels:</p> <p>Linear Kernel (no transformation): \\(\\(K(\\mathbf{x}, \\mathbf{x}') = \\mathbf{x}^\\top \\mathbf{x}'\\)\\)</p> <p>Polynomial Kernel (degree \\(d\\)): \\(\\(K(\\mathbf{x}, \\mathbf{x}') = (\\gamma \\mathbf{x}^\\top \\mathbf{x}' + r)^d\\)\\)</p> <p>Radial Basis Function (RBF/Gaussian) Kernel: \\(\\(K(\\mathbf{x}, \\mathbf{x}') = \\exp\\left(-\\gamma \\|\\mathbf{x} - \\mathbf{x}'\\|^2\\right)\\)\\)</p> <p>where \\(\\gamma = \\frac{1}{2\\sigma^2}\\) controls smoothness.</p> <p>Example: Linear kernel cannot separate XOR problem: - Points: \\((0,0) \\rightarrow -1\\), \\((0,1) \\rightarrow +1\\), \\((1,0) \\rightarrow +1\\), \\((1,1) \\rightarrow -1\\)</p> <p>But polynomial kernel of degree 2 maps to 3D space where linear separation exists.</p> <p>Advantages: 1. Effective in High Dimensions: Text data with 50,000+ dimensions 2. Memory Efficient: Only store support vectors (typically 10-30% of training data) 3. Kernel Flexibility: Can handle non-linear decision boundaries 4. Theoretical Guarantees: Maximum margin reduces generalization error (VC theory)</p> <p>Limitations: 1. Computational Complexity: Training is \\(O(N^2)\\) to \\(O(N^3)\\) (quadratic programming)    - Prohibitive for \\(N &gt; 100,000\\) (modern datasets have millions) 2. Hyperparameter Sensitivity: Requires careful tuning of \\(C\\), \\(\\gamma\\) (kernel parameters) 3. No Probabilistic Interpretation: Outputs decision values, not probabilities    - (Platt scaling can calibrate to probabilities post-hoc) 4. Binary Classification: Requires one-vs-rest or one-vs-one decomposition for multi-class</p> <p>Classification Algorithm 3: Logistic Regression</p> <p>Core Idea: Model posterior class probability using the logistic (sigmoid) function, ensuring outputs lie in \\([0, 1]\\).</p> <p>Binary Logistic Regression:</p> <p>For binary classification \\(y \\in \\{0, 1\\}\\):</p> \\[ P(y = 1 \\mid \\mathbf{x}; \\mathbf{w}, b) = \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b) = \\frac{1}{1 + \\exp(-(\\mathbf{w}^\\top \\mathbf{x} + b))} \\] <p>where \\(\\sigma(z)\\) is the sigmoid function:</p> \\[ \\sigma(z) = \\frac{1}{1 + e^{-z}} = \\frac{e^z}{1 + e^z} \\] <p>Sigmoid Properties: - \\(\\sigma(0) = 0.5\\) (decision boundary) - \\(\\lim_{z \\to \\infty} \\sigma(z) = 1\\) - \\(\\lim_{z \\to -\\infty} \\sigma(z) = 0\\) - \\(\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))\\) (convenient for gradient computation)</p> <p>Multi-Class Extension (Softmax Regression):</p> <p>For \\(K\\) classes, define linear score for each class:</p> \\[ z_k = \\mathbf{w}_k^\\top \\mathbf{x} + b_k, \\quad k = 1, \\ldots, K \\] <p>Apply softmax function to convert scores to probability distribution:</p> \\[ P(y = k \\mid \\mathbf{x}; \\mathbf{W}, \\mathbf{b}) = \\frac{\\exp(z_k)}{\\sum_{j=1}^K \\exp(z_j)} = \\frac{\\exp(\\mathbf{w}_k^\\top \\mathbf{x} + b_k)}{\\sum_{j=1}^K \\exp(\\mathbf{w}_j^\\top \\mathbf{x} + b_j)} \\] <p>Softmax Properties: - \\(\\sum_{k=1}^K P(y = k \\mid \\mathbf{x}) = 1\\) (valid probability distribution) - \\(P(y = k \\mid \\mathbf{x}) \\in (0, 1)\\) (all probabilities positive) - \\(\\arg\\max_k P(y = k \\mid \\mathbf{x}) = \\arg\\max_k z_k\\) (invariant to constant shifts)</p> <p>Training: Maximum Likelihood Estimation</p> <p>Likelihood of observing data \\(\\mathcal{D} = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N\\):</p> \\[ \\mathcal{L}(\\mathbf{W}, \\mathbf{b}) = \\prod_{i=1}^N P(y_i \\mid \\mathbf{x}_i; \\mathbf{W}, \\mathbf{b}) \\] <p>Log-Likelihood (easier to optimize):</p> \\[ \\log \\mathcal{L}(\\mathbf{W}, \\mathbf{b}) = \\sum_{i=1}^N \\log P(y_i \\mid \\mathbf{x}_i; \\mathbf{W}, \\mathbf{b}) \\] <p>Negative Log-Likelihood (Cross-Entropy Loss):</p> \\[ \\mathcal{L}_{\\text{CE}}(\\mathbf{W}, \\mathbf{b}) = -\\sum_{i=1}^N \\log P(y_i \\mid \\mathbf{x}_i; \\mathbf{W}, \\mathbf{b}) \\] <p>For multi-class with one-hot encoding \\(\\mathbf{y}_i = [0, \\ldots, 1, \\ldots, 0]\\) (1 at position \\(y_i\\)):</p> \\[ \\mathcal{L}_{\\text{CE}}(\\mathbf{W}, \\mathbf{b}) = -\\sum_{i=1}^N \\sum_{k=1}^K y_{ik} \\log P(y = k \\mid \\mathbf{x}_i; \\mathbf{W}, \\mathbf{b}) \\] <p>Regularized Objective (prevent overfitting):</p> \\[ \\min_{\\mathbf{W}, \\mathbf{b}} \\quad \\mathcal{L}_{\\text{CE}}(\\mathbf{W}, \\mathbf{b}) + \\lambda \\|\\mathbf{W}\\|_2^2 \\] <p>where \\(\\lambda &gt; 0\\) controls regularization strength (L2 penalty).</p> <p>Optimization: Gradient descent or quasi-Newton methods (L-BFGS)</p> <p>Gradient Computation:</p> \\[ \\frac{\\partial \\mathcal{L}_{\\text{CE}}}{\\partial \\mathbf{w}_k} = \\sum_{i=1}^N (\\hat{y}_{ik} - y_{ik}) \\mathbf{x}_i \\] <p>where \\(\\hat{y}_{ik} = P(y = k \\mid \\mathbf{x}_i)\\) is predicted probability.</p> <p>Advantages: 1. Fast Training: Convex optimization guarantees global optimum 2. Probabilistic Outputs: Well-calibrated confidence scores 3. Interpretable: Weight \\(w_k^{(j)}\\) shows contribution of feature \\(j\\) to class \\(k\\) 4. Regularization: L1 (Lasso) induces sparsity, L2 (Ridge) prevents overfitting</p> <p>Limitations: 1. Linear Decision Boundaries: Cannot model XOR-like patterns without feature engineering 2. Feature Independence Assumption: Like Naive Bayes, assumes features are independent 3. Requires Feature Engineering: Manual construction of informative features (n-grams, POS tags)</p> <p>Fundamental Limitation of All Classical Methods:</p> <p>All these approaches treat words as atomic units with fixed representations, failing to capture:</p> <ol> <li>Semantic Similarity: \"car\" and \"automobile\" are treated as completely different features despite identical meaning</li> <li>Contextual Meaning: \"bank\" receives the same representation in \"financial bank\" vs. \"river bank\"</li> <li>Compositional Semantics: \"not good\" is represented as independent \"not\" and \"good\", losing the negation relationship</li> </ol> <p>This motivated the paradigm shift to learned distributed representations in Phase 2.</p>"},{"location":"#phase-2-neural-embeddings-and-deep-learning-2010-2017","title":"Phase 2: Neural Embeddings and Deep Learning (2010-2017)","text":"<p>Revolutionary Insight: The Distributional Hypothesis</p> <p>\"You shall know a word by the company it keeps\" \u2014 J.R. Firth (1957)</p> <p>Words appearing in similar contexts should have similar meanings. This principle enables learning dense vector representations from word co-occurrence patterns in large unlabeled corpora.</p> <p>Paradigm Shift: Instead of treating words as atomic symbols with arbitrary IDs, represent them as continuous vectors in a learned semantic space where geometric relationships correspond to semantic relationships.</p> <p>Word2Vec: Neural Embedding Learning (Mikolov et al., 2013)</p> <p>Two complementary architectures for learning distributed word representations:</p> <p>Architecture 1: Continuous Bag-of-Words (CBOW)</p> <p>Objective: Predict center word from surrounding context words.</p> <p>Given context window of size \\(c\\), predict target word \\(w_t\\) from context \\(\\{w_{t-c}, \\ldots, w_{t-1}, w_{t+1}, \\ldots, w_{t+c}\\}\\).</p> <p>Model Architecture:</p> <ol> <li> <p>Input Layer: One-hot encoded context words \\(\\mathbf{x}_{t-c}, \\ldots, \\mathbf{x}_{t-1}, \\mathbf{x}_{t+1}, \\ldots, \\mathbf{x}_{t+c} \\in \\{0,1\\}^{|\\mathcal{V}|}\\)</p> </li> <li> <p>Embedding Layer: Map to dense vectors via embedding matrix \\(\\mathbf{E} \\in \\mathbb{R}^{d \\times |\\mathcal{V}|}\\):    \\(\\(\\mathbf{v}_{t+j} = \\mathbf{E} \\mathbf{x}_{t+j} \\in \\mathbb{R}^d\\)\\)</p> </li> <li> <p>Context Representation: Average context embeddings:    \\(\\(\\mathbf{h} = \\frac{1}{2c} \\sum_{j \\in \\{-c, \\ldots, -1, 1, \\ldots, c\\}} \\mathbf{v}_{t+j}\\)\\)</p> </li> <li> <p>Output Layer: Predict target word via softmax over vocabulary:    \\(\\(P(w_t \\mid \\text{context}) = \\frac{\\exp(\\mathbf{u}_{w_t}^\\top \\mathbf{h})}{\\sum_{w \\in \\mathcal{V}} \\exp(\\mathbf{u}_w^\\top \\mathbf{h})}\\)\\)</p> </li> </ol> <p>where \\(\\mathbf{u}_w \\in \\mathbb{R}^d\\) is the output embedding for word \\(w\\).</p> <p>Training Objective: Maximize log-likelihood over corpus:</p> \\[ \\mathcal{L}_{\\text{CBOW}} = \\sum_{t=1}^T \\log P(w_t \\mid w_{t-c}, \\ldots, w_{t-1}, w_{t+1}, \\ldots, w_{t+c}) \\] <p>Architecture 2: Skip-Gram</p> <p>Objective: Predict context words from center word (inverse of CBOW).</p> <p>Given target word \\(w_t\\), predict each context word \\(w_{t+j}\\) independently.</p> <p>Model: For each context position \\(j \\in \\{-c, \\ldots, -1, 1, \\ldots, c\\}\\):</p> \\[ P(w_{t+j} \\mid w_t) = \\frac{\\exp(\\mathbf{u}_{w_{t+j}}^\\top \\mathbf{v}_{w_t})}{\\sum_{w \\in \\mathcal{V}} \\exp(\\mathbf{u}_w^\\top \\mathbf{v}_{w_t})} \\] <p>where: - \\(\\mathbf{v}_{w_t} \\in \\mathbb{R}^d\\): Input embedding of center word - \\(\\mathbf{u}_{w_{t+j}} \\in \\mathbb{R}^d\\): Output embedding of context word</p> <p>Training Objective: Maximize log-likelihood:</p> \\[ \\mathcal{L}_{\\text{Skip-gram}} = \\sum_{t=1}^T \\sum_{j \\in \\{-c, \\ldots, c\\}, j \\neq 0} \\log P(w_{t+j} \\mid w_t) \\] <p>Computational Challenge: Softmax denominator requires summing over entire vocabulary (50,000+ terms) for each prediction\u2014computationally prohibitive.</p> <p>Solution 1: Hierarchical Softmax</p> <p>Replace flat softmax with binary tree structure (Huffman tree based on word frequency).</p> <p>Probability Computation: Path from root to word \\(w\\) with \\(L(w)\\) nodes:</p> \\[ P(w \\mid w_t) = \\prod_{i=1}^{L(w)-1} \\sigma\\left(\\text{\u27e6} n(w, i+1) = \\text{left}(n(w, i)) \\text{\u27e7} \\cdot \\mathbf{u}_{n(w,i)}^\\top \\mathbf{v}_{w_t}\\right) \\] \\[ P(w \\mid w_t) = \\prod_{i=1}^{L(w)-1} \\sigma\\left(\\llbracket n(w, i+1) = \\text{left}(n(w, i)) \\rrbracket \\cdot \\mathbf{u}_{n(w,i)}^\\top \\mathbf{v}_{w_t}\\right) \\] <p>where: - \\(n(w, i)\\): \\(i\\)-th node on path to word \\(w\\) - \\(\\llbracket \\cdot \\rrbracket\\): Indicator function (1 if true, -1 if false) - \\(\\sigma(z) = 1/(1 + e^{-z})\\): Sigmoid function</p> <p>Complexity Reduction: \\(O(|\\mathcal{V}|) \\rightarrow O(\\log |\\mathcal{V}|)\\) per word</p> <p>Solution 2: Negative Sampling</p> <p>Approximate softmax by discriminating target word from \\(k\\) random \"negative\" samples.</p> <p>Modified Objective: For each target word \\(w_t\\) and context \\(w_c\\), sample \\(k\\) negative words \\(w_i \\sim P_{\\text{noise}}\\):</p> \\[ \\mathcal{L}_{\\text{NEG}} = \\log \\sigma(\\mathbf{u}_{w_c}^\\top \\mathbf{v}_{w_t}) + \\sum_{i=1}^k \\mathbb{E}_{w_i \\sim P_{\\text{noise}}} \\left[\\log \\sigma(-\\mathbf{u}_{w_i}^\\top \\mathbf{v}_{w_t})\\right] \\] <p>Noise Distribution: Empirically, unigram distribution raised to power \u00be works best:</p> \\[ P_{\\text{noise}}(w) = \\frac{f(w)^{3/4}}{\\sum_{w' \\in \\mathcal{V}} f(w')^{3/4}} \\] <p>where \\(f(w)\\) is word frequency.</p> <p>Intuition:  - Maximize probability that target word appears in context: \\(\\sigma(\\mathbf{u}_{w_c}^\\top \\mathbf{v}_{w_t}) \\rightarrow 1\\) - Minimize probability that random words appear: \\(\\sigma(\\mathbf{u}_{w_i}^\\top \\mathbf{v}_{w_t}) \\rightarrow 0\\)</p> <p>Complexity: \\(O(|\\mathcal{V}|) \\rightarrow O(k)\\) per word, typically \\(k=5-20\\)</p> <p>Emergent Semantic Properties</p> <p>After training on billions of words (e.g., Google News corpus: 100B tokens), word vectors exhibit remarkable linear regularities:</p> <p>Semantic Analogies:</p> \\[ \\mathbf{v}(\\text{king}) - \\mathbf{v}(\\text{man}) + \\mathbf{v}(\\text{woman}) \\approx \\mathbf{v}(\\text{queen}) \\] \\[ \\mathbf{v}(\\text{Paris}) - \\mathbf{v}(\\text{France}) + \\mathbf{v}(\\text{Italy}) \\approx \\mathbf{v}(\\text{Rome}) \\] <p>Syntactic Analogies:</p> \\[ \\mathbf{v}(\\text{walking}) - \\mathbf{v}(\\text{walk}) \\approx \\mathbf{v}(\\text{swimming}) - \\mathbf{v}(\\text{swim}) \\] <p>(verb tense transformation)</p> \\[ \\mathbf{v}(\\text{slow}) - \\mathbf{v}(\\text{slower}) \\approx \\mathbf{v}(\\text{fast}) - \\mathbf{v}(\\text{faster}) \\] <p>(comparative form)</p> <p>Cosine Similarity Clustering: Semantically related words have high cosine similarity:</p> \\[ \\cos(\\mathbf{v}_i, \\mathbf{v}_j) = \\frac{\\mathbf{v}_i^\\top \\mathbf{v}_j}{\\|\\mathbf{v}_i\\| \\|\\mathbf{v}_j\\|} \\] <p>Examples: - Countries: \\(\\{\\text{France}, \\text{Germany}, \\text{Italy}, \\text{Spain}\\}\\) have pairwise similarity \\(&gt;0.7\\) - Sports: \\(\\{\\text{football}, \\text{basketball}, \\text{tennis}, \\text{soccer}\\}\\) have pairwise similarity \\(&gt;0.6\\)</p> <p>Geometric Interpretation: Word vectors organize into coherent semantic and syntactic subspaces where: - Direction encodes relationships (gender, tense, plurality) - Distance measures semantic similarity</p> <p>GloVe: Global Vectors for Word Representation (Pennington et al., 2014)</p> <p>Motivation: Word2Vec relies on local context windows, potentially missing global corpus statistics.</p> <p>Core Idea: Directly factorize word co-occurrence matrix to leverage global statistics.</p> <p>Co-occurrence Matrix: Define \\(X_{ij}\\) as number of times word \\(j\\) appears in context of word \\(i\\):</p> \\[ X_{ij} = \\sum_{t=1}^T \\sum_{k=-c}^c \\mathbb{I}[w_t = i \\wedge w_{t+k} = j] \\] <p>Objective: Learn vectors such that their dot product equals log co-occurrence:</p> \\[ \\mathbf{w}_i^\\top \\mathbf{w}_j + b_i + b_j \\approx \\log X_{ij} \\] <p>where \\(b_i, b_j\\) are bias terms for words \\(i, j\\).</p> <p>Weighted Least Squares Loss:</p> \\[ \\mathcal{L}_{\\text{GloVe}} = \\sum_{i,j=1}^{|\\mathcal{V}|} f(X_{ij}) \\left(\\mathbf{w}_i^\\top \\mathbf{w}_j + b_i + b_j - \\log X_{ij}\\right)^2 \\] <p>Weighting Function: Prevent common word pairs from dominating:</p> \\[ f(x) = \\begin{cases} (x / x_{\\max})^\\alpha &amp; \\text{if } x &lt; x_{\\max} \\\\ 1 &amp; \\text{otherwise} \\end{cases} \\] <p>Typical values: \\(x_{\\max} = 100\\), \\(\\alpha = 0.75\\).</p> <p>Intuition: - Rare co-occurrences (\\(X_{ij}\\) small): Low weight (unreliable statistics) - Very common co-occurrences (\\(X_{ij} &gt; x_{\\max}\\)): Capped weight (prevent dominance) - Intermediate frequencies: Highest relative weight</p> <p>Advantage over Word2Vec: Captures global corpus statistics, not just local windows. Empirically achieves better performance on word analogy tasks (75% \u2192 80% accuracy).</p> <p>Neural Classification Architectures</p> <p>Convolutional Neural Networks for Text (Kim, 2014)</p> <p>Architecture Pipeline:</p> <ol> <li> <p>Embedding Layer: Map words to dense vectors    \\(\\(\\mathbf{x}_{1:n} = [\\mathbf{v}_{w_1}, \\mathbf{v}_{w_2}, \\ldots, \\mathbf{v}_{w_n}]\\)\\)    where each \\(\\mathbf{v}_{w_i} \\in \\mathbb{R}^d\\) (typically \\(d=300\\) from pre-trained Word2Vec/GloVe)</p> </li> <li> <p>Convolutional Filters: Detect n-gram patterns</p> </li> </ol> <p>For filter \\(\\mathbf{W} \\in \\mathbb{R}^{k \\times d}\\) of height \\(k\\) (n-gram size):</p> <p>\\(\\(c_i = f\\left(\\mathbf{W} \\cdot \\mathbf{x}_{i:i+k-1} + b\\right)\\)\\)</p> <p>where:    - \\(\\mathbf{x}_{i:i+k-1} = [\\mathbf{v}_{w_i}; \\mathbf{v}_{w_{i+1}}; \\ldots; \\mathbf{v}_{w_{i+k-1}}] \\in \\mathbb{R}^{kd}\\) is concatenation of \\(k\\) consecutive word vectors    - \\(f\\) is activation function (typically ReLU: \\(f(z) = \\max(0, z)\\))    - \\(b \\in \\mathbb{R}\\) is bias term</p> <p>This produces feature map:    \\(\\(\\mathbf{c} = [c_1, c_2, \\ldots, c_{n-k+1}] \\in \\mathbb{R}^{n-k+1}\\)\\)</p> <ol> <li> <p>Max-Pooling: Extract most important feature from each filter    \\(\\(\\hat{c} = \\max(\\mathbf{c}) = \\max\\{c_1, c_2, \\ldots, c_{n-k+1}\\}\\)\\)</p> </li> <li> <p>Multiple Filter Sizes: Use filters of different heights (\\(k \\in \\{3, 4, 5\\}\\)) with \\(m\\) filters per size    \\(\\(\\mathbf{z} = [\\hat{c}_1^{(3)}, \\ldots, \\hat{c}_m^{(3)}, \\hat{c}_1^{(4)}, \\ldots, \\hat{c}_m^{(4)}, \\hat{c}_1^{(5)}, \\ldots, \\hat{c}_m^{(5)}] \\in \\mathbb{R}^{3m}\\)\\)</p> </li> <li> <p>Fully Connected Layer: Classification    \\(\\(\\mathbf{y} = \\text{softmax}(\\mathbf{W}_{\\text{fc}} \\mathbf{z} + \\mathbf{b}_{\\text{fc}})\\)\\)</p> </li> </ol> <p>Intuition:  - 3-gram filters detect trigrams: \"not very good\", \"extremely happy\" - 4-gram filters detect 4-word phrases: \"very easy to use\" - 5-gram filters detect longer patterns: \"I would highly recommend this\"</p> <p>Advantages: 1. Captures Local Patterns: N-grams indicative of sentiment/topic 2. Translation Invariant: Same filter applied everywhere 3. Parallel Computation: All filters computed simultaneously (fast on GPUs) 4. Pre-trained Embeddings: Initialize with Word2Vec/GloVe (transfer learning)</p> <p>Limitations: 1. Fixed Receptive Field: Cannot capture dependencies beyond n-gram size 2. Loses Long-Range Order: Max-pooling discards position information 3. No Sequential Dependencies: Unlike RNNs, doesn't model word order globally</p> <p>Recurrent Neural Networks: Long Short-Term Memory (LSTM)</p> <p>Motivation: Standard RNNs suffer from vanishing gradient problem\u2014gradients decay exponentially with sequence length, preventing learning of long-term dependencies.</p> <p>Vanishing Gradient in Standard RNN:</p> <p>For RNN \\(\\mathbf{h}_t = \\tanh(\\mathbf{W} \\mathbf{h}_{t-1} + \\mathbf{U} \\mathbf{x}_t)\\), gradient at step \\(t\\) w.r.t. step \\(t-k\\):</p> \\[ \\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_{t-k}} = \\prod_{i=t-k+1}^t \\frac{\\partial \\mathbf{h}_i}{\\partial \\mathbf{h}_{i-1}} = \\prod_{i=t-k+1}^t \\mathbf{W}^\\top \\text{diag}[\\tanh'(\\cdot)] \\] <p>Since \\(|\\tanh'(z)| \\leq 1\\) and typically \\(\\|\\mathbf{W}\\| &lt; 1\\) for stability, gradients decay as:</p> \\[ \\left\\|\\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_{t-k}}\\right\\| \\approx \\gamma^k \\quad \\text{where } \\gamma &lt; 1 \\] <p>For \\(k=100\\) and \\(\\gamma = 0.9\\): gradient is \\(0.9^{100} \\approx 10^{-5}\\) (vanished!).</p> <p>LSTM Solution (Hochreiter &amp; Schmidhuber, 1997)</p> <p>Introduce gating mechanisms to control information flow, enabling gradients to flow unchanged across many time steps.</p> <p>Four Components:</p> <p>1. Forget Gate \\(\\mathbf{f}_t\\) (what to discard from cell state):</p> \\[ \\mathbf{f}_t = \\sigma(\\mathbf{W}_f \\cdot [\\mathbf{h}_{t-1}, \\mathbf{x}_t] + \\mathbf{b}_f) \\] <p>where \\(\\sigma(z) = 1/(1+e^{-z})\\) is sigmoid function outputting values in \\((0, 1)\\).</p> <p>2. Input Gate \\(\\mathbf{i}_t\\) (what new information to store):</p> \\[ \\mathbf{i}_t = \\sigma(\\mathbf{W}_i \\cdot [\\mathbf{h}_{t-1}, \\mathbf{x}_t] + \\mathbf{b}_i) \\] <p>Candidate Values \\(\\tilde{\\mathbf{C}}_t\\) (potential new information):</p> \\[ \\tilde{\\mathbf{C}}_t = \\tanh(\\mathbf{W}_C \\cdot [\\mathbf{h}_{t-1}, \\mathbf{x}_t] + \\mathbf{b}_C) \\] <p>3. Cell State Update \\(\\mathbf{C}_t\\) (memory highway):</p> \\[ \\mathbf{C}_t = \\mathbf{f}_t \\odot \\mathbf{C}_{t-1} + \\mathbf{i}_t \\odot \\tilde{\\mathbf{C}}_t \\] <p>where \\(\\odot\\) is element-wise (Hadamard) product.</p> <p>Interpretation: - \\(\\mathbf{f}_t \\odot \\mathbf{C}_{t-1}\\): Selectively forget old memory (forget gate acts as filter) - \\(\\mathbf{i}_t \\odot \\tilde{\\mathbf{C}}_t\\): Selectively add new information (input gate controls flow)</p> <p>4. Output Gate \\(\\mathbf{o}_t\\) (what to output):</p> \\[ \\mathbf{o}_t = \\sigma(\\mathbf{W}_o \\cdot [\\mathbf{h}_{t-1}, \\mathbf{x}_t] + \\mathbf{b}_o) \\] <p>Hidden State:</p> \\[ \\mathbf{h}_t = \\mathbf{o}_t \\odot \\tanh(\\mathbf{C}_t) \\] <p>Geometric Interpretation:</p> <ul> <li>Cell State \\(\\mathbf{C}_t\\): \"Memory highway\" carrying information across time with minimal transformation</li> <li>Gates (sigmoid outputs \\(\\in (0,1)\\)): Differentiable switches</li> <li>\\(\\sigma(z) \\approx 1\\): Gate open (information flows)</li> <li>\\(\\sigma(z) \\approx 0\\): Gate closed (information blocked)</li> </ul> <p>Gradient Flow: Crucial property enabling long-term learning:</p> \\[ \\frac{\\partial \\mathbf{C}_t}{\\partial \\mathbf{C}_{t-1}} = \\mathbf{f}_t \\] <p>Since \\(\\mathbf{f}_t \\in (0,1)\\) is learned (not fixed like \\(\\mathbf{W}\\) in RNN), the network can learn to set \\(\\mathbf{f}_t \\approx 1\\) for important information, allowing gradients to flow unchanged across 100+ steps.</p> <p>Concrete Example: </p> <p>Sentence: \"The cat, which I saw yesterday in the park while I was walking, was sleeping.\"</p> <p>Challenge: Predict verb \"was\" (singular) requiring subject \"cat\" from 12 words earlier.</p> <p>LSTM Behavior: 1. At \"cat\": Input gate \\(\\mathbf{i}_t\\) opens, stores \"singular subject\" in cell state \\(\\mathbf{C}_t\\) 2. During intervening clause: Forget gate \\(\\mathbf{f}_t \\approx 1\\) preserves \"singular\" information 3. At \"was\": Output gate \\(\\mathbf{o}_t\\) opens, retrieves \"singular\" \u2192 selects \"was\" (not \"were\")</p> <p>Bidirectional LSTM (BiLSTM):</p> <p>Process sequence in both directions:</p> \\[ \\begin{aligned} \\overrightarrow{\\mathbf{h}}_t &amp;= \\text{LSTM}(\\overrightarrow{\\mathbf{h}}_{t-1}, \\mathbf{x}_t) \\quad \\text{(forward)} \\\\ \\overleftarrow{\\mathbf{h}}_t &amp;= \\text{LSTM}(\\overleftarrow{\\mathbf{h}}_{t+1}, \\mathbf{x}_t) \\quad \\text{(backward)} \\\\ \\mathbf{h}_t &amp;= [\\overrightarrow{\\mathbf{h}}_t; \\overleftarrow{\\mathbf{h}}_t] \\quad \\text{(concatenate)} \\end{aligned} \\] <p>Advantage: Access to both past and future context (crucial for classification where entire document is available).</p> <p>Advantages of LSTMs: 1. Long-Range Dependencies: Captures patterns across 100+ tokens 2. Variable Length: Naturally handles sequences of any length 3. Sequential Structure: Models inherent word order 4. Bidirectionality: BiLSTM sees full context</p> <p>Limitations: 1. Sequential Processing: Cannot parallelize across time steps (slow training) 2. Still Limited: Struggles with 500+ token dependencies 3. Computational Cost: Requires two passes for BiLSTM</p> <p>Critical Limitation of Phase 2: Context-Independent Embeddings</p> <p>Fundamental Problem: Word2Vec and GloVe produce static embeddings\u2014each word receives a single fixed vector regardless of context.</p> <p>Example Failure: Word \"bank\"</p> <p>Word2Vec assigns fixed vector \\(\\mathbf{v}_{\\text{bank}}\\) used in both: - \"I deposited money at the bank\" (financial institution) - \"We sat by the river bank\" (land alongside water)</p> <p>These usages have completely different meanings, but receive identical representations!</p> <p>Attempted Solution: Use LSTM to compute contextualized representations:</p> \\[ \\mathbf{h}_t = \\text{BiLSTM}(\\mathbf{v}_{w_1}, \\ldots, \\mathbf{v}_{w_t}, \\ldots, \\mathbf{v}_{w_n}) \\] <p>Remaining Issue: LSTM still initializes from static embeddings and suffers from: - Sequential processing bottleneck - Limited context window (100-200 tokens effective range) - Difficulty modeling very long-range dependencies</p> <p>This limitation motivated Phase 3: Attention mechanisms enabling truly context-dependent representations with global receptive field.</p>"},{"location":"#phase-3-attention-mechanisms-and-transformers-2017-2019","title":"Phase 3: Attention Mechanisms and Transformers (2017-2019)","text":"<p>The Attention Revolution</p> <p>Core Insight: Instead of forcing the network to compress entire sequence into fixed-size vector, allow it to selectively attend to relevant parts for each prediction.</p> <p>Self-Attention Mechanism</p> <p>Motivation: For each token, compute representation as weighted combination of all tokens in sequence, with weights determined by relevance.</p> <p>Mathematical Formulation:</p> <p>Given input sequence of \\(n\\) tokens represented as matrix:</p> \\[ \\mathbf{X} = [\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_n]^\\top \\in \\mathbb{R}^{n \\times d} \\] <p>where each \\(\\mathbf{x}_i \\in \\mathbb{R}^d\\) is token embedding.</p> <p>Step 1: Linear Projections</p> <p>Transform input to three representations via learned matrices:</p> \\[ \\begin{aligned} \\mathbf{Q} &amp;= \\mathbf{X} \\mathbf{W}_Q \\in \\mathbb{R}^{n \\times d_k} \\quad \\text{(Queries)} \\\\ \\mathbf{K} &amp;= \\mathbf{X} \\mathbf{W}_K \\in \\mathbb{R}^{n \\times d_k} \\quad \\text{(Keys)} \\\\ \\mathbf{V} &amp;= \\mathbf{X} \\mathbf{W}_V \\in \\mathbb{R}^{n \\times d_v} \\quad \\text{(Values)} \\end{aligned} \\] <p>where \\(\\mathbf{W}_Q, \\mathbf{W}_K \\in \\mathbb{R}^{d \\times d_k}\\) and \\(\\mathbf{W}_V \\in \\mathbb{R}^{d \\times d_v}\\) are learned projection matrices.</p> <p>Interpretation: - Query \\(\\mathbf{q}_i\\): \"What am I looking for?\" (what information does token \\(i\\) need) - Key \\(\\mathbf{k}_j\\): \"What information do I contain?\" (what token \\(j\\) offers) - Value \\(\\mathbf{v}_j\\): \"What information do I provide?\" (actual content from token \\(j\\))</p> <p>Step 2: Compute Attention Scores</p> <p>Measure relevance between all token pairs via dot product:</p> \\[ \\mathbf{S} = \\mathbf{Q} \\mathbf{K}^\\top \\in \\mathbb{R}^{n \\times n} \\] <p>where \\(S_{ij} = \\mathbf{q}_i^\\top \\mathbf{k}_j\\) measures compatibility between query \\(i\\) and key \\(j\\).</p> <p>Scaled Dot-Product (prevent gradients from vanishing):</p> \\[ \\mathbf{S} = \\frac{\\mathbf{Q} \\mathbf{K}^\\top}{\\sqrt{d_k}} \\] <p>Why scaling? For random vectors \\(\\mathbf{q}, \\mathbf{k} \\in \\mathbb{R}^{d_k}\\) with unit variance:</p> \\[ \\mathbb{E}[\\mathbf{q}^\\top \\mathbf{k}] = 0, \\quad \\text{Var}[\\mathbf{q}^\\top \\mathbf{k}] = d_k \\] <p>Dot products grow with dimension \u2192 softmax saturates \u2192 gradients vanish. Dividing by \\(\\sqrt{d_k}\\) maintains unit variance.</p> <p>Step 3: Attention Weights</p> <p>Convert scores to probability distribution via softmax (row-wise):</p> \\[ \\mathbf{A} = \\text{softmax}(\\mathbf{S}) \\in \\mathbb{R}^{n \\times n} \\] \\[ A_{ij} = \\frac{\\exp(S_{ij})}{\\sum_{k=1}^n \\exp(S_{ik})} \\] <p>Properties: - Each row sums to 1: \\(\\sum_{j=1}^n A_{ij} = 1\\) - All values positive: \\(A_{ij} \\in (0, 1)\\) - \\(A_{ij}\\) represents \"how much token \\(i\\) attends to token \\(j\\)\"</p> <p>Step 4: Weighted Aggregation</p> <p>Compute output as attention-weighted sum of values:</p> \\[ \\mathbf{Z} = \\mathbf{A} \\mathbf{V} \\in \\mathbb{R}^{n \\times d_v} \\] \\[ \\mathbf{z}_i = \\sum_{j=1}^n A_{ij} \\mathbf{v}_j \\] <p>Complete Self-Attention Formula:</p> \\[ \\text{Attention}(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}) = \\text{softmax}\\left(\\frac{\\mathbf{Q} \\mathbf{K}^\\top}{\\sqrt{d_k}}\\right) \\mathbf{V} \\] <p>Concrete Example:</p> <p>Sentence: \"The cat sat on the mat\"</p> <p>For token \"sat\" (query): - High attention to \"cat\" (subject performing action): \\(A_{\\text{sat,cat}} = 0.45\\) - High attention to \"mat\" (object of preposition): \\(A_{\\text{sat,mat}} = 0.30\\) - Moderate attention to \"on\" (preposition): \\(A_{\\text{sat,on}} = 0.15\\) - Low attention to \"the\": \\(A_{\\text{sat,the}} = 0.05\\) each</p> <p>Output representation \\(\\mathbf{z}_{\\text{sat}}\\) is weighted combination:</p> \\[ \\mathbf{z}_{\\text{sat}} = 0.45 \\mathbf{v}_{\\text{cat}} + 0.30 \\mathbf{v}_{\\text{mat}} + 0.15 \\mathbf{v}_{\\text{on}} + \\ldots \\] <p>This representation captures that \"sat\" relates primarily to \"cat\" and \"mat\"\u2014syntactic and semantic structure discovered automatically!</p> <p>Multi-Head Attention</p> <p>Motivation: Single attention mechanism may focus on one relationship type (e.g., syntactic). Multiple heads can capture different relationship types in parallel.</p> <p>Formulation: Run \\(h\\) attention heads with different projection matrices:</p> \\[ \\text{head}_i = \\text{Attention}(\\mathbf{Q} \\mathbf{W}_Q^i, \\mathbf{K} \\mathbf{W}_K^i, \\mathbf{V} \\mathbf{W}_V^i) \\] <p>where \\(\\mathbf{W}_Q^i, \\mathbf{W}_K^i \\in \\mathbb{R}^{d \\times d_k}\\), \\(\\mathbf{W}_V^i \\in \\mathbb{R}^{d \\times d_v}\\) are learned parameters for head \\(i\\).</p> <p>Concatenate and Project:</p> \\[ \\text{MultiHead}(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}) = \\text{Concat}(\\text{head}_1, \\ldots, \\text{head}_h) \\mathbf{W}^O \\] <p>where \\(\\mathbf{W}^O \\in \\mathbb{R}^{h \\cdot d_v \\times d}\\) projects back to original dimension.</p> <p>Typical Configuration:  - BERT-Base: \\(h=12\\) heads, \\(d_k = d_v = d/h = 768/12 = 64\\) - Each head has 64-dimensional queries/keys/values</p> <p>Empirical Finding: Different heads specialize in different patterns:</p> <ul> <li>Head 1: Subject-verb agreement (\"cat was\" vs. \"cats were\")</li> <li>Head 2: Object-verb relationships</li> <li>Head 3: Prepositional attachments</li> <li>Head 4: Coreference resolution (pronouns \u2192 antecedents: \"John ... he\")</li> <li>Head 5: Positional proximity (adjacent words)</li> <li>Head 6: Semantic similarity (synonyms, related concepts)</li> </ul> <p>Visualization: Attention patterns reveal linguistic structure without explicit supervision!</p> <p>The Transformer Architecture (Vaswani et al., 2017)</p> <p>Revolutionary Design: Entirely based on attention, completely removing recurrence and convolution.</p> <p>Encoder Architecture (for classification):</p> Text Only<pre><code>Input Tokens\n    \u2193\nToken Embedding + Positional Encoding\n    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Encoder Block (\u00d7N layers)      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Multi-Head Self-Attention \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502            \u2193                     \u2502\n\u2502      Add &amp; Normalize             \u2502\n\u2502            \u2193                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Feed-Forward Network     \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502            \u2193                     \u2502\n\u2502      Add &amp; Normalize             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2193\nClassification Head (pooling + linear)\n    \u2193\nOutput Probabilities\n</code></pre> <p>Key Components:</p> <p>1. Positional Encoding</p> <p>Problem: Attention is permutation invariant\u2014reordering tokens doesn't change attention output. But word order matters in language!</p> <p>Solution: Add position-dependent patterns to input embeddings.</p> <p>Sinusoidal Encoding (original Transformer):</p> \\[ \\begin{aligned} PE_{(\\text{pos}, 2i)} &amp;= \\sin\\left(\\frac{\\text{pos}}{10000^{2i/d}}\\right) \\\\ PE_{(\\text{pos}, 2i+1)} &amp;= \\cos\\left(\\frac{\\text{pos}}{10000^{2i/d}}\\right) \\end{aligned} \\] <p>where: - \\(\\text{pos} \\in \\{0, 1, \\ldots, n-1\\}\\): Position in sequence - \\(i \\in \\{0, 1, \\ldots, d/2-1\\}\\): Dimension index - Even dimensions use sine, odd use cosine</p> <p>Properties: - Each position has unique encoding - Relative positions have consistent patterns: \\(PE_{\\text{pos}+k}\\) is linear function of \\(PE_{\\text{pos}}\\) (enables learning of relative position relationships) - Extrapolates to longer sequences than seen during training</p> <p>Alternative: Learned Positional Embeddings (BERT):</p> \\[ PE_{\\text{pos}} = \\mathbf{W}_{\\text{pos}}[\\text{pos}] \\in \\mathbb{R}^d \\] <p>where \\(\\mathbf{W}_{\\text{pos}} \\in \\mathbb{R}^{n_{\\max} \\times d}\\) is learned embedding matrix for positions up to \\(n_{\\max}\\).</p> <p>Input to First Layer:</p> \\[ \\mathbf{x}_i^{(0)} = \\text{TokenEmbed}(w_i) + PE_i \\] <p>2. Feed-Forward Network</p> <p>Applied independently to each position (no interaction between positions):</p> \\[ \\text{FFN}(\\mathbf{x}) = \\max(0, \\mathbf{x} \\mathbf{W}_1 + \\mathbf{b}_1) \\mathbf{W}_2 + \\mathbf{b}_2 \\] <p>where: - \\(\\mathbf{W}_1 \\in \\mathbb{R}^{d \\times d_{\\text{ff}}}\\): Expand dimension (typically \\(d_{\\text{ff}} = 4d\\)) - \\(\\mathbf{W}_2 \\in \\mathbb{R}^{d_{\\text{ff}} \\times d}\\): Project back - ReLU activation: \\(\\max(0, \\cdot)\\)</p> <p>Intuition:  - Self-attention mixes information across positions - FFN processes each position independently to extract features</p> <p>3. Layer Normalization</p> <p>Normalize activations across feature dimension (not batch like BatchNorm):</p> \\[ \\text{LayerNorm}(\\mathbf{x}) = \\gamma \\odot \\frac{\\mathbf{x} - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta \\] <p>where: - \\(\\mu = \\frac{1}{d} \\sum_{i=1}^d x_i\\): Mean across features - \\(\\sigma^2 = \\frac{1}{d} \\sum_{i=1}^d (x_i - \\mu)^2\\): Variance - \\(\\gamma, \\beta \\in \\mathbb{R}^d\\): Learned scale and shift parameters - \\(\\epsilon\\): Small constant for numerical stability (typically \\(10^{-12}\\))</p> <p>Why Layer Norm? Stabilizes training of deep networks by preventing internal covariate shift.</p> <p>4. Residual Connections</p> <p>Add input to output of each sublayer:</p> \\[ \\mathbf{x}^{(\\ell+1)} = \\text{LayerNorm}(\\mathbf{x}^{(\\ell)} + \\text{Sublayer}(\\mathbf{x}^{(\\ell)})) \\] <p>Benefit: Enable gradient flow through deep networks (up to 24 layers in BERT-Large).</p> <p>Gradient Backpropagation: Residual connections create direct paths:</p> \\[ \\frac{\\partial \\mathbf{x}^{(L)}}{\\partial \\mathbf{x}^{(0)}} = \\mathbf{I} + \\frac{\\partial}{\\partial \\mathbf{x}^{(0)}} \\sum_{\\ell=1}^L \\text{Sublayer}^{(\\ell)} \\] <p>Identity \\(\\mathbf{I}\\) ensures gradient has magnitude at least 1 (prevents vanishing).</p> <p>Complete Encoder Layer:</p> \\[ \\begin{aligned} \\mathbf{z}^{(\\ell)} &amp;= \\text{LayerNorm}(\\mathbf{x}^{(\\ell-1)} + \\text{MultiHead}(\\mathbf{x}^{(\\ell-1)})) \\\\ \\mathbf{x}^{(\\ell)} &amp;= \\text{LayerNorm}(\\mathbf{z}^{(\\ell)} + \\text{FFN}(\\mathbf{z}^{(\\ell)})) \\end{aligned} \\] <p>Advantages Over RNNs and CNNs:</p> Aspect RNN/LSTM CNN Transformer Parallelization Sequential (one token at a time) Parallel within layer Fully parallel Training Speed Slow (\\(O(n)\\) sequential steps) Fast Very fast Long-Range Dependencies Limited (gradient decay) Limited (receptive field) Unlimited (direct connections) Path Length \\(O(n)\\) between distant tokens \\(O(\\log n)\\) (stacked layers) \\(O(1)\\) (direct attention) Memory \\(O(n)\\) \\(O(n)\\) \\(O(n^2)\\) (attention matrix) Receptive Field Full sequence Local then global (stacking) Full sequence from layer 1 <p>Computational Complexity Analysis:</p> <p>For sequence length \\(n\\) and dimension \\(d\\):</p> <p>Self-Attention: - \\(\\mathbf{Q} \\mathbf{K}^\\top\\): \\(O(n^2 \\cdot d)\\) (bottleneck for long sequences) - Softmax: \\(O(n^2)\\) - Attention \\(\\times\\) Values: \\(O(n^2 \\cdot d)\\) - Total: \\(O(n^2 \\cdot d)\\)</p> <p>Feed-Forward: - Two matrix multiplications: \\(O(n \\cdot d \\cdot d_{\\text{ff}}) = O(n \\cdot d^2)\\) (since \\(d_{\\text{ff}} = 4d\\))</p> <p>Trade-off: - Short sequences (\\(n &lt; d\\)): Self-attention faster - Long sequences (\\(n &gt; d\\)): FFN dominates</p> <p>For typical transformers: \\(n=512\\), \\(d=768\\) \u2192 \\(n &lt; d\\) \u2192 attention is bottleneck</p> <p>Maximum Sequence Length: Quadratic memory \\(O(n^2)\\) limits practical length: - BERT: 512 tokens - RoBERTa: 512 tokens - Longformer: 4096 tokens (sparse attention) - BigBird: 4096 tokens (random/window/global attention)</p> <p>This concludes Phase 3. Shall I continue with Phase 4 (Pre-trained Language Models) and Phase 5 (LLMs and Parameter Efficiency)?</p>"},{"location":"#project-structure","title":"Project Structure","text":"<p>The repository is organized as follows:</p> Text Only<pre><code>ag-news-text-classification/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 CITATION.cff\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 ARCHITECTURE.md\n\u251c\u2500\u2500 PERFORMANCE.md\n\u251c\u2500\u2500 SECURITY.md\n\u251c\u2500\u2500 TROUBLESHOOTING.md\n\u251c\u2500\u2500 SOTA_MODELS_GUIDE.md\n\u251c\u2500\u2500 OVERFITTING_PREVENTION.md\n\u251c\u2500\u2500 ROADMAP.md\n\u251c\u2500\u2500 FREE_DEPLOYMENT_GUIDE.md\n\u251c\u2500\u2500 PLATFORM_OPTIMIZATION_GUIDE.md\n\u251c\u2500\u2500 IDE_SETUP_GUIDE.md\n\u251c\u2500\u2500 LOCAL_MONITORING_GUIDE.md\n\u251c\u2500\u2500 QUICK_START.md\n\u251c\u2500\u2500 HEALTH_CHECK.md\n\u251c\u2500\u2500 setup.py\n\u251c\u2500\u2500 setup.cfg\n\u251c\u2500\u2500 MANIFEST.in\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 poetry.lock\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 install.sh\n\u251c\u2500\u2500 .env.example\n\u251c\u2500\u2500 .env.test\n\u251c\u2500\u2500 .env.local\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .gitattributes\n\u251c\u2500\u2500 .dockerignore\n\u251c\u2500\u2500 .editorconfig\n\u251c\u2500\u2500 .pre-commit-config.yaml\n\u251c\u2500\u2500 .flake8\n\u251c\u2500\u2500 commitlint.config.js\n\u2502\n\u251c\u2500\u2500 requirements/\n\u2502   \u251c\u2500\u2500 base.txt\n\u2502   \u251c\u2500\u2500 ml.txt\n\u2502   \u251c\u2500\u2500 llm.txt\n\u2502   \u251c\u2500\u2500 efficient.txt\n\u2502   \u251c\u2500\u2500 local_prod.txt\n\u2502   \u251c\u2500\u2500 dev.txt\n\u2502   \u251c\u2500\u2500 data.txt\n\u2502   \u251c\u2500\u2500 ui.txt\n\u2502   \u251c\u2500\u2500 docs.txt\n\u2502   \u251c\u2500\u2500 minimal.txt\n\u2502   \u251c\u2500\u2500 research.txt\n\u2502   \u251c\u2500\u2500 robustness.txt\n\u2502   \u251c\u2500\u2500 all_local.txt\n\u2502   \u251c\u2500\u2500 colab.txt\n\u2502   \u251c\u2500\u2500 kaggle.txt\n\u2502   \u251c\u2500\u2500 free_tier.txt\n\u2502   \u251c\u2500\u2500 platform_minimal.txt\n\u2502   \u251c\u2500\u2500 local_monitoring.txt\n\u2502   \u2514\u2500\u2500 lock/\n\u2502       \u251c\u2500\u2500 base.lock\n\u2502       \u251c\u2500\u2500 ml.lock\n\u2502       \u251c\u2500\u2500 llm.lock\n\u2502       \u251c\u2500\u2500 all.lock\n\u2502       \u2514\u2500\u2500 README.md\n\u2502\n\u251c\u2500\u2500 .devcontainer/\n\u2502   \u251c\u2500\u2500 devcontainer.json\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u2502\n\u251c\u2500\u2500 .husky/\n\u2502   \u251c\u2500\u2500 pre-commit\n\u2502   \u2514\u2500\u2500 commit-msg\n\u2502\n\u251c\u2500\u2500 .ide/\n\u2502   \u251c\u2500\u2500 SOURCE_OF_TRUTH.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 vscode/\n\u2502   \u2502   \u251c\u2500\u2500 settings.json\n\u2502   \u2502   \u251c\u2500\u2500 launch.json\n\u2502   \u2502   \u251c\u2500\u2500 tasks.json\n\u2502   \u2502   \u251c\u2500\u2500 extensions.json\n\u2502   \u2502   \u2514\u2500\u2500 snippets/\n\u2502   \u2502       \u251c\u2500\u2500 python.json\n\u2502   \u2502       \u2514\u2500\u2500 yaml.json\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 pycharm/\n\u2502   \u2502   \u251c\u2500\u2500 .idea/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 workspace.xml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 misc.xml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 modules.xml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 inspectionProfiles/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 runConfigurations/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 train_model.xml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 run_tests.xml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 start_api.xml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 codeStyles/\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 Project.xml\n\u2502   \u2502   \u251c\u2500\u2500 README_PYCHARM.md\n\u2502   \u2502   \u2514\u2500\u2500 settings.zip\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 jupyter/\n\u2502   \u2502   \u251c\u2500\u2500 jupyter_notebook_config.py\n\u2502   \u2502   \u251c\u2500\u2500 jupyter_lab_config.py\n\u2502   \u2502   \u251c\u2500\u2500 custom/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 custom.css\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 custom.js\n\u2502   \u2502   \u251c\u2500\u2500 nbextensions_config.json\n\u2502   \u2502   \u251c\u2500\u2500 lab/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 user-settings/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 workspaces/\n\u2502   \u2502   \u2514\u2500\u2500 kernels/\n\u2502   \u2502       \u2514\u2500\u2500 ag-news/\n\u2502   \u2502           \u2514\u2500\u2500 kernel.json\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 vim/\n\u2502   \u2502   \u251c\u2500\u2500 .vimrc\n\u2502   \u2502   \u251c\u2500\u2500 coc-settings.json\n\u2502   \u2502   \u251c\u2500\u2500 ultisnips/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 python.snippets\n\u2502   \u2502   \u2514\u2500\u2500 README_VIM.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 neovim/\n\u2502   \u2502   \u251c\u2500\u2500 init.lua\n\u2502   \u2502   \u251c\u2500\u2500 lua/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 plugins.lua\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 lsp.lua\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 keymaps.lua\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 ag-news/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 config.lua\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 commands.lua\n\u2502   \u2502   \u251c\u2500\u2500 coc-settings.json\n\u2502   \u2502   \u2514\u2500\u2500 README_NEOVIM.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 sublime/\n\u2502   \u2502   \u251c\u2500\u2500 ag-news.sublime-project\n\u2502   \u2502   \u251c\u2500\u2500 ag-news.sublime-workspace\n\u2502   \u2502   \u251c\u2500\u2500 Preferences.sublime-settings\n\u2502   \u2502   \u251c\u2500\u2500 Python.sublime-settings\n\u2502   \u2502   \u251c\u2500\u2500 snippets/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 pytorch-model.sublime-snippet\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 lora-config.sublime-snippet\n\u2502   \u2502   \u251c\u2500\u2500 build_systems/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 Train Model.sublime-build\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 Run Tests.sublime-build\n\u2502   \u2502   \u2514\u2500\u2500 README_SUBLIME.md\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 cloud_ides/\n\u2502       \u251c\u2500\u2500 gitpod/\n\u2502       \u2502   \u251c\u2500\u2500 .gitpod.yml\n\u2502       \u2502   \u2514\u2500\u2500 .gitpod.Dockerfile\n\u2502       \u251c\u2500\u2500 codespaces/\n\u2502       \u2502   \u2514\u2500\u2500 .devcontainer.json\n\u2502       \u251c\u2500\u2500 colab/\n\u2502       \u2502   \u251c\u2500\u2500 colab_setup.py\n\u2502       \u2502   \u2514\u2500\u2500 drive_mount.py\n\u2502       \u2514\u2500\u2500 kaggle/\n\u2502           \u2514\u2500\u2500 kaggle_setup.py\n\u2502\n\u251c\u2500\u2500 images/\n\u2502   \u251c\u2500\u2500 pipeline.png\n\u2502   \u251c\u2500\u2500 api_architecture.png\n\u2502   \u251c\u2500\u2500 local_deployment_flow.png\n\u2502   \u251c\u2500\u2500 overfitting_prevention_flow.png\n\u2502   \u251c\u2500\u2500 sota_model_architecture.png\n\u2502   \u251c\u2500\u2500 decision_tree.png\n\u2502   \u251c\u2500\u2500 platform_detection_flow.png\n\u2502   \u251c\u2500\u2500 auto_training_workflow.png\n\u2502   \u251c\u2500\u2500 quota_management_diagram.png\n\u2502   \u2514\u2500\u2500 progressive_disclosure.png\n\u2502\n\u251c\u2500\u2500 configs/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 config_loader.py\n\u2502   \u251c\u2500\u2500 config_validator.py\n\u2502   \u251c\u2500\u2500 config_schema.py\n\u2502   \u251c\u2500\u2500 constants.py\n\u2502   \u251c\u2500\u2500 compatibility_matrix.yaml\n\u2502   \u251c\u2500\u2500 smart_defaults.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u251c\u2500\u2500 rest_config.yaml\n\u2502   \u2502   \u251c\u2500\u2500 auth_config.yaml\n\u2502   \u2502   \u2514\u2500\u2500 rate_limit_config.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 services/\n\u2502   \u2502   \u251c\u2500\u2500 prediction_service.yaml\n\u2502   \u2502   \u251c\u2500\u2500 training_service.yaml\n\u2502   \u2502   \u251c\u2500\u2500 data_service.yaml\n\u2502   \u2502   \u251c\u2500\u2500 model_service.yaml\n\u2502   \u2502   \u2514\u2500\u2500 local_monitoring.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 environments/\n\u2502   \u2502   \u251c\u2500\u2500 dev.yaml\n\u2502   \u2502   \u251c\u2500\u2500 local_prod.yaml\n\u2502   \u2502   \u251c\u2500\u2500 colab.yaml\n\u2502   \u2502   \u2514\u2500\u2500 kaggle.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 features/\n\u2502   \u2502   \u2514\u2500\u2500 feature_flags.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 secrets/\n\u2502   \u2502   \u251c\u2500\u2500 secrets.template.yaml\n\u2502   \u2502   \u2514\u2500\u2500 local_secrets.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 templates/\n\u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u251c\u2500\u2500 deberta_template.yaml.j2\n\u2502   \u2502   \u251c\u2500\u2500 roberta_template.yaml.j2\n\u2502   \u2502   \u251c\u2500\u2500 llm_template.yaml.j2\n\u2502   \u2502   \u251c\u2500\u2500 ensemble_template.yaml.j2\n\u2502   \u2502   \u2514\u2500\u2500 training_template.yaml.j2\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 generation/\n\u2502   \u2502   \u251c\u2500\u2500 model_specs.yaml\n\u2502   \u2502   \u251c\u2500\u2500 training_specs.yaml\n\u2502   \u2502   \u2514\u2500\u2500 ensemble_specs.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u251c\u2500\u2500 SELECTION_GUIDE.md\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 recommended/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ag_news_best_practices.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 quick_start.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 balanced.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 sota_accuracy.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 tier_1_sota/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v3_xlarge_lora.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v2_xxlarge_qlora.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta_large_lora.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 electra_large_lora.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 xlnet_large_lora.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 tier_2_llm/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama2_7b_qlora.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama2_13b_qlora.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama3_8b_qlora.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mistral_7b_qlora.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mixtral_8x7b_qlora.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 falcon_7b_qlora.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 phi_3_qlora.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 mpt_7b_qlora.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 tier_3_ensemble/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 xlarge_ensemble.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llm_ensemble.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 hybrid_ensemble.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 open_source_llm_ensemble.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 tier_4_distilled/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama_distilled_deberta.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mistral_distilled_roberta.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ensemble_distilled.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 tier_5_free_optimized/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 auto_selected/\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 colab_free_auto.yaml\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 colab_pro_auto.yaml\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 kaggle_auto.yaml\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 local_auto.yaml\n\u2502   \u2502   \u2502       \u2502   \u2514\u2500\u2500 platform_matrix.yaml\n\u2502   \u2502   \u2502       \u2502\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 platform_specific/\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 colab_optimized.yaml\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 kaggle_tpu_optimized.yaml\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 local_cpu_optimized.yaml\n\u2502   \u2502   \u2502       \u2502   \u2514\u2500\u2500 local_gpu_optimized.yaml\n\u2502   \u2502   \u2502       \u2502\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 colab_friendly/\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 deberta_large_lora_colab.yaml\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 distilroberta_efficient.yaml\n\u2502   \u2502   \u2502       \u2502   \u2514\u2500\u2500 ensemble_lightweight.yaml\n\u2502   \u2502   \u2502       \u2502\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 cpu_friendly/\n\u2502   \u2502   \u2502           \u251c\u2500\u2500 distilled_cpu_optimized.yaml\n\u2502   \u2502   \u2502           \u2514\u2500\u2500 quantized_int8.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 single/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 transformers/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta/\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v3_base.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v3_large.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v3_xlarge.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v2_xlarge.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v2_xxlarge.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 deberta_sliding_window.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta/\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta_base.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta_large.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta_large_mnli.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 xlm_roberta_large.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 electra/\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 electra_base.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 electra_large.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 electra_discriminator.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 xlnet/\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 xlnet_base.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 xlnet_large.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 longformer/\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 longformer_base.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 longformer_large.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 t5/\n\u2502   \u2502   \u2502   \u2502       \u251c\u2500\u2500 t5_base.yaml\n\u2502   \u2502   \u2502   \u2502       \u251c\u2500\u2500 t5_large.yaml\n\u2502   \u2502   \u2502   \u2502       \u251c\u2500\u2500 t5_3b.yaml\n\u2502   \u2502   \u2502   \u2502       \u2514\u2500\u2500 flan_t5_xl.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 llm/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 llama/\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 llama2_7b.yaml\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 llama2_13b.yaml\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 llama2_70b.yaml\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 llama3_8b.yaml\n\u2502   \u2502   \u2502       \u2502   \u2514\u2500\u2500 llama3_70b.yaml\n\u2502   \u2502   \u2502       \u2502\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 mistral/\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 mistral_7b.yaml\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 mistral_7b_instruct.yaml\n\u2502   \u2502   \u2502       \u2502   \u2514\u2500\u2500 mixtral_8x7b.yaml\n\u2502   \u2502   \u2502       \u2502\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 falcon/\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 falcon_7b.yaml\n\u2502   \u2502   \u2502       \u2502   \u2514\u2500\u2500 falcon_40b.yaml\n\u2502   \u2502   \u2502       \u2502\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 mpt/\n\u2502   \u2502   \u2502       \u2502   \u251c\u2500\u2500 mpt_7b.yaml\n\u2502   \u2502   \u2502       \u2502   \u2514\u2500\u2500 mpt_30b.yaml\n\u2502   \u2502   \u2502       \u2502\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 phi/\n\u2502   \u2502   \u2502           \u251c\u2500\u2500 phi_2.yaml\n\u2502   \u2502   \u2502           \u2514\u2500\u2500 phi_3.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 ensemble/\n\u2502   \u2502       \u251c\u2500\u2500 ENSEMBLE_SELECTION_GUIDE.yaml\n\u2502   \u2502       \u251c\u2500\u2500 presets/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 quick_start.yaml\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 sota_accuracy.yaml\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 balanced.yaml\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u251c\u2500\u2500 voting/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 soft_voting_xlarge.yaml\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 weighted_voting_llm.yaml\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 rank_voting_hybrid.yaml\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u251c\u2500\u2500 stacking/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 stacking_xlarge_xgboost.yaml\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 stacking_llm_lightgbm.yaml\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 stacking_hybrid_catboost.yaml\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u251c\u2500\u2500 blending/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 blending_xlarge.yaml\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 dynamic_blending_llm.yaml\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u2514\u2500\u2500 advanced/\n\u2502   \u2502           \u251c\u2500\u2500 bayesian_ensemble_xlarge.yaml\n\u2502   \u2502           \u251c\u2500\u2500 snapshot_ensemble_llm.yaml\n\u2502   \u2502           \u2514\u2500\u2500 multi_level_ensemble.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 training/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 standard/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base_training.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 mixed_precision.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 distributed.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 platform_adaptive/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 colab_free_training.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 colab_pro_training.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 kaggle_gpu_training.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 kaggle_tpu_training.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local_gpu_training.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 local_cpu_training.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 efficient/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 lora/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_config.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_xlarge.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_llm.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_rank_experiments.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 lora_target_modules_experiments.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 qlora/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 qlora_4bit.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 qlora_8bit.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 qlora_nf4.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 qlora_llm.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 adapters/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 adapter_houlsby.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 adapter_pfeiffer.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 adapter_parallel.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 adapter_fusion.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 adapter_stacking.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prefix_tuning/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 prefix_tuning.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 prefix_tuning_llm.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 prefix_length_experiments.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt_tuning/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 soft_prompt_tuning.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 p_tuning_v2.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 prompt_length_experiments.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ia3/\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ia3_config.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 combined/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 lora_plus_adapters.yaml\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 qlora_plus_prompt.yaml\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 multi_method_fusion.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 tpu/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 kaggle_tpu_v3.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 tpu_optimization.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 advanced/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 curriculum_learning.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 adversarial_training.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 multitask_learning.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 contrastive_learning.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 knowledge_distillation/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 standard_distillation.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama_distillation.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mistral_distillation.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llm_to_xlarge_distillation.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 xlarge_to_large_distillation.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ensemble_distillation.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 self_distillation.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 meta_learning.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 instruction_tuning/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 alpaca_style.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 dolly_style.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 vicuna_style.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 custom_instructions.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 multi_stage/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 stage_manager.yaml\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 progressive_training.yaml\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 iterative_refinement.yaml\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 base_to_xlarge_progressive.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 regularization/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 dropout_strategies/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 standard_dropout.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 variational_dropout.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 dropconnect.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 adaptive_dropout.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 monte_carlo_dropout.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 scheduled_dropout.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 advanced_regularization/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 r_drop.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mixout.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 spectral_normalization.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gradient_penalty.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 weight_decay_schedule.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 elastic_weight_consolidation.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 data_regularization/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mixup.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cutmix.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cutout.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 manifold_mixup.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 augmax.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 combined/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 heavy_regularization.yaml\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 xlarge_safe_config.yaml\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 llm_safe_config.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 safe/\n\u2502   \u2502       \u251c\u2500\u2500 xlarge_safe_training.yaml\n\u2502   \u2502       \u251c\u2500\u2500 llm_safe_training.yaml\n\u2502   \u2502       \u251c\u2500\u2500 ensemble_safe_training.yaml\n\u2502   \u2502       \u2514\u2500\u2500 ultra_safe_training.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 overfitting_prevention/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 constraints/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 model_size_constraints.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 xlarge_constraints.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 llm_constraints.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ensemble_constraints.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 training_constraints.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 parameter_efficiency_requirements.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 monitoring/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 realtime_monitoring.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 thresholds.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 metrics_to_track.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 reporting_schedule.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 validation/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cross_validation_strategy.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 holdout_validation.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_set_protection.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 data_split_rules.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 hyperparameter_tuning_rules.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 recommendations/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 dataset_specific/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ag_news_recommendations.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 small_dataset.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 medium_dataset.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 large_dataset.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 model_recommendations/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 xlarge_models.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llm_models.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 model_selection_guide.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 technique_recommendations/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 lora_recommendations.yaml\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 qlora_recommendations.yaml\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 distillation_recommendations.yaml\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 ensemble_recommendations.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 safe_defaults/\n\u2502   \u2502       \u251c\u2500\u2500 xlarge_safe_defaults.yaml\n\u2502   \u2502       \u251c\u2500\u2500 llm_safe_defaults.yaml\n\u2502   \u2502       \u2514\u2500\u2500 beginner_safe_defaults.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 data/\n\u2502   \u2502   \u251c\u2500\u2500 preprocessing/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 standard.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 advanced.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 llm_preprocessing.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 instruction_formatting.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 domain_specific.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 augmentation/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 safe_augmentation.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 basic_augmentation.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 back_translation.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 paraphrase_generation.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 llm_augmentation/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama_augmentation.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mistral_augmentation.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 controlled_generation.yaml\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 mixup_strategies.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 adversarial_augmentation.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 contrast_sets.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 selection/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 coreset_selection.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 influence_functions.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 active_selection.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 validation/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 stratified_split.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 k_fold_cv.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 nested_cv.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 time_based_split.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 holdout_validation.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 external/\n\u2502   \u2502       \u251c\u2500\u2500 news_corpus.yaml\n\u2502   \u2502       \u251c\u2500\u2500 wikipedia.yaml\n\u2502   \u2502       \u251c\u2500\u2500 domain_adaptive_pretraining.yaml\n\u2502   \u2502       \u2514\u2500\u2500 synthetic_data/\n\u2502   \u2502           \u251c\u2500\u2500 llm_generated.yaml\n\u2502   \u2502           \u2514\u2500\u2500 quality_filtering.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 deployment/\n\u2502   \u2502   \u251c\u2500\u2500 local/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 docker_local.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 api_local.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 inference_local.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 free_tier/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 colab_deployment.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 kaggle_deployment.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 huggingface_spaces.yaml\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 platform_profiles/\n\u2502   \u2502       \u251c\u2500\u2500 colab_profile.yaml\n\u2502   \u2502       \u251c\u2500\u2500 kaggle_profile.yaml\n\u2502   \u2502       \u251c\u2500\u2500 gitpod_profile.yaml\n\u2502   \u2502       \u251c\u2500\u2500 codespaces_profile.yaml\n\u2502   \u2502       \u2514\u2500\u2500 hf_spaces_profile.yaml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 quotas/\n\u2502   \u2502   \u251c\u2500\u2500 quota_limits.yaml\n\u2502   \u2502   \u251c\u2500\u2500 quota_tracking.yaml\n\u2502   \u2502   \u2514\u2500\u2500 platform_quotas.yaml\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 experiments/\n\u2502       \u251c\u2500\u2500 baselines/\n\u2502       \u2502   \u251c\u2500\u2500 classical_ml.yaml\n\u2502       \u2502   \u2514\u2500\u2500 transformer_baseline.yaml\n\u2502       \u2502\n\u2502       \u251c\u2500\u2500 ablations/\n\u2502       \u2502   \u251c\u2500\u2500 model_size_ablation.yaml\n\u2502       \u2502   \u251c\u2500\u2500 data_amount.yaml\n\u2502       \u2502   \u251c\u2500\u2500 lora_rank_ablation.yaml\n\u2502       \u2502   \u251c\u2500\u2500 qlora_bits_ablation.yaml\n\u2502       \u2502   \u251c\u2500\u2500 regularization_ablation.yaml\n\u2502       \u2502   \u251c\u2500\u2500 augmentation_impact.yaml\n\u2502       \u2502   \u251c\u2500\u2500 ensemble_size_ablation.yaml\n\u2502       \u2502   \u251c\u2500\u2500 ensemble_components.yaml\n\u2502       \u2502   \u251c\u2500\u2500 prompt_ablation.yaml\n\u2502       \u2502   \u2514\u2500\u2500 distillation_temperature_ablation.yaml\n\u2502       \u2502\n\u2502       \u251c\u2500\u2500 hyperparameter_search/\n\u2502       \u2502   \u251c\u2500\u2500 lora_search.yaml\n\u2502       \u2502   \u251c\u2500\u2500 qlora_search.yaml\n\u2502       \u2502   \u251c\u2500\u2500 regularization_search.yaml\n\u2502       \u2502   \u2514\u2500\u2500 ensemble_weights_search.yaml\n\u2502       \u2502\n\u2502       \u251c\u2500\u2500 sota_experiments/\n\u2502       \u2502   \u251c\u2500\u2500 phase1_xlarge_models.yaml\n\u2502       \u2502   \u251c\u2500\u2500 phase2_llm_models.yaml\n\u2502       \u2502   \u251c\u2500\u2500 phase3_llm_distillation.yaml\n\u2502       \u2502   \u251c\u2500\u2500 phase4_ensemble_sota.yaml\n\u2502       \u2502   \u251c\u2500\u2500 phase5_ultimate_sota.yaml\n\u2502       \u2502   \u2514\u2500\u2500 phase6_production_sota.yaml\n\u2502       \u2502\n\u2502       \u2514\u2500\u2500 reproducibility/\n\u2502           \u251c\u2500\u2500 seeds.yaml\n\u2502           \u2514\u2500\u2500 hardware_specs.yaml\n\u2502\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 raw/\n\u2502   \u2502   \u251c\u2500\u2500 ag_news/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 train.csv\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test.csv\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2502   \u2514\u2500\u2500 .gitkeep\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 processed/\n\u2502   \u2502   \u251c\u2500\u2500 train/\n\u2502   \u2502   \u251c\u2500\u2500 validation/\n\u2502   \u2502   \u251c\u2500\u2500 test/\n\u2502   \u2502   \u251c\u2500\u2500 stratified_folds/\n\u2502   \u2502   \u251c\u2500\u2500 instruction_formatted/\n\u2502   \u2502   \u2514\u2500\u2500 .test_set_hash\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 augmented/\n\u2502   \u2502   \u251c\u2500\u2500 back_translated/\n\u2502   \u2502   \u251c\u2500\u2500 paraphrased/\n\u2502   \u2502   \u251c\u2500\u2500 synthetic/\n\u2502   \u2502   \u251c\u2500\u2500 llm_generated/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 llama2/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 mistral/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 mixtral/\n\u2502   \u2502   \u251c\u2500\u2500 mixup/\n\u2502   \u2502   \u2514\u2500\u2500 contrast_sets/\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 external/\n\u2502   \u2502   \u251c\u2500\u2500 news_corpus/\n\u2502   \u2502   \u251c\u2500\u2500 pretrain_data/\n\u2502   \u2502   \u2514\u2500\u2500 distillation_data/\n\u2502   \u2502       \u251c\u2500\u2500 llama_outputs/\n\u2502   \u2502       \u251c\u2500\u2500 mistral_outputs/\n\u2502   \u2502       \u2514\u2500\u2500 teacher_ensemble_outputs/\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 pseudo_labeled/\n\u2502   \u251c\u2500\u2500 selected_subsets/\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 test_samples/\n\u2502   \u2502   \u251c\u2500\u2500 api_test_cases.json\n\u2502   \u2502   \u2514\u2500\u2500 mock_responses.json\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 metadata/\n\u2502   \u2502   \u251c\u2500\u2500 split_info.json\n\u2502   \u2502   \u251c\u2500\u2500 statistics.json\n\u2502   \u2502   \u251c\u2500\u2500 leakage_check.json\n\u2502   \u2502   \u2514\u2500\u2500 model_predictions/\n\u2502   \u2502       \u251c\u2500\u2500 xlarge_predictions.json\n\u2502   \u2502       \u251c\u2500\u2500 llm_predictions.json\n\u2502   \u2502       \u2514\u2500\u2500 ensemble_predictions.json\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 test_access_log.json\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 platform_cache/\n\u2502   \u2502   \u251c\u2500\u2500 colab_cache/\n\u2502   \u2502   \u251c\u2500\u2500 kaggle_cache/\n\u2502   \u2502   \u2514\u2500\u2500 local_cache/\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 quota_tracking/\n\u2502   \u2502   \u251c\u2500\u2500 quota_history.json\n\u2502   \u2502   \u251c\u2500\u2500 session_logs.json\n\u2502   \u2502   \u2514\u2500\u2500 platform_usage.db\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 cache/\n\u2502       \u251c\u2500\u2500 local_cache/\n\u2502       \u251c\u2500\u2500 model_cache/\n\u2502       \u2514\u2500\u2500 huggingface_cache/\n\u2502\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 __version__.py\n\u2502   \u251c\u2500\u2500 cli.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 cli_commands/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 auto_train.py\n\u2502   \u2502   \u251c\u2500\u2500 choose_platform.py\n\u2502   \u2502   \u251c\u2500\u2500 check_quota.py\n\u2502   \u2502   \u2514\u2500\u2500 platform_info.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 core/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 registry.py\n\u2502   \u2502   \u251c\u2500\u2500 factory.py\n\u2502   \u2502   \u251c\u2500\u2500 types.py\n\u2502   \u2502   \u251c\u2500\u2500 exceptions.py\n\u2502   \u2502   \u251c\u2500\u2500 interfaces.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 health/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 health_checker.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 dependency_checker.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 gpu_checker.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 config_checker.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 data_checker.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 auto_fix/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 config_fixer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 dependency_fixer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cache_cleaner.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 ide_sync_fixer.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 overfitting_prevention/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u251c\u2500\u2500 validators/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 test_set_validator.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 config_validator.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 data_leakage_detector.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 hyperparameter_validator.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 split_validator.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 model_size_validator.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 lora_config_validator.py\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 ensemble_validator.py\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u251c\u2500\u2500 monitors/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 training_monitor.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 overfitting_detector.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 complexity_monitor.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 benchmark_comparator.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 metrics_tracker.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 gradient_monitor.py\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 lora_rank_monitor.py\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u251c\u2500\u2500 constraints/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 model_constraints.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 ensemble_constraints.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 augmentation_constraints.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 training_constraints.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 constraint_enforcer.py\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 parameter_efficiency_enforcer.py\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u251c\u2500\u2500 guards/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 test_set_guard.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 validation_guard.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 experiment_guard.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 access_control.py\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 parameter_freeze_guard.py\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u251c\u2500\u2500 recommendations/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 model_recommender.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 config_recommender.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 prevention_recommender.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 ensemble_recommender.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 lora_recommender.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 distillation_recommender.py\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 parameter_efficiency_recommender.py\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u251c\u2500\u2500 reporting/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 overfitting_reporter.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 risk_scorer.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 comparison_reporter.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 html_report_generator.py\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 parameter_efficiency_reporter.py\n\u2502   \u2502       \u2502\n\u2502   \u2502       \u2514\u2500\u2500 utils/\n\u2502   \u2502           \u251c\u2500\u2500 __init__.py\n\u2502   \u2502           \u251c\u2500\u2500 hash_utils.py\n\u2502   \u2502           \u251c\u2500\u2500 statistical_tests.py\n\u2502   \u2502           \u2514\u2500\u2500 visualization_utils.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 deployment/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 platform_detector.py\n\u2502   \u2502   \u251c\u2500\u2500 smart_selector.py\n\u2502   \u2502   \u251c\u2500\u2500 cache_manager.py\n\u2502   \u2502   \u251c\u2500\u2500 checkpoint_manager.py\n\u2502   \u2502   \u251c\u2500\u2500 quota_tracker.py\n\u2502   \u2502   \u251c\u2500\u2500 storage_sync.py\n\u2502   \u2502   \u251c\u2500\u2500 session_manager.py\n\u2502   \u2502   \u2514\u2500\u2500 resource_monitor.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 base/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base_handler.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 auth.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 rate_limiter.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 error_handler.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cors_handler.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 request_validator.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 rest/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 app.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 routers/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 classification.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 training.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 models.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 data.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 health.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 metrics.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 overfitting.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llm.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 platform.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 admin.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 schemas/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 request_schemas.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 response_schemas.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 error_schemas.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 common_schemas.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 middleware/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 logging_middleware.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 metrics_middleware.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 security_middleware.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 dependencies.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 validators.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 websocket_handler.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 local/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 simple_api.py\n\u2502   \u2502       \u251c\u2500\u2500 batch_api.py\n\u2502   \u2502       \u2514\u2500\u2500 streaming_api.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 services/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 base_service.py\n\u2502   \u2502   \u251c\u2500\u2500 service_registry.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 core/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prediction_service.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 training_service.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 data_service.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 model_management_service.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 llm_service.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 local/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local_cache_service.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local_queue_service.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 file_storage_service.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 monitoring/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 monitoring_router.py\n\u2502   \u2502       \u251c\u2500\u2500 tensorboard_service.py\n\u2502   \u2502       \u251c\u2500\u2500 mlflow_service.py\n\u2502   \u2502       \u251c\u2500\u2500 wandb_service.py\n\u2502   \u2502       \u251c\u2500\u2500 local_metrics_service.py\n\u2502   \u2502       \u2514\u2500\u2500 logging_service.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 data/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 datasets/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ag_news.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 external_news.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 combined_dataset.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompted_dataset.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 instruction_dataset.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 distillation_dataset.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 preprocessing/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 text_cleaner.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 tokenization.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 feature_extraction.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 sliding_window.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt_formatter.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 instruction_formatter.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 augmentation/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base_augmenter.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 back_translation.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 paraphrase.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 token_replacement.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 mixup.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cutmix.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 adversarial.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 contrast_set_generator.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 llm_augmenter/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 llama_augmenter.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 mistral_augmenter.py\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 controlled_generation.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 sampling/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 balanced_sampler.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 curriculum_sampler.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 active_learning.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 uncertainty_sampling.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 coreset_sampler.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 selection/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 influence_function.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 gradient_matching.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 diversity_selection.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 quality_filtering.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 validation/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 split_strategies.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cross_validator.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 nested_cross_validator.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 holdout_manager.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 loaders/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 dataloader.py\n\u2502   \u2502       \u251c\u2500\u2500 dynamic_batching.py\n\u2502   \u2502       \u2514\u2500\u2500 prefetch_loader.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 base/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base_model.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 model_wrapper.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 complexity_tracker.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 pooling_strategies.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 transformers/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v3_base.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v3_large.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v3_xlarge.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v2_xlarge.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_v2_xxlarge.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deberta_sliding_window.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 deberta_hierarchical.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta_base.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta_large.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta_large_mnli.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta_enhanced.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta_domain.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 xlm_roberta_large.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 electra/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 electra_base.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 electra_large.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 electra_discriminator.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 xlnet/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 xlnet_base.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 xlnet_large.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 xlnet_classifier.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 longformer/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 longformer_large.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 longformer_global.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 t5/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 t5_base.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 t5_large.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 t5_3b.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 flan_t5_xl.py\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 t5_classifier.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 llm/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 llama/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama2_7b.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama2_13b.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama2_70b.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama3_8b.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama3_70b.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 llama_for_classification.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 mistral/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mistral_7b.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mistral_7b_instruct.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mixtral_8x7b.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 mistral_for_classification.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 falcon/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 falcon_7b.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 falcon_40b.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 falcon_for_classification.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 mpt/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mpt_7b.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mpt_30b.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 mpt_for_classification.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 phi/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 phi_2.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 phi_3.py\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 phi_for_classification.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 prompt_based/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt_model.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 soft_prompt.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 instruction_model.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 template_manager.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 efficient/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 lora/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_model.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_config.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_layers.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_utils.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 rank_selection.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 target_modules_selector.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 qlora/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 qlora_model.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 qlora_config.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 quantization.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 dequantization.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 adapters/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 adapter_model.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 adapter_config.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 houlsby_adapter.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 pfeiffer_adapter.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 parallel_adapter.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 adapter_fusion.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 adapter_stacking.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prefix_tuning/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 prefix_tuning_model.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 prefix_encoder.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 prefix_length_selector.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt_tuning/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 soft_prompt_model.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt_encoder.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 p_tuning_v2.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 prompt_initialization.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ia3/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ia3_model.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 quantization/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 int8_quantization.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 dynamic_quantization.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 pruning/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 magnitude_pruning.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 combined/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 lora_plus_adapter.py\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 multi_method_model.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 ensemble/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base_ensemble.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ensemble_selector.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 voting/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 soft_voting.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 hard_voting.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 weighted_voting.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 rank_averaging.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 confidence_weighted_voting.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 stacking/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 stacking_classifier.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 meta_learners.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cross_validation_stacking.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 neural_stacking.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 blending/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 blending_ensemble.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 dynamic_blending.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 advanced/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 bayesian_ensemble.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 snapshot_ensemble.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 multi_level_ensemble.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 mixture_of_experts.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 diversity/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 diversity_calculator.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 diversity_optimizer.py\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 ensemble_pruning.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 heads/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 classification_head.py\n\u2502   \u2502       \u251c\u2500\u2500 multitask_head.py\n\u2502   \u2502       \u251c\u2500\u2500 hierarchical_head.py\n\u2502   \u2502       \u251c\u2500\u2500 attention_head.py\n\u2502   \u2502       \u251c\u2500\u2500 prompt_head.py\n\u2502   \u2502       \u2514\u2500\u2500 adaptive_head.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 training/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 trainers/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 standard_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 distributed_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 apex_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 safe_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 auto_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 qlora_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 adapter_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 instruction_trainer.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 multi_stage_trainer.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 strategies/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 curriculum/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 curriculum_learning.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 self_paced.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 competence_based.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 adversarial/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 fgm.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 pgd.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 freelb.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 smart.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 regularization/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 r_drop.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mixout.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 spectral_norm.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 adaptive_dropout.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gradient_penalty.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 elastic_weight_consolidation.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 sharpness_aware_minimization.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 distillation/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 knowledge_distillation.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 feature_distillation.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 self_distillation.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llama_distillation.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 mistral_distillation.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ensemble_distillation.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 progressive_distillation.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 meta/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 maml.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 reptile.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt_based/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt_tuning.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 prefix_tuning.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 p_tuning.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 soft_prompt_tuning.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 tpu_training.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 adaptive_training.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 multi_stage/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 stage_manager.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 progressive_training.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 iterative_refinement.py\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 base_to_xlarge_progression.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 objectives/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 losses/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 focal_loss.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 label_smoothing.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 contrastive_loss.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 triplet_loss.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 custom_ce_loss.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 instruction_loss.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 distillation_loss.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 regularizers/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 l2_regularizer.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 gradient_penalty.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 complexity_regularizer.py\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 parameter_norm_regularizer.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 optimization/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 optimizers/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 adamw_custom.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 lamb.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 lookahead.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 sam.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 adafactor.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 schedulers/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cosine_warmup.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 polynomial_decay.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cyclic_scheduler.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 inverse_sqrt_scheduler.py\n\u2502   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 gradient/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 gradient_accumulation.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 gradient_clipping.py\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 gradient_checkpointing.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 callbacks/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 early_stopping.py\n\u2502   \u2502       \u251c\u2500\u2500 model_checkpoint.py\n\u2502   \u2502       \u251c\u2500\u2500 tensorboard_logger.py\n\u2502   \u2502       \u251c\u2500\u2500 wandb_logger.py\n\u2502   \u2502       \u251c\u2500\u2500 mlflow_logger.py\n\u2502   \u2502       \u251c\u2500\u2500 learning_rate_monitor.py\n\u2502   \u2502       \u251c\u2500\u2500 overfitting_monitor.py\n\u2502   \u2502       \u251c\u2500\u2500 complexity_regularizer_callback.py\n\u2502   \u2502       \u251c\u2500\u2500 test_protection_callback.py\n\u2502   \u2502       \u251c\u2500\u2500 lora_rank_callback.py\n\u2502   \u2502       \u251c\u2500\u2500 memory_monitor_callback.py\n\u2502   \u2502       \u251c\u2500\u2500 colab_callback.py\n\u2502   \u2502       \u251c\u2500\u2500 kaggle_callback.py\n\u2502   \u2502       \u251c\u2500\u2500 platform_callback.py\n\u2502   \u2502       \u251c\u2500\u2500 quota_callback.py\n\u2502   \u2502       \u2514\u2500\u2500 session_callback.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 evaluation/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 metrics/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 classification_metrics.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 overfitting_metrics.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 diversity_metrics.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 efficiency_metrics.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 analysis/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 error_analysis.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 overfitting_analysis.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 train_val_test_comparison.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_rank_analysis.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 ensemble_analysis.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 visualizations/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 training_curves.py\n\u2502   \u2502       \u251c\u2500\u2500 confusion_matrix.py\n\u2502   \u2502       \u251c\u2500\u2500 attention_visualization.py\n\u2502   \u2502       \u2514\u2500\u2500 lora_weight_visualization.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 inference/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 predictors/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 single_predictor.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ensemble_predictor.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 lora_predictor.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 qlora_predictor.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 optimization/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 model_quantization.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 model_pruning.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 onnx_export.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 openvino_optimization.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 serving/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 local_server.py\n\u2502   \u2502       \u251c\u2500\u2500 batch_predictor.py\n\u2502   \u2502       \u2514\u2500\u2500 streaming_predictor.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 utils/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 io_utils.py\n\u2502       \u251c\u2500\u2500 logging_config.py\n\u2502       \u251c\u2500\u2500 reproducibility.py\n\u2502       \u251c\u2500\u2500 distributed_utils.py\n\u2502       \u251c\u2500\u2500 memory_utils.py\n\u2502       \u251c\u2500\u2500 profiling_utils.py\n\u2502       \u251c\u2500\u2500 experiment_tracking.py\n\u2502       \u251c\u2500\u2500 prompt_utils.py\n\u2502       \u251c\u2500\u2500 api_utils.py\n\u2502       \u251c\u2500\u2500 local_utils.py\n\u2502       \u251c\u2500\u2500 platform_utils.py\n\u2502       \u251c\u2500\u2500 resource_utils.py\n\u2502       \u2514\u2500\u2500 quota_utils.py\n\u2502\n\u251c\u2500\u2500 experiments/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 experiment_runner.py\n\u2502   \u251c\u2500\u2500 experiment_tagger.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 hyperparameter_search/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 optuna_search.py\n\u2502   \u2502   \u251c\u2500\u2500 ray_tune_search.py\n\u2502   \u2502   \u251c\u2500\u2500 hyperband.py\n\u2502   \u2502   \u251c\u2500\u2500 bayesian_optimization.py\n\u2502   \u2502   \u251c\u2500\u2500 lora_rank_search.py\n\u2502   \u2502   \u2514\u2500\u2500 ensemble_weight_search.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 benchmarks/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 speed_benchmark.py\n\u2502   \u2502   \u251c\u2500\u2500 memory_benchmark.py\n\u2502   \u2502   \u251c\u2500\u2500 accuracy_benchmark.py\n\u2502   \u2502   \u251c\u2500\u2500 robustness_benchmark.py\n\u2502   \u2502   \u251c\u2500\u2500 sota_comparison.py\n\u2502   \u2502   \u251c\u2500\u2500 overfitting_benchmark.py\n\u2502   \u2502   \u2514\u2500\u2500 parameter_efficiency_benchmark.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 baselines/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 classical/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 naive_bayes.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 svm_baseline.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 random_forest.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 logistic_regression.py\n\u2502   \u2502   \u2514\u2500\u2500 neural/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 lstm_baseline.py\n\u2502   \u2502       \u251c\u2500\u2500 cnn_baseline.py\n\u2502   \u2502       \u2514\u2500\u2500 bert_vanilla.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 ablation_studies/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 component_ablation.py\n\u2502   \u2502   \u251c\u2500\u2500 data_ablation.py\n\u2502   \u2502   \u251c\u2500\u2500 model_size_ablation.py\n\u2502   \u2502   \u251c\u2500\u2500 feature_ablation.py\n\u2502   \u2502   \u251c\u2500\u2500 lora_rank_ablation.py\n\u2502   \u2502   \u251c\u2500\u2500 qlora_bits_ablation.py\n\u2502   \u2502   \u251c\u2500\u2500 regularization_ablation.py\n\u2502   \u2502   \u251c\u2500\u2500 prompt_ablation.py\n\u2502   \u2502   \u2514\u2500\u2500 distillation_temperature_ablation.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 sota_experiments/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 phase1_xlarge_lora.py\n\u2502   \u2502   \u251c\u2500\u2500 phase2_llm_qlora.py\n\u2502   \u2502   \u251c\u2500\u2500 phase3_llm_distillation.py\n\u2502   \u2502   \u251c\u2500\u2500 phase4_ensemble_xlarge.py\n\u2502   \u2502   \u251c\u2500\u2500 phase5_ultimate_sota.py\n\u2502   \u2502   \u251c\u2500\u2500 single_model_sota.py\n\u2502   \u2502   \u251c\u2500\u2500 ensemble_sota.py\n\u2502   \u2502   \u251c\u2500\u2500 full_pipeline_sota.py\n\u2502   \u2502   \u251c\u2500\u2500 production_sota.py\n\u2502   \u2502   \u251c\u2500\u2500 prompt_based_sota.py\n\u2502   \u2502   \u2514\u2500\u2500 compare_all_approaches.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 results/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 experiment_tracker.py\n\u2502       \u251c\u2500\u2500 result_aggregator.py\n\u2502       \u2514\u2500\u2500 leaderboard_generator.py\n\u2502\n\u251c\u2500\u2500 monitoring/\n\u2502   \u251c\u2500\u2500 README.md\n\u2502   \u251c\u2500\u2500 local/\n\u2502   \u2502   \u251c\u2500\u2500 docker-compose.local.yml\n\u2502   \u2502   \u251c\u2500\u2500 tensorboard_config.yaml\n\u2502   \u2502   \u251c\u2500\u2500 mlflow_config.yaml\n\u2502   \u2502   \u2514\u2500\u2500 setup_local_monitoring.sh\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 dashboards/\n\u2502   \u2502   \u251c\u2500\u2500 tensorboard/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 scalar_config.json\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 image_config.json\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 custom_scalars.json\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 mlflow/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 experiment_dashboard.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 model_registry.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 wandb/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 training_dashboard.json\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 overfitting_dashboard.json\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 parameter_efficiency_dashboard.json\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 platform_dashboard.json\n\u2502   \u2502   \u2514\u2500\u2500 quota_dashboard.json\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 metrics/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 custom_metrics.py\n\u2502   \u2502   \u251c\u2500\u2500 metric_collectors.py\n\u2502   \u2502   \u251c\u2500\u2500 local_metrics.py\n\u2502   \u2502   \u251c\u2500\u2500 model_metrics.py\n\u2502   \u2502   \u251c\u2500\u2500 training_metrics.py\n\u2502   \u2502   \u251c\u2500\u2500 overfitting_metrics.py\n\u2502   \u2502   \u251c\u2500\u2500 platform_metrics.py\n\u2502   \u2502   \u2514\u2500\u2500 quota_metrics.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 logs_analysis/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 log_parser.py\n\u2502   \u2502   \u251c\u2500\u2500 anomaly_detector.py\n\u2502   \u2502   \u2514\u2500\u2500 log_aggregator.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 scripts/\n\u2502       \u251c\u2500\u2500 start_tensorboard.sh\n\u2502       \u251c\u2500\u2500 start_mlflow.sh\n\u2502       \u251c\u2500\u2500 start_wandb.sh\n\u2502       \u251c\u2500\u2500 monitor_platform.sh\n\u2502       \u251c\u2500\u2500 export_metrics.py\n\u2502       \u251c\u2500\u2500 export_quota_metrics.py\n\u2502       \u2514\u2500\u2500 generate_report.py\n\u2502\n\u251c\u2500\u2500 security/\n\u2502   \u251c\u2500\u2500 local_auth/\n\u2502   \u2502   \u251c\u2500\u2500 simple_token.py\n\u2502   \u2502   \u2514\u2500\u2500 local_rbac.py\n\u2502   \u251c\u2500\u2500 data_privacy/\n\u2502   \u2502   \u251c\u2500\u2500 pii_detector.py\n\u2502   \u2502   \u2514\u2500\u2500 data_masking.py\n\u2502   \u2514\u2500\u2500 model_security/\n\u2502       \u251c\u2500\u2500 adversarial_defense.py\n\u2502       \u2514\u2500\u2500 model_checksum.py\n\u2502\n\u251c\u2500\u2500 plugins/\n\u2502   \u251c\u2500\u2500 custom_models/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 plugin_interface.py\n\u2502   \u251c\u2500\u2500 data_sources/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 custom_loaders/\n\u2502   \u251c\u2500\u2500 evaluators/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 custom_metrics/\n\u2502   \u2514\u2500\u2500 processors/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 custom_preprocessors/\n\u2502\n\u251c\u2500\u2500 migrations/\n\u2502   \u251c\u2500\u2500 data/\n\u2502   \u2502   \u251c\u2500\u2500 001_initial_schema.py\n\u2502   \u2502   \u2514\u2500\u2500 migration_runner.py\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u251c\u2500\u2500 version_converter.py\n\u2502   \u2502   \u2514\u2500\u2500 compatibility_layer.py\n\u2502   \u2514\u2500\u2500 configs/\n\u2502       \u2514\u2500\u2500 config_migrator.py\n\u2502\n\u251c\u2500\u2500 cache/\n\u2502   \u251c\u2500\u2500 local/\n\u2502   \u2502   \u251c\u2500\u2500 disk_cache.py\n\u2502   \u2502   \u251c\u2500\u2500 memory_cache.py\n\u2502   \u2502   \u2514\u2500\u2500 lru_cache.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 sqlite/\n\u2502       \u2514\u2500\u2500 cache_db_schema.sql\n\u2502\n\u251c\u2500\u2500 backup/\n\u2502   \u251c\u2500\u2500 strategies/\n\u2502   \u2502   \u251c\u2500\u2500 incremental_backup.yaml\n\u2502   \u2502   \u2514\u2500\u2500 local_backup.yaml\n\u2502   \u251c\u2500\u2500 scripts/\n\u2502   \u2502   \u251c\u2500\u2500 backup_local.sh\n\u2502   \u2502   \u2514\u2500\u2500 restore_local.sh\n\u2502   \u2514\u2500\u2500 recovery/\n\u2502       \u2514\u2500\u2500 local_recovery_plan.md\n\u2502\n\u251c\u2500\u2500 quickstart/\n\u2502   \u251c\u2500\u2500 README.md\n\u2502   \u251c\u2500\u2500 SIMPLE_START.md\n\u2502   \u251c\u2500\u2500 setup_wizard.py\n\u2502   \u251c\u2500\u2500 interactive_cli.py\n\u2502   \u251c\u2500\u2500 decision_tree.py\n\u2502   \u251c\u2500\u2500 minimal_example.py\n\u2502   \u251c\u2500\u2500 train_simple.py\n\u2502   \u251c\u2500\u2500 evaluate_simple.py\n\u2502   \u251c\u2500\u2500 demo_app.py\n\u2502   \u251c\u2500\u2500 local_api_quickstart.py\n\u2502   \u251c\u2500\u2500 auto_start.py\n\u2502   \u251c\u2500\u2500 auto_train_demo.py\n\u2502   \u251c\u2500\u2500 colab_notebook.ipynb\n\u2502   \u251c\u2500\u2500 kaggle_notebook.ipynb\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 use_cases/\n\u2502   \u2502   \u251c\u2500\u2500 quick_demo_5min.py\n\u2502   \u2502   \u251c\u2500\u2500 auto_demo_2min.py\n\u2502   \u2502   \u251c\u2500\u2500 research_experiment_30min.py\n\u2502   \u2502   \u251c\u2500\u2500 production_deployment_1hr.py\n\u2502   \u2502   \u251c\u2500\u2500 learning_exploration.py\n\u2502   \u2502   \u2514\u2500\u2500 platform_comparison_demo.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 docker_quickstart/\n\u2502       \u251c\u2500\u2500 Dockerfile.local\n\u2502       \u2514\u2500\u2500 docker-compose.local.yml\n\u2502\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 experiment/\n\u2502   \u2502   \u251c\u2500\u2500 experiment_template.py\n\u2502   \u2502   \u2514\u2500\u2500 config_template.yaml\n\u2502   \u251c\u2500\u2500 model/\n\u2502   \u2502   \u251c\u2500\u2500 model_template.py\n\u2502   \u2502   \u2514\u2500\u2500 README_template.md\n\u2502   \u251c\u2500\u2500 dataset/\n\u2502   \u2502   \u2514\u2500\u2500 dataset_template.py\n\u2502   \u251c\u2500\u2500 evaluation/\n\u2502   \u2502   \u2514\u2500\u2500 metric_template.py\n\u2502   \u2514\u2500\u2500 ide/\n\u2502       \u251c\u2500\u2500 pycharm_run_config.xml\n\u2502       \u251c\u2500\u2500 vscode_task.json\n\u2502       \u2514\u2500\u2500 jupyter_template.ipynb\n\u2502\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 setup/\n\u2502   \u2502   \u251c\u2500\u2500 download_all_data.py\n\u2502   \u2502   \u251c\u2500\u2500 setup_local_environment.sh\n\u2502   \u2502   \u251c\u2500\u2500 setup_platform.py\n\u2502   \u2502   \u251c\u2500\u2500 setup_colab.sh\n\u2502   \u2502   \u251c\u2500\u2500 setup_kaggle.sh\n\u2502   \u2502   \u251c\u2500\u2500 verify_installation.py\n\u2502   \u2502   \u251c\u2500\u2500 verify_dependencies.py\n\u2502   \u2502   \u251c\u2500\u2500 verify_platform.py\n\u2502   \u2502   \u251c\u2500\u2500 optimize_for_platform.sh\n\u2502   \u2502   \u2514\u2500\u2500 download_pretrained_models.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 data_preparation/\n\u2502   \u2502   \u251c\u2500\u2500 prepare_ag_news.py\n\u2502   \u2502   \u251c\u2500\u2500 prepare_external_data.py\n\u2502   \u2502   \u251c\u2500\u2500 create_augmented_data.py\n\u2502   \u2502   \u251c\u2500\u2500 create_instruction_data.py\n\u2502   \u2502   \u251c\u2500\u2500 generate_with_llama.py\n\u2502   \u2502   \u251c\u2500\u2500 generate_with_mistral.py\n\u2502   \u2502   \u251c\u2500\u2500 generate_pseudo_labels.py\n\u2502   \u2502   \u251c\u2500\u2500 create_data_splits.py\n\u2502   \u2502   \u251c\u2500\u2500 generate_contrast_sets.py\n\u2502   \u2502   \u251c\u2500\u2500 select_quality_data.py\n\u2502   \u2502   \u251c\u2500\u2500 verify_data_splits.py\n\u2502   \u2502   \u2514\u2500\u2500 register_test_set.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 training/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 single_model/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 train_xlarge_lora.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 train_xxlarge_qlora.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 train_llm_qlora.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 train_with_adapters.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 ensemble/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 train_xlarge_ensemble.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 train_llm_ensemble.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 train_hybrid_ensemble.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 distillation/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 distill_from_llama.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 distill_from_mistral.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 distill_from_ensemble.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 progressive_distillation.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 instruction_tuning/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 instruction_tuning_llama.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 instruction_tuning_mistral.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 multi_stage/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 base_to_xlarge.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 pretrain_finetune_distill.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 auto_train.sh\n\u2502   \u2502   \u251c\u2500\u2500 train_all_models.sh\n\u2502   \u2502   \u251c\u2500\u2500 train_single_model.py\n\u2502   \u2502   \u251c\u2500\u2500 train_ensemble.py\n\u2502   \u2502   \u251c\u2500\u2500 train_local.py\n\u2502   \u2502   \u251c\u2500\u2500 resume_training.py\n\u2502   \u2502   \u2514\u2500\u2500 train_with_prompts.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 domain_adaptation/\n\u2502   \u2502   \u251c\u2500\u2500 pretrain_on_news.py\n\u2502   \u2502   \u251c\u2500\u2500 download_news_corpus.py\n\u2502   \u2502   \u2514\u2500\u2500 run_dapt.sh\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 evaluation/\n\u2502   \u2502   \u251c\u2500\u2500 evaluate_all_models.py\n\u2502   \u2502   \u251c\u2500\u2500 evaluate_with_guard.py\n\u2502   \u2502   \u251c\u2500\u2500 final_evaluation.py\n\u2502   \u2502   \u251c\u2500\u2500 generate_reports.py\n\u2502   \u2502   \u251c\u2500\u2500 create_leaderboard.py\n\u2502   \u2502   \u251c\u2500\u2500 check_overfitting.py\n\u2502   \u2502   \u251c\u2500\u2500 evaluate_parameter_efficiency.py\n\u2502   \u2502   \u251c\u2500\u2500 statistical_analysis.py\n\u2502   \u2502   \u2514\u2500\u2500 evaluate_contrast_sets.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 optimization/\n\u2502   \u2502   \u251c\u2500\u2500 hyperparameter_search.py\n\u2502   \u2502   \u251c\u2500\u2500 lora_rank_search.py\n\u2502   \u2502   \u251c\u2500\u2500 ensemble_optimization.py\n\u2502   \u2502   \u251c\u2500\u2500 quantization_optimization.py\n\u2502   \u2502   \u251c\u2500\u2500 architecture_search.py\n\u2502   \u2502   \u2514\u2500\u2500 prompt_optimization.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 deployment/\n\u2502   \u2502   \u251c\u2500\u2500 export_models.py\n\u2502   \u2502   \u251c\u2500\u2500 optimize_for_inference.py\n\u2502   \u2502   \u251c\u2500\u2500 create_docker_local.sh\n\u2502   \u2502   \u251c\u2500\u2500 deploy_to_local.py\n\u2502   \u2502   \u251c\u2500\u2500 deploy_auto.py\n\u2502   \u2502   \u2514\u2500\u2500 deploy_to_hf_spaces.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 overfitting_prevention/\n\u2502   \u2502   \u251c\u2500\u2500 get_model_recommendations.py\n\u2502   \u2502   \u251c\u2500\u2500 validate_experiment_config.py\n\u2502   \u2502   \u251c\u2500\u2500 check_data_leakage.py\n\u2502   \u2502   \u251c\u2500\u2500 monitor_training_live.py\n\u2502   \u2502   \u2514\u2500\u2500 generate_overfitting_report.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 platform/\n\u2502   \u2502   \u251c\u2500\u2500 colab/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 mount_drive.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 setup_colab.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 keep_alive.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 kaggle/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 setup_kaggle.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 setup_tpu.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 create_dataset.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 local/\n\u2502   \u2502       \u251c\u2500\u2500 detect_gpu.py\n\u2502   \u2502       \u2514\u2500\u2500 optimize_local.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 monitoring/\n\u2502   \u2502   \u251c\u2500\u2500 monitor_quota.py\n\u2502   \u2502   \u2514\u2500\u2500 monitor_session.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 ide/\n\u2502   \u2502   \u251c\u2500\u2500 setup_pycharm.py\n\u2502   \u2502   \u251c\u2500\u2500 setup_vscode.py\n\u2502   \u2502   \u251c\u2500\u2500 setup_jupyter.py\n\u2502   \u2502   \u251c\u2500\u2500 setup_vim.py\n\u2502   \u2502   \u2514\u2500\u2500 setup_all_ides.sh\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 local/\n\u2502   \u2502   \u251c\u2500\u2500 start_local_api.sh\n\u2502   \u2502   \u251c\u2500\u2500 start_monitoring.sh\n\u2502   \u2502   \u251c\u2500\u2500 cleanup_cache.sh\n\u2502   \u2502   \u2514\u2500\u2500 backup_experiments.sh\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 ci/\n\u2502       \u251c\u2500\u2500 run_tests.sh\n\u2502       \u251c\u2500\u2500 run_benchmarks.sh\n\u2502       \u251c\u2500\u2500 build_docker_local.sh\n\u2502       \u251c\u2500\u2500 test_local_deployment.sh\n\u2502       \u251c\u2500\u2500 check_docs_sync.py\n\u2502       \u2514\u2500\u2500 verify_all.sh\n\u2502\n\u251c\u2500\u2500 prompts/\n\u2502   \u251c\u2500\u2500 classification/\n\u2502   \u2502   \u251c\u2500\u2500 zero_shot.txt\n\u2502   \u2502   \u251c\u2500\u2500 few_shot.txt\n\u2502   \u2502   \u2514\u2500\u2500 chain_of_thought.txt\n\u2502   \u251c\u2500\u2500 instruction/\n\u2502   \u2502   \u251c\u2500\u2500 base_instruction.txt\n\u2502   \u2502   \u251c\u2500\u2500 detailed_instruction.txt\n\u2502   \u2502   \u2514\u2500\u2500 task_specific.txt\n\u2502   \u2514\u2500\u2500 distillation/\n\u2502       \u251c\u2500\u2500 llm_prompts.txt\n\u2502       \u2514\u2500\u2500 explanation_prompts.txt\n\u2502\n\u251c\u2500\u2500 notebooks/\n\u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 00_setup/\n\u2502   \u2502   \u251c\u2500\u2500 00_auto_setup.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 00_local_setup.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 01_colab_setup.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 02_kaggle_setup.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 03_vscode_setup.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 04_pycharm_setup.ipynb\n\u2502   \u2502   \u2514\u2500\u2500 05_jupyterlab_setup.ipynb\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 01_tutorials/\n\u2502   \u2502   \u251c\u2500\u2500 00_auto_training_tutorial.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 00_environment_setup.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 01_data_loading_basics.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 02_preprocessing_tutorial.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 03_model_training_basics.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 04_lora_tutorial.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 05_qlora_tutorial.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 06_distillation_tutorial.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 07_ensemble_tutorial.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 08_overfitting_prevention.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 09_safe_training_workflow.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 10_evaluation_tutorial.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 11_prompt_engineering.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 12_instruction_tuning.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 13_local_api_usage.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 14_monitoring_setup.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 15_platform_optimization.ipynb\n\u2502   \u2502   \u2514\u2500\u2500 16_quota_management.ipynb\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 02_exploratory/\n\u2502   \u2502   \u251c\u2500\u2500 01_data_exploration.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 02_model_size_analysis.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 03_parameter_efficiency_analysis.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 04_data_statistics.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 05_label_distribution.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 06_text_length_analysis.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 07_vocabulary_analysis.ipynb\n\u2502   \u2502   \u2514\u2500\u2500 08_contrast_set_exploration.ipynb\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 03_experiments/\n\u2502   \u2502   \u251c\u2500\u2500 01_baseline_experiments.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 02_xlarge_lora_experiments.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 03_llm_qlora_experiments.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 04_ensemble_experiments.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 05_distillation_experiments.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 06_sota_experiments.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 07_ablation_studies.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 08_sota_reproduction.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 09_prompt_experiments.ipynb\n\u2502   \u2502   \u2514\u2500\u2500 10_single_model_experiments.ipynb\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 04_analysis/\n\u2502   \u2502   \u251c\u2500\u2500 01_error_analysis.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 02_overfitting_analysis.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 03_lora_rank_analysis.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 04_ensemble_diversity_analysis.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 05_parameter_efficiency_comparison.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 06_model_interpretability.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 07_attention_visualization.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 08_embedding_analysis.ipynb\n\u2502   \u2502   \u2514\u2500\u2500 09_failure_cases.ipynb\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 05_deployment/\n\u2502   \u2502   \u251c\u2500\u2500 01_model_export.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 02_quantization.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 03_local_serving.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 04_model_optimization.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 05_inference_pipeline.ipynb\n\u2502   \u2502   \u251c\u2500\u2500 06_api_demo.ipynb\n\u2502   \u2502   \u2514\u2500\u2500 07_hf_spaces_deploy.ipynb\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 06_platform_specific/\n\u2502       \u251c\u2500\u2500 local/\n\u2502       \u2502   \u251c\u2500\u2500 auto_training_local.ipynb\n\u2502       \u2502   \u251c\u2500\u2500 cpu_training.ipynb\n\u2502       \u2502   \u251c\u2500\u2500 gpu_training.ipynb\n\u2502       \u2502   \u251c\u2500\u2500 multi_gpu_local.ipynb\n\u2502       \u2502   \u2514\u2500\u2500 inference_demo.ipynb\n\u2502       \u2502\n\u2502       \u251c\u2500\u2500 colab/\n\u2502       \u2502   \u251c\u2500\u2500 auto_training_colab.ipynb\n\u2502       \u2502   \u251c\u2500\u2500 quick_start_colab.ipynb\n\u2502       \u2502   \u251c\u2500\u2500 full_training_colab.ipynb\n\u2502       \u2502   \u251c\u2500\u2500 drive_optimization.ipynb\n\u2502       \u2502   \u251c\u2500\u2500 keep_alive_demo.ipynb\n\u2502       \u2502   \u2514\u2500\u2500 inference_demo_colab.ipynb\n\u2502       \u2502\n\u2502       \u251c\u2500\u2500 kaggle/\n\u2502       \u2502   \u251c\u2500\u2500 auto_training_kaggle.ipynb\n\u2502       \u2502   \u251c\u2500\u2500 kaggle_submission.ipynb\n\u2502       \u2502   \u251c\u2500\u2500 kaggle_training.ipynb\n\u2502       \u2502   \u251c\u2500\u2500 tpu_training.ipynb\n\u2502       \u2502   \u2514\u2500\u2500 dataset_caching.ipynb\n\u2502       \u2502\n\u2502       \u2514\u2500\u2500 huggingface/\n\u2502           \u2514\u2500\u2500 spaces_demo.ipynb\n\u2502\n\u251c\u2500\u2500 app/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 streamlit_app.py\n\u2502   \u251c\u2500\u2500 gradio_app.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 pages/\n\u2502   \u2502   \u251c\u2500\u2500 01_Home.py\n\u2502   \u2502   \u251c\u2500\u2500 02_Single_Prediction.py\n\u2502   \u2502   \u251c\u2500\u2500 03_Batch_Analysis.py\n\u2502   \u2502   \u251c\u2500\u2500 04_Model_Comparison.py\n\u2502   \u2502   \u251c\u2500\u2500 05_Overfitting_Dashboard.py\n\u2502   \u2502   \u251c\u2500\u2500 06_Model_Recommender.py\n\u2502   \u2502   \u251c\u2500\u2500 07_Parameter_Efficiency_Dashboard.py\n\u2502   \u2502   \u251c\u2500\u2500 08_Interpretability.py\n\u2502   \u2502   \u251c\u2500\u2500 09_Performance_Dashboard.py\n\u2502   \u2502   \u251c\u2500\u2500 10_Real_Time_Demo.py\n\u2502   \u2502   \u251c\u2500\u2500 11_Model_Selection.py\n\u2502   \u2502   \u251c\u2500\u2500 12_Documentation.py\n\u2502   \u2502   \u251c\u2500\u2500 13_Prompt_Testing.py\n\u2502   \u2502   \u251c\u2500\u2500 14_Local_Monitoring.py\n\u2502   \u2502   \u251c\u2500\u2500 15_IDE_Setup_Guide.py\n\u2502   \u2502   \u251c\u2500\u2500 16_Experiment_Tracker.py\n\u2502   \u2502   \u251c\u2500\u2500 17_Platform_Info.py\n\u2502   \u2502   \u251c\u2500\u2500 18_Quota_Dashboard.py\n\u2502   \u2502   \u251c\u2500\u2500 19_Platform_Selector.py\n\u2502   \u2502   \u2514\u2500\u2500 20_Auto_Train_UI.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 components/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 prediction_component.py\n\u2502   \u2502   \u251c\u2500\u2500 overfitting_monitor.py\n\u2502   \u2502   \u251c\u2500\u2500 lora_config_selector.py\n\u2502   \u2502   \u251c\u2500\u2500 ensemble_builder.py\n\u2502   \u2502   \u251c\u2500\u2500 visualization_component.py\n\u2502   \u2502   \u251c\u2500\u2500 model_selector.py\n\u2502   \u2502   \u251c\u2500\u2500 file_uploader.py\n\u2502   \u2502   \u251c\u2500\u2500 result_display.py\n\u2502   \u2502   \u251c\u2500\u2500 performance_monitor.py\n\u2502   \u2502   \u251c\u2500\u2500 prompt_builder.py\n\u2502   \u2502   \u251c\u2500\u2500 ide_configurator.py\n\u2502   \u2502   \u251c\u2500\u2500 platform_info_component.py\n\u2502   \u2502   \u251c\u2500\u2500 quota_monitor_component.py\n\u2502   \u2502   \u2514\u2500\u2500 resource_gauge.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 utils/\n\u2502   \u2502   \u251c\u2500\u2500 session_manager.py\n\u2502   \u2502   \u251c\u2500\u2500 caching.py\n\u2502   \u2502   \u251c\u2500\u2500 theming.py\n\u2502   \u2502   \u2514\u2500\u2500 helpers.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 assets/\n\u2502       \u251c\u2500\u2500 css/\n\u2502       \u2502   \u2514\u2500\u2500 custom.css\n\u2502       \u251c\u2500\u2500 js/\n\u2502       \u2502   \u2514\u2500\u2500 custom.js\n\u2502       \u2514\u2500\u2500 images/\n\u2502           \u251c\u2500\u2500 logo.png\n\u2502           \u2514\u2500\u2500 banner.png\n\u2502\n\u251c\u2500\u2500 outputs/\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u251c\u2500\u2500 checkpoints/\n\u2502   \u2502   \u251c\u2500\u2500 pretrained/\n\u2502   \u2502   \u251c\u2500\u2500 fine_tuned/\n\u2502   \u2502   \u251c\u2500\u2500 lora_adapters/\n\u2502   \u2502   \u251c\u2500\u2500 qlora_adapters/\n\u2502   \u2502   \u251c\u2500\u2500 ensembles/\n\u2502   \u2502   \u251c\u2500\u2500 distilled/\n\u2502   \u2502   \u251c\u2500\u2500 optimized/\n\u2502   \u2502   \u251c\u2500\u2500 exported/\n\u2502   \u2502   \u2514\u2500\u2500 prompted/\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 results/\n\u2502   \u2502   \u251c\u2500\u2500 experiments/\n\u2502   \u2502   \u251c\u2500\u2500 benchmarks/\n\u2502   \u2502   \u251c\u2500\u2500 overfitting_reports/\n\u2502   \u2502   \u251c\u2500\u2500 parameter_efficiency_reports/\n\u2502   \u2502   \u251c\u2500\u2500 ablations/\n\u2502   \u2502   \u2514\u2500\u2500 reports/\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 analysis/\n\u2502   \u2502   \u251c\u2500\u2500 error_analysis/\n\u2502   \u2502   \u251c\u2500\u2500 interpretability/\n\u2502   \u2502   \u2514\u2500\u2500 statistical/\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 logs/\n\u2502   \u2502   \u251c\u2500\u2500 training/\n\u2502   \u2502   \u251c\u2500\u2500 tensorboard/\n\u2502   \u2502   \u251c\u2500\u2500 mlflow/\n\u2502   \u2502   \u251c\u2500\u2500 wandb/\n\u2502   \u2502   \u2514\u2500\u2500 local/\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 profiling/\n\u2502   \u2502   \u251c\u2500\u2500 memory/\n\u2502   \u2502   \u251c\u2500\u2500 speed/\n\u2502   \u2502   \u2514\u2500\u2500 traces/\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 artifacts/\n\u2502       \u251c\u2500\u2500 figures/\n\u2502       \u251c\u2500\u2500 tables/\n\u2502       \u251c\u2500\u2500 lora_visualizations/\n\u2502       \u2514\u2500\u2500 presentations/\n\u2502\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 00_START_HERE.md\n\u2502   \u251c\u2500\u2500 limitations.md\n\u2502   \u251c\u2500\u2500 ethical_considerations.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 getting_started/\n\u2502   \u2502   \u251c\u2500\u2500 installation.md\n\u2502   \u2502   \u251c\u2500\u2500 local_setup.md\n\u2502   \u2502   \u251c\u2500\u2500 ide_setup.md\n\u2502   \u2502   \u251c\u2500\u2500 quickstart.md\n\u2502   \u2502   \u251c\u2500\u2500 auto_mode.md\n\u2502   \u2502   \u251c\u2500\u2500 platform_detection.md\n\u2502   \u2502   \u251c\u2500\u2500 overfitting_prevention_quickstart.md\n\u2502   \u2502   \u251c\u2500\u2500 choosing_model.md\n\u2502   \u2502   \u251c\u2500\u2500 choosing_platform.md\n\u2502   \u2502   \u251c\u2500\u2500 free_deployment.md\n\u2502   \u2502   \u2514\u2500\u2500 troubleshooting.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 level_1_beginner/\n\u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u251c\u2500\u2500 01_installation.md\n\u2502   \u2502   \u251c\u2500\u2500 02_first_model.md\n\u2502   \u2502   \u251c\u2500\u2500 03_evaluation.md\n\u2502   \u2502   \u251c\u2500\u2500 04_deployment.md\n\u2502   \u2502   \u2514\u2500\u2500 quick_demo.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 level_2_intermediate/\n\u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u251c\u2500\u2500 01_lora_qlora.md\n\u2502   \u2502   \u251c\u2500\u2500 02_ensemble.md\n\u2502   \u2502   \u251c\u2500\u2500 03_distillation.md\n\u2502   \u2502   \u2514\u2500\u2500 04_optimization.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 level_3_advanced/\n\u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u251c\u2500\u2500 01_sota_pipeline.md\n\u2502   \u2502   \u251c\u2500\u2500 02_custom_models.md\n\u2502   \u2502   \u2514\u2500\u2500 03_research_workflow.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 platform_guides/\n\u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u251c\u2500\u2500 colab_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 colab_advanced.md\n\u2502   \u2502   \u251c\u2500\u2500 kaggle_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 kaggle_tpu.md\n\u2502   \u2502   \u251c\u2500\u2500 local_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 gitpod_guide.md\n\u2502   \u2502   \u2514\u2500\u2500 platform_comparison.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 user_guide/\n\u2502   \u2502   \u251c\u2500\u2500 data_preparation.md\n\u2502   \u2502   \u251c\u2500\u2500 model_training.md\n\u2502   \u2502   \u251c\u2500\u2500 auto_training.md\n\u2502   \u2502   \u251c\u2500\u2500 lora_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 qlora_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 distillation_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 ensemble_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 overfitting_prevention.md\n\u2502   \u2502   \u251c\u2500\u2500 safe_training_practices.md\n\u2502   \u2502   \u251c\u2500\u2500 evaluation.md\n\u2502   \u2502   \u251c\u2500\u2500 local_deployment.md\n\u2502   \u2502   \u251c\u2500\u2500 quota_management.md\n\u2502   \u2502   \u251c\u2500\u2500 platform_optimization.md\n\u2502   \u2502   \u251c\u2500\u2500 prompt_engineering.md\n\u2502   \u2502   \u2514\u2500\u2500 advanced_techniques.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 developer_guide/\n\u2502   \u2502   \u251c\u2500\u2500 architecture.md\n\u2502   \u2502   \u251c\u2500\u2500 adding_models.md\n\u2502   \u2502   \u251c\u2500\u2500 custom_datasets.md\n\u2502   \u2502   \u251c\u2500\u2500 local_api_development.md\n\u2502   \u2502   \u2514\u2500\u2500 contributing.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 api_reference/\n\u2502   \u2502   \u251c\u2500\u2500 rest_api.md\n\u2502   \u2502   \u251c\u2500\u2500 data_api.md\n\u2502   \u2502   \u251c\u2500\u2500 models_api.md\n\u2502   \u2502   \u251c\u2500\u2500 training_api.md\n\u2502   \u2502   \u251c\u2500\u2500 lora_api.md\n\u2502   \u2502   \u251c\u2500\u2500 ensemble_api.md\n\u2502   \u2502   \u251c\u2500\u2500 overfitting_prevention_api.md\n\u2502   \u2502   \u251c\u2500\u2500 platform_api.md\n\u2502   \u2502   \u251c\u2500\u2500 quota_api.md\n\u2502   \u2502   \u2514\u2500\u2500 evaluation_api.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 ide_guides/\n\u2502   \u2502   \u251c\u2500\u2500 vscode_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 pycharm_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 jupyter_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 vim_guide.md\n\u2502   \u2502   \u251c\u2500\u2500 sublime_guide.md\n\u2502   \u2502   \u2514\u2500\u2500 comparison.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 tutorials/\n\u2502   \u2502   \u251c\u2500\u2500 basic_usage.md\n\u2502   \u2502   \u251c\u2500\u2500 xlarge_model_tutorial.md\n\u2502   \u2502   \u251c\u2500\u2500 llm_tutorial.md\n\u2502   \u2502   \u251c\u2500\u2500 distillation_tutorial.md\n\u2502   \u2502   \u251c\u2500\u2500 sota_pipeline_tutorial.md\n\u2502   \u2502   \u251c\u2500\u2500 local_training_tutorial.md\n\u2502   \u2502   \u251c\u2500\u2500 free_deployment_tutorial.md\n\u2502   \u2502   \u2514\u2500\u2500 best_practices.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 best_practices/\n\u2502   \u2502   \u251c\u2500\u2500 model_selection.md\n\u2502   \u2502   \u251c\u2500\u2500 parameter_efficient_finetuning.md\n\u2502   \u2502   \u251c\u2500\u2500 avoiding_overfitting.md\n\u2502   \u2502   \u251c\u2500\u2500 local_optimization.md\n\u2502   \u2502   \u2514\u2500\u2500 ensemble_building.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 examples/\n\u2502   \u2502   \u251c\u2500\u2500 00_hello_world.md\n\u2502   \u2502   \u251c\u2500\u2500 01_train_baseline.md\n\u2502   \u2502   \u251c\u2500\u2500 02_sota_pipeline.md\n\u2502   \u2502   \u2514\u2500\u2500 03_custom_model.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 cheatsheets/\n\u2502   \u2502   \u251c\u2500\u2500 model_selection_cheatsheet.pdf\n\u2502   \u2502   \u251c\u2500\u2500 overfitting_prevention_checklist.pdf\n\u2502   \u2502   \u251c\u2500\u2500 free_deployment_comparison.pdf\n\u2502   \u2502   \u251c\u2500\u2500 platform_comparison_chart.pdf\n\u2502   \u2502   \u251c\u2500\u2500 auto_train_cheatsheet.pdf\n\u2502   \u2502   \u251c\u2500\u2500 quota_limits_reference.pdf\n\u2502   \u2502   \u2514\u2500\u2500 cli_commands.pdf\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 troubleshooting/\n\u2502   \u2502   \u251c\u2500\u2500 platform_issues.md\n\u2502   \u2502   \u2514\u2500\u2500 quota_issues.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 architecture/\n\u2502   \u2502   \u251c\u2500\u2500 decisions/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 001-model-selection.md\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 002-ensemble-strategy.md\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 003-local-first-design.md\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 004-overfitting-prevention.md\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 005-parameter-efficiency.md\n\u2502   \u2502   \u251c\u2500\u2500 diagrams/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 system-overview.puml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 data-flow.puml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local-deployment.puml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 overfitting-prevention-flow.puml\n\u2502   \u2502   \u2514\u2500\u2500 patterns/\n\u2502   \u2502       \u251c\u2500\u2500 factory-pattern.md\n\u2502   \u2502       \u2514\u2500\u2500 strategy-pattern.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 operations/\n\u2502   \u2502   \u251c\u2500\u2500 runbooks/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 local_deployment.md\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 troubleshooting.md\n\u2502   \u2502   \u2514\u2500\u2500 sops/\n\u2502   \u2502       \u251c\u2500\u2500 model-update.md\n\u2502   \u2502       \u2514\u2500\u2500 data-refresh.md\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 _static/\n\u2502       \u2514\u2500\u2500 custom.css\n\u2502\n\u251c\u2500\u2500 deployment/\n\u2502   \u251c\u2500\u2500 docker/\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile.local\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile.gpu.local\n\u2502   \u2502   \u251c\u2500\u2500 docker-compose.local.yml\n\u2502   \u2502   \u2514\u2500\u2500 .dockerignore\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 auto_deploy/\n\u2502   \u2502   \u251c\u2500\u2500 auto_deploy.py\n\u2502   \u2502   \u251c\u2500\u2500 platform_deploy.sh\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 platform_specific/\n\u2502   \u2502   \u251c\u2500\u2500 colab_deploy.md\n\u2502   \u2502   \u251c\u2500\u2500 kaggle_deploy.md\n\u2502   \u2502   \u2514\u2500\u2500 local_deploy.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 huggingface/\n\u2502   \u2502   \u251c\u2500\u2500 spaces_config.yaml\n\u2502   \u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2502   \u251c\u2500\u2500 app.py\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 streamlit_cloud/\n\u2502   \u2502   \u251c\u2500\u2500 .streamlit/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 config.toml\n\u2502   \u2502   \u2514\u2500\u2500 requirements.txt\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 local/\n\u2502       \u251c\u2500\u2500 systemd/\n\u2502       \u2502   \u251c\u2500\u2500 ag-news-api.service\n\u2502       \u2502   \u2514\u2500\u2500 ag-news-monitor.service\n\u2502       \u251c\u2500\u2500 nginx/\n\u2502       \u2502   \u2514\u2500\u2500 ag-news.conf\n\u2502       \u2514\u2500\u2500 scripts/\n\u2502           \u251c\u2500\u2500 start_all.sh\n\u2502           \u2514\u2500\u2500 stop_all.sh\n\u2502\n\u251c\u2500\u2500 benchmarks/\n\u2502   \u251c\u2500\u2500 accuracy/\n\u2502   \u2502   \u251c\u2500\u2500 model_comparison.json\n\u2502   \u2502   \u251c\u2500\u2500 xlarge_models.json\n\u2502   \u2502   \u251c\u2500\u2500 llm_models.json\n\u2502   \u2502   \u251c\u2500\u2500 ensemble_results.json\n\u2502   \u2502   \u2514\u2500\u2500 sota_benchmarks.json\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 efficiency/\n\u2502   \u2502   \u251c\u2500\u2500 parameter_efficiency.json\n\u2502   \u2502   \u251c\u2500\u2500 memory_usage.json\n\u2502   \u2502   \u251c\u2500\u2500 training_time.json\n\u2502   \u2502   \u251c\u2500\u2500 inference_speed.json\n\u2502   \u2502   \u2514\u2500\u2500 platform_comparison.json\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 robustness/\n\u2502   \u2502   \u251c\u2500\u2500 adversarial_results.json\n\u2502   \u2502   \u251c\u2500\u2500 ood_detection.json\n\u2502   \u2502   \u2514\u2500\u2500 contrast_set_results.json\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 overfitting/\n\u2502       \u251c\u2500\u2500 train_val_gaps.json\n\u2502       \u251c\u2500\u2500 lora_ranks.json\n\u2502       \u2514\u2500\u2500 prevention_effectiveness.json\n\u2502\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 unit/\n\u2502   \u2502   \u251c\u2500\u2500 data/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_preprocessing.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_augmentation.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_dataloader.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_contrast_sets.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_transformers.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_ensemble.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_efficient.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_prompt_models.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 training/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_trainers.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_auto_trainer.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_strategies.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_callbacks.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_multi_stage.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 deployment/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_platform_detector.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_smart_selector.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_cache_manager.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_checkpoint_manager.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_quota_tracker.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_rest_api.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_local_api.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_auth.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 overfitting_prevention/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_validators.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_monitors.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_constraints.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_guards.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_recommenders.py\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 utils/\n\u2502   \u2502       \u251c\u2500\u2500 test_memory_utils.py\n\u2502   \u2502       \u2514\u2500\u2500 test_utilities.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 integration/\n\u2502   \u2502   \u251c\u2500\u2500 test_full_pipeline.py\n\u2502   \u2502   \u251c\u2500\u2500 test_auto_train_flow.py\n\u2502   \u2502   \u251c\u2500\u2500 test_ensemble_pipeline.py\n\u2502   \u2502   \u251c\u2500\u2500 test_inference_pipeline.py\n\u2502   \u2502   \u251c\u2500\u2500 test_local_api_flow.py\n\u2502   \u2502   \u251c\u2500\u2500 test_prompt_pipeline.py\n\u2502   \u2502   \u251c\u2500\u2500 test_llm_integration.py\n\u2502   \u2502   \u251c\u2500\u2500 test_platform_workflows.py\n\u2502   \u2502   \u251c\u2500\u2500 test_quota_tracking_flow.py\n\u2502   \u2502   \u2514\u2500\u2500 test_overfitting_prevention_flow.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 platform_specific/\n\u2502   \u2502   \u251c\u2500\u2500 test_colab_integration.py\n\u2502   \u2502   \u251c\u2500\u2500 test_kaggle_integration.py\n\u2502   \u2502   \u2514\u2500\u2500 test_local_integration.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 performance/\n\u2502   \u2502   \u251c\u2500\u2500 test_model_speed.py\n\u2502   \u2502   \u251c\u2500\u2500 test_memory_usage.py\n\u2502   \u2502   \u251c\u2500\u2500 test_accuracy_benchmarks.py\n\u2502   \u2502   \u251c\u2500\u2500 test_local_performance.py\n\u2502   \u2502   \u251c\u2500\u2500 test_sla_compliance.py\n\u2502   \u2502   \u2514\u2500\u2500 test_throughput.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 e2e/\n\u2502   \u2502   \u251c\u2500\u2500 test_complete_workflow.py\n\u2502   \u2502   \u251c\u2500\u2500 test_user_scenarios.py\n\u2502   \u2502   \u251c\u2500\u2500 test_local_deployment.py\n\u2502   \u2502   \u251c\u2500\u2500 test_free_deployment.py\n\u2502   \u2502   \u251c\u2500\u2500 test_quickstart_pipeline.py\n\u2502   \u2502   \u251c\u2500\u2500 test_sota_pipeline.py\n\u2502   \u2502   \u251c\u2500\u2500 test_auto_train_colab.py\n\u2502   \u2502   \u251c\u2500\u2500 test_auto_train_kaggle.py\n\u2502   \u2502   \u2514\u2500\u2500 test_quota_enforcement.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 regression/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 test_model_accuracy.py\n\u2502   \u2502   \u251c\u2500\u2500 test_ensemble_diversity.py\n\u2502   \u2502   \u251c\u2500\u2500 test_inference_speed.py\n\u2502   \u2502   \u2514\u2500\u2500 baseline_results.json\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 chaos/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 test_fault_tolerance.py\n\u2502   \u2502   \u251c\u2500\u2500 test_corrupted_config.py\n\u2502   \u2502   \u251c\u2500\u2500 test_oom_handling.py\n\u2502   \u2502   \u2514\u2500\u2500 test_network_failures.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 compatibility/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 test_torch_versions.py\n\u2502   \u2502   \u251c\u2500\u2500 test_transformers_versions.py\n\u2502   \u2502   \u2514\u2500\u2500 test_cross_platform.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 fixtures/\n\u2502       \u251c\u2500\u2500 sample_data.py\n\u2502       \u251c\u2500\u2500 mock_models.py\n\u2502       \u251c\u2500\u2500 test_configs.py\n\u2502       \u2514\u2500\u2500 local_fixtures.py\n\u2502\n\u251c\u2500\u2500 .github/\n\u2502   \u251c\u2500\u2500 workflows/\n\u2502   \u2502   \u251c\u2500\u2500 ci.yml\n\u2502   \u2502   \u251c\u2500\u2500 tests.yml\n\u2502   \u2502   \u251c\u2500\u2500 documentation.yml\n\u2502   \u2502   \u251c\u2500\u2500 benchmarks.yml\n\u2502   \u2502   \u251c\u2500\u2500 overfitting_checks.yml\n\u2502   \u2502   \u251c\u2500\u2500 docs_sync_check.yml\n\u2502   \u2502   \u251c\u2500\u2500 local_deployment_test.yml\n\u2502   \u2502   \u251c\u2500\u2500 dependency_updates.yml\n\u2502   \u2502   \u251c\u2500\u2500 compatibility_matrix.yml\n\u2502   \u2502   \u251c\u2500\u2500 regression_tests.yml\n\u2502   \u2502   \u251c\u2500\u2500 test_platform_detection.yml\n\u2502   \u2502   \u251c\u2500\u2500 test_auto_train.yml\n\u2502   \u2502   \u2514\u2500\u2500 platform_compatibility.yml\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 ISSUE_TEMPLATE/\n\u2502   \u2502   \u251c\u2500\u2500 bug_report.md\n\u2502   \u2502   \u251c\u2500\u2500 feature_request.md\n\u2502   \u2502   \u251c\u2500\u2500 ide_support_request.md\n\u2502   \u2502   \u2514\u2500\u2500 overfitting_report.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 PULL_REQUEST_TEMPLATE.md\n\u2502   \u2514\u2500\u2500 dependabot.yml\n\u2502\n\u2514\u2500\u2500 tools/\n    \u2502\n    \u251c\u2500\u2500 profiling/\n    \u2502   \u251c\u2500\u2500 memory_profiler.py\n    \u2502   \u251c\u2500\u2500 speed_profiler.py\n    \u2502   \u251c\u2500\u2500 parameter_counter.py\n    \u2502   \u2514\u2500\u2500 local_profiler.py\n    \u2502\n    \u251c\u2500\u2500 debugging/\n    \u2502   \u251c\u2500\u2500 model_debugger.py\n    \u2502   \u251c\u2500\u2500 overfitting_debugger.py\n    \u2502   \u251c\u2500\u2500 lora_debugger.py\n    \u2502   \u251c\u2500\u2500 data_validator.py\n    \u2502   \u251c\u2500\u2500 platform_debugger.py\n    \u2502   \u251c\u2500\u2500 quota_debugger.py\n    \u2502   \u2514\u2500\u2500 local_debugger.py\n    \u2502\n    \u251c\u2500\u2500 visualization/\n    \u2502   \u251c\u2500\u2500 training_monitor.py\n    \u2502   \u251c\u2500\u2500 lora_weight_plotter.py\n    \u2502   \u251c\u2500\u2500 ensemble_diversity_plotter.py\n    \u2502   \u2514\u2500\u2500 result_plotter.py\n    \u2502\n    \u251c\u2500\u2500 config_tools/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 config_generator.py\n    \u2502   \u251c\u2500\u2500 config_explainer.py\n    \u2502   \u251c\u2500\u2500 config_comparator.py\n    \u2502   \u251c\u2500\u2500 config_optimizer.py\n    \u2502   \u251c\u2500\u2500 sync_manager.py\n    \u2502   \u251c\u2500\u2500 auto_sync.sh\n    \u2502   \u2514\u2500\u2500 validate_all_configs.py\n    \u2502\n    \u251c\u2500\u2500 platform_tools/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 detector_tester.py\n    \u2502   \u251c\u2500\u2500 quota_simulator.py\n    \u2502   \u2514\u2500\u2500 platform_benchmark.py\n    \u2502\n    \u251c\u2500\u2500 cost_tools/\n    \u2502   \u251c\u2500\u2500 cost_estimator.py\n    \u2502   \u2514\u2500\u2500 cost_comparator.py\n    \u2502\n    \u251c\u2500\u2500 ide_tools/\n    \u2502   \u251c\u2500\u2500 pycharm_config_generator.py\n    \u2502   \u251c\u2500\u2500 vscode_tasks_generator.py\n    \u2502   \u251c\u2500\u2500 jupyter_kernel_setup.py\n    \u2502   \u251c\u2500\u2500 vim_plugin_installer.sh\n    \u2502   \u251c\u2500\u2500 universal_ide_generator.py\n    \u2502   \u2514\u2500\u2500 sync_ide_configs.py\n    \u2502\n    \u251c\u2500\u2500 compatibility/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 compatibility_checker.py\n    \u2502   \u251c\u2500\u2500 version_matrix_tester.py\n    \u2502   \u2514\u2500\u2500 upgrade_path_finder.py\n    \u2502\n    \u251c\u2500\u2500 automation/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 health_check_runner.py\n    \u2502   \u251c\u2500\u2500 auto_fix_runner.py\n    \u2502   \u251c\u2500\u2500 batch_config_generator.py\n    \u2502   \u251c\u2500\u2500 platform_health.py\n    \u2502   \u2514\u2500\u2500 nightly_tasks.sh\n    \u2502\n    \u2514\u2500\u2500 cli_helpers/\n        \u251c\u2500\u2500 __init__.py\n        \u251c\u2500\u2500 rich_console.py\n        \u251c\u2500\u2500 progress_bars.py\n        \u251c\u2500\u2500 interactive_prompts.py\n        \u2514\u2500\u2500 ascii_art.py\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"ARCHITECTURE/","title":"ARCHITECTURE","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"ARCHITECTURE/#overview","title":"Overview","text":"<p>Comprehensive guide for ARCHITECTURE.</p>"},{"location":"ARCHITECTURE/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"ARCHITECTURE/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"ARCHITECTURE/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"CHANGELOG/","title":"AG News Text Classification - Changelog","text":"<p>All notable changes to the AG News Text Classification project will be documented in this file.</p> <p>The format is based on Keep a Changelog (https://keepachangelog.com/en/1.0.0/), and this project adheres to Semantic Versioning (https://semver.org/spec/v2.0.0.html).</p>"},{"location":"CHANGELOG/#project-information","title":"Project Information","text":"<ul> <li>Project Name: AG News Text Classification (ag-news-text-classification)</li> <li>Author: V\u00f5 H\u1ea3i D\u0169ng</li> <li>Email: vohaidung.work@gmail.com</li> <li>License: MIT</li> <li>Repository: https://github.com/VoHaiDung/ag-news-text-classification</li> </ul>"},{"location":"CHANGELOG/#version-history","title":"Version History","text":""},{"location":"CHANGELOG/#unreleased","title":"[Unreleased]","text":""},{"location":"CHANGELOG/#planned-features","title":"Planned Features","text":"<ul> <li>Multi-language support for non-English news classification</li> <li>Real-time learning pipeline for continuous model improvement</li> <li>AutoML integration for automated hyperparameter optimization</li> <li>Federated learning support for privacy-preserving distributed training</li> <li>Mobile deployment optimization (TensorFlow Lite, Core ML, ONNX Mobile)</li> <li>Active learning pipeline for efficient data labeling strategies</li> <li>Graph neural networks for hierarchical topic modeling</li> <li>Temporal analysis for news trend detection and evolution</li> <li>Cross-dataset transfer learning for domain adaptation</li> <li>Online learning capabilities for streaming data</li> </ul>"},{"location":"CHANGELOG/#under-research","title":"Under Research","text":"<ul> <li>GPT-4 based knowledge distillation for compact student models</li> <li>Chain-of-thought prompting for enhanced interpretability</li> <li>Constitutional AI techniques for bias detection and mitigation</li> <li>Retrieval-augmented generation for context-aware classification</li> <li>Multi-modal learning combining text, images, and metadata</li> <li>Zero-shot learning for emerging news categories</li> <li>Few-shot learning with prototypical networks and matching networks</li> <li>Continual learning without catastrophic forgetting</li> <li>Adversarial training for improved robustness</li> <li>Neural architecture search for optimal model design</li> </ul>"},{"location":"CHANGELOG/#100-2025-09-19","title":"[1.0.0] - 2025-09-19","text":""},{"location":"CHANGELOG/#initial-release","title":"Initial Release","text":"<p>This is the first stable release of the AG News Text Classification framework, representing comprehensive research and development work in text classification, overfitting prevention, and parameter-efficient fine-tuning. The project achieves state-of-the-art performance on the AG News dataset while maintaining strong generalization through advanced prevention mechanisms.</p>"},{"location":"CHANGELOG/#added","title":"Added","text":""},{"location":"CHANGELOG/#core-framework-architecture","title":"Core Framework Architecture","text":""},{"location":"CHANGELOG/#project-structure","title":"Project Structure","text":"<ul> <li>Comprehensive project organization with 15 top-level directories</li> <li>Modular architecture implementing separation of concerns principle</li> <li>Type-annotated codebase with comprehensive docstrings following Google style</li> <li>Centralized error handling with custom exception hierarchy</li> <li>Structured logging system using loguru with rotation and retention policies</li> <li>Health check system validating dependencies, GPU availability, and configuration</li> <li>Auto-fix utilities for automatic resolution of common configuration issues</li> <li>Command-line interface with typer and rich for enhanced user experience</li> <li>Interactive setup wizard with platform detection and optimal configuration</li> </ul>"},{"location":"CHANGELOG/#configuration-system","title":"Configuration System","text":"<ul> <li>Hierarchical YAML-based configuration with 300+ files</li> <li>Configuration validation using Pydantic schemas</li> <li>Template-based configuration generation with Jinja2</li> <li>Configuration loader with environment variable substitution</li> <li>Smart defaults system adapting to platform and resources</li> <li>Feature flags for experimental functionality</li> <li>Environment-specific configurations (dev, local_prod, colab, kaggle)</li> <li>Configuration compatibility matrix ensuring valid combinations</li> <li>Constants management for magic number elimination</li> <li>Secrets management with template-based approach</li> </ul>"},{"location":"CHANGELOG/#data-processing-pipeline","title":"Data Processing Pipeline","text":""},{"location":"CHANGELOG/#dataset-management","title":"Dataset Management","text":"<ul> <li>AG News dataset loader with automatic download and caching</li> <li>Dataset wrapper with stratified sampling and balancing</li> <li>External news corpus integration for domain-adaptive pretraining</li> <li>Combined dataset support for multi-source training</li> <li>Prompted dataset wrapper for few-shot learning scenarios</li> <li>Instruction-formatted dataset for instruction-tuned LLMs</li> <li>Distillation dataset with teacher model soft labels</li> <li>Platform-specific caching strategies (Drive for Colab, Datasets for Kaggle)</li> </ul>"},{"location":"CHANGELOG/#preprocessing","title":"Preprocessing","text":"<ul> <li>Text cleaning with HTML tag removal and normalization</li> <li>Tokenization with HuggingFace tokenizers and caching</li> <li>Feature extraction for classical ML models</li> <li>Sliding window approach for long document handling</li> <li>Prompt formatting for zero-shot and few-shot scenarios</li> <li>Instruction formatting following Alpaca, Dolly, and Vicuna templates</li> <li>Tokenization statistics and vocabulary analysis</li> </ul>"},{"location":"CHANGELOG/#data-augmentation","title":"Data Augmentation","text":"<ul> <li>Back-translation using MarianMT models with multiple language pivots</li> <li>Paraphrasing with T5 and PEGASUS models</li> <li>Token-level augmentation (synonym replacement, random insertion/deletion/swap)</li> <li>Contextual word embeddings for synonym generation</li> <li>Sentence-level mixup and manifold mixup</li> <li>Cutmix and cutout for text sequences</li> <li>Adversarial augmentation with gradient-based perturbations</li> <li>Contrast set generation for robustness evaluation</li> <li>LLM-based augmentation using LLaMA and Mistral</li> <li>Controlled generation with temperature and top-p sampling</li> <li>Quality filtering using perplexity and semantic similarity</li> <li>Diversity enforcement through nucleus sampling</li> <li>Augmentation constraints preventing over-augmentation</li> </ul>"},{"location":"CHANGELOG/#data-validation-and-quality-control","title":"Data Validation and Quality Control","text":"<ul> <li>Stratified data splitting with reproducible random seeds</li> <li>Cross-validation strategies (k-fold, stratified k-fold, nested CV)</li> <li>Holdout validation set management</li> <li>Time-based splitting for temporal datasets</li> <li>Data leakage detection using statistical tests</li> <li>Test set protection with SHA-256 hashing</li> <li>Test access logging and auditing</li> <li>Split information metadata tracking</li> <li>Data quality metrics (completeness, consistency, validity)</li> </ul>"},{"location":"CHANGELOG/#data-selection-and-sampling","title":"Data Selection and Sampling","text":"<ul> <li>Coreset selection using k-center greedy algorithm</li> <li>Influence function based sample selection</li> <li>Gradient matching for dataset distillation</li> <li>Diversity-based selection maximizing feature coverage</li> <li>Quality filtering using confidence thresholds</li> <li>Uncertainty sampling for active learning</li> <li>Curriculum sampling with difficulty estimation</li> <li>Balanced sampling maintaining class distribution</li> </ul>"},{"location":"CHANGELOG/#model-architecture-support","title":"Model Architecture Support","text":""},{"location":"CHANGELOG/#transformer-models","title":"Transformer Models","text":"<ul> <li>DeBERTa implementation</li> <li>DeBERTa v3 base (184M parameters)</li> <li>DeBERTa v3 large (435M parameters)</li> <li>DeBERTa v3 xlarge (900M parameters)</li> <li>DeBERTa v2 xlarge (900M parameters)</li> <li>DeBERTa v2 xxlarge (1.5B parameters)</li> <li>Sliding window attention for long sequences</li> <li>Hierarchical attention for document-level classification</li> <li>RoBERTa variants</li> <li>RoBERTa base (125M parameters)</li> <li>RoBERTa large (355M parameters)</li> <li>RoBERTa large MNLI (domain-adapted)</li> <li>XLM-RoBERTa large for multilingual support</li> <li>Enhanced RoBERTa with additional pretraining</li> <li>Domain-adapted RoBERTa on news corpus</li> <li>ELECTRA models</li> <li>ELECTRA base (110M parameters)</li> <li>ELECTRA large (335M parameters)</li> <li>Discriminator-based classification head</li> <li>XLNet architectures</li> <li>XLNet base (110M parameters)</li> <li>XLNet large (340M parameters)</li> <li>Custom classifier head with pooling strategies</li> <li>Longformer for long documents</li> <li>Longformer base (149M parameters)</li> <li>Longformer large (435M parameters)</li> <li>Global attention mechanism for classification tokens</li> <li>T5 encoder-decoder models</li> <li>T5 base (220M parameters)</li> <li>T5 large (770M parameters)</li> <li>T5 3B (3B parameters)</li> <li>FLAN-T5 XL (3B parameters, instruction-tuned)</li> <li>Custom classification head for encoder representations</li> </ul>"},{"location":"CHANGELOG/#large-language-models","title":"Large Language Models","text":"<ul> <li>LLaMA family</li> <li>LLaMA 2 7B (7B parameters)</li> <li>LLaMA 2 13B (13B parameters)</li> <li>LLaMA 2 70B (70B parameters)</li> <li>LLaMA 3 8B (8B parameters)</li> <li>LLaMA 3 70B (70B parameters)</li> <li>Classification adapter for decoder-only architecture</li> <li>Mistral family</li> <li>Mistral 7B base (7B parameters)</li> <li>Mistral 7B Instruct (instruction-tuned)</li> <li>Mixtral 8x7B (47B parameters, sparse mixture of experts)</li> <li>Classification head for causal language models</li> <li>Falcon models</li> <li>Falcon 7B (7B parameters)</li> <li>Falcon 40B (40B parameters)</li> <li>Custom classification adapter</li> <li>MPT series</li> <li>MPT 7B (7B parameters)</li> <li>MPT 30B (30B parameters)</li> <li>Classification wrapper for decoder models</li> <li>Phi models</li> <li>Phi 2 (2.7B parameters)</li> <li>Phi 3 (3.8B parameters)</li> <li>Lightweight classification head</li> </ul>"},{"location":"CHANGELOG/#prompt-based-models","title":"Prompt-based Models","text":"<ul> <li>Soft prompt tuning with learnable prompt embeddings</li> <li>Prefix tuning with virtual tokens prepended to input</li> <li>P-tuning v2 with deep prompt tuning across layers</li> <li>Instruction-following models with template-based prompting</li> <li>Template manager for zero-shot and few-shot scenarios</li> </ul>"},{"location":"CHANGELOG/#classical-baseline-models","title":"Classical Baseline Models","text":"<ul> <li>Naive Bayes with TF-IDF features</li> <li>Support Vector Machines with RBF kernel</li> <li>Random Forest with 100-500 estimators</li> <li>Logistic Regression with L2 regularization</li> <li>Gradient boosting (XGBoost, LightGBM, CatBoost)</li> </ul>"},{"location":"CHANGELOG/#model-base-components","title":"Model Base Components","text":"<ul> <li>Base model wrapper with consistent interface</li> <li>Model registry for dynamic model loading</li> <li>Model factory pattern for instantiation</li> <li>Complexity tracker monitoring parameter counts and FLOPs</li> <li>Pooling strategies (CLS token, mean pooling, max pooling, attention pooling)</li> <li>Classification heads (linear, multi-layer perceptron, hierarchical, attention-based)</li> <li>Multitask heads for auxiliary task learning</li> <li>Adaptive heads adjusting to task complexity</li> </ul>"},{"location":"CHANGELOG/#parameter-efficient-fine-tuning-methods","title":"Parameter-Efficient Fine-Tuning Methods","text":""},{"location":"CHANGELOG/#lora-low-rank-adaptation","title":"LoRA (Low-Rank Adaptation)","text":"<ul> <li>LoRA implementation for attention layers</li> <li>Configurable rank values (r=4, 8, 16, 32, 64, 128, 256)</li> <li>Alpha scaling parameter for initialization</li> <li>Target module selection (query, key, value, output projections)</li> <li>Rank selection utilities based on task complexity</li> <li>Target module selector optimizing for parameter efficiency</li> <li>LoRA layer implementation with trainable A and B matrices</li> <li>Weight merging for inference optimization</li> <li>LoRA adapter saving and loading</li> <li>Rank search experiments for optimal configuration</li> <li>LoRA-specific configurations per model architecture</li> </ul>"},{"location":"CHANGELOG/#qlora-quantized-lora","title":"QLoRA (Quantized LoRA)","text":"<ul> <li>4-bit quantization with NF4 (Normal Float 4)</li> <li>8-bit quantization for memory-constrained environments</li> <li>Double quantization for additional memory savings</li> <li>Compute dtype configuration (fp16, bf16, fp32)</li> <li>Quantization configuration per model</li> <li>Dequantization utilities for inference</li> <li>Memory-efficient training enabling 70B models on consumer GPUs</li> </ul>"},{"location":"CHANGELOG/#adapter-modules","title":"Adapter Modules","text":"<ul> <li>Houlsby adapters with bottleneck architecture</li> <li>Pfeiffer adapters with optimized placement</li> <li>Parallel adapters for concurrent processing</li> <li>Adapter fusion combining multiple task-specific adapters</li> <li>Adapter stacking for hierarchical feature learning</li> <li>Adapter configuration with reduction factor tuning</li> <li>Adapter-specific training procedures</li> </ul>"},{"location":"CHANGELOG/#prefix-tuning","title":"Prefix Tuning","text":"<ul> <li>Prefix encoder generating virtual tokens</li> <li>Prefix length optimization (10-200 tokens)</li> <li>Per-layer prefix parameters</li> <li>Reparameterization for training stability</li> <li>Prefix tuning for encoder-decoder and decoder-only models</li> </ul>"},{"location":"CHANGELOG/#prompt-tuning","title":"Prompt Tuning","text":"<ul> <li>Soft prompt embeddings learned end-to-end</li> <li>Prompt initialization strategies (random, vocabulary sampling, task-specific)</li> <li>Prompt length experiments (5-100 tokens)</li> <li>P-tuning v2 with deep prompts across all layers</li> <li>Prompt encoder for complex prompt structures</li> </ul>"},{"location":"CHANGELOG/#ia3-infused-adapter-by-inhibiting-and-amplifying-inner-activations","title":"IA3 (Infused Adapter by Inhibiting and Amplifying Inner Activations)","text":"<ul> <li>Learned rescaling vectors for efficient adaptation</li> <li>Minimal parameter overhead (under 0.01% of model parameters)</li> <li>Integration with attention and feedforward layers</li> </ul>"},{"location":"CHANGELOG/#combined-methods","title":"Combined Methods","text":"<ul> <li>LoRA with adapter modules for complementary benefits</li> <li>QLoRA with prompt tuning for extreme efficiency</li> <li>Multi-method fusion optimizing multiple objectives</li> <li>Adapter switching for multi-task scenarios</li> </ul>"},{"location":"CHANGELOG/#ensemble-learning-framework","title":"Ensemble Learning Framework","text":""},{"location":"CHANGELOG/#voting-ensembles","title":"Voting Ensembles","text":"<ul> <li>Soft voting with probability averaging across models</li> <li>Hard voting using majority rule for predictions</li> <li>Weighted voting with learnable or performance-based weights</li> <li>Rank averaging for robust aggregation</li> <li>Confidence-weighted voting prioritizing certain predictions</li> <li>Temperature scaling for calibrated probabilities</li> </ul>"},{"location":"CHANGELOG/#stacking-ensembles","title":"Stacking Ensembles","text":"<ul> <li>Two-level stacking with cross-validation predictions</li> <li>Meta-learner implementations</li> <li>XGBoost meta-learner with tree-based learning</li> <li>LightGBM for fast gradient boosting</li> <li>CatBoost handling categorical features</li> <li>Neural network meta-learner for complex relationships</li> <li>Cross-validation stacking preventing overfitting</li> <li>Feature engineering for meta-learner inputs</li> <li>Regularization in meta-learner training</li> </ul>"},{"location":"CHANGELOG/#blending-ensembles","title":"Blending Ensembles","text":"<ul> <li>Holdout-based blending with separate validation set</li> <li>Dynamic blending with adaptive weights</li> <li>Calibration-aware blending for probabilistic outputs</li> </ul>"},{"location":"CHANGELOG/#advanced-ensemble-methods","title":"Advanced Ensemble Methods","text":"<ul> <li>Bayesian model averaging with posterior model probabilities</li> <li>Snapshot ensembles from single training run</li> <li>Multi-level ensembles with hierarchical structure</li> <li>Mixture of experts with gating network</li> <li>Negative correlation learning for diversity</li> <li>Ensemble pruning removing redundant models</li> </ul>"},{"location":"CHANGELOG/#diversity-optimization","title":"Diversity Optimization","text":"<ul> <li>Diversity metrics (disagreement, Q-statistic, correlation coefficient)</li> <li>Diversity calculator for ensemble analysis</li> <li>Diversity optimizer maximizing ensemble diversity</li> <li>Ensemble pruning based on diversity-accuracy trade-off</li> <li>Component contribution analysis identifying important models</li> </ul>"},{"location":"CHANGELOG/#ensemble-selection","title":"Ensemble Selection","text":"<ul> <li>Ensemble selector choosing optimal subset</li> <li>Greedy forward selection based on validation performance</li> <li>Diversity-aware selection balancing accuracy and disagreement</li> <li>Size-constrained selection for deployment efficiency</li> </ul>"},{"location":"CHANGELOG/#training-infrastructure","title":"Training Infrastructure","text":""},{"location":"CHANGELOG/#standard-training","title":"Standard Training","text":"<ul> <li>Base trainer with training loop abstraction</li> <li>Standard trainer for single-model training</li> <li>Mixed precision training (FP16, BF16) with automatic mixed precision</li> <li>Gradient checkpointing reducing memory consumption by 40-50%</li> <li>Gradient accumulation for large effective batch sizes</li> <li>Distributed training with DistributedDataParallel (DDP)</li> <li>Fully Sharded Data Parallel (FSDP) for large model training</li> <li>DeepSpeed integration (ZeRO stage 1, 2, 3)</li> <li>APEX mixed precision for older CUDA versions</li> </ul>"},{"location":"CHANGELOG/#specialized-trainers","title":"Specialized Trainers","text":"<ul> <li>Safe trainer with overfitting prevention mechanisms</li> <li>Auto trainer with automatic platform detection and optimization</li> <li>LoRA trainer optimizing for adapter training</li> <li>QLoRA trainer with quantization-aware training</li> <li>Adapter trainer for various adapter architectures</li> <li>Prompt trainer for soft prompt optimization</li> <li>Instruction trainer for instruction-tuned models</li> <li>Multi-stage trainer orchestrating progressive training</li> </ul>"},{"location":"CHANGELOG/#advanced-training-strategies","title":"Advanced Training Strategies","text":"<ul> <li>Curriculum learning</li> <li>Self-paced curriculum with automatic difficulty scoring</li> <li>Competence-based scheduling</li> <li>Transfer teacher curriculum from larger model</li> <li>Data difficulty estimation using loss and confidence</li> <li>Adversarial training</li> <li>Fast Gradient Method (FGM) for adversarial perturbations</li> <li>Projected Gradient Descent (PGD) with multiple steps</li> <li>FreeLB with adversarial training in latent space</li> <li>SMART (Smoothness-inducing Adversarial Regularization)</li> <li>Regularization techniques</li> <li>R-Drop with KL divergence between two forward passes</li> <li>Mixout randomly replacing fine-tuned weights with pretrained</li> <li>Spectral normalization for weight matrix constraints</li> <li>Adaptive dropout adjusting rate during training</li> <li>Gradient penalty for smoothness</li> <li>Elastic Weight Consolidation (EWC) for continual learning</li> <li>Sharpness-Aware Minimization (SAM) for flatter minima</li> <li>Knowledge distillation</li> <li>Standard distillation with temperature scaling</li> <li>Feature-based distillation matching intermediate representations</li> <li>Self-distillation from model's own predictions</li> <li>LLaMA distillation to smaller encoder models</li> <li>Mistral distillation with instruction preservation</li> <li>Ensemble distillation from multiple teacher models</li> <li>Progressive distillation with iterative compression</li> <li>Multi-teacher distillation aggregating knowledge</li> <li>Meta-learning</li> <li>Model-Agnostic Meta-Learning (MAML) for few-shot adaptation</li> <li>Reptile for simplified meta-learning</li> <li>Prototypical networks for metric learning</li> <li>Multi-stage training</li> <li>Stage manager coordinating training phases</li> <li>Progressive training from base to xlarge models</li> <li>Iterative refinement with multiple fine-tuning rounds</li> <li>Base to xlarge progression strategy</li> <li>Pretrain-finetune-distill pipeline</li> <li>Contrastive learning</li> <li>Supervised contrastive loss for representation learning</li> <li>Triplet loss with hard negative mining</li> <li>Contrastive learning with data augmentation</li> </ul>"},{"location":"CHANGELOG/#optimization-components","title":"Optimization Components","text":"<ul> <li>Custom optimizers</li> <li>AdamW with decoupled weight decay</li> <li>LAMB for large batch training</li> <li>Lookahead optimizer with slow and fast weights</li> <li>Sharpness-Aware Minimization (SAM)</li> <li>Adafactor for memory-efficient optimization</li> <li>Learning rate schedulers</li> <li>Cosine annealing with warmup</li> <li>Polynomial decay</li> <li>Cyclic learning rate with triangular policy</li> <li>Inverse square root scheduler</li> <li>OneCycle learning rate policy</li> <li>Gradient management</li> <li>Gradient accumulation across micro-batches</li> <li>Gradient clipping by norm and value</li> <li>Gradient checkpointing for memory efficiency</li> <li>Gradient monitoring detecting vanishing/exploding gradients</li> </ul>"},{"location":"CHANGELOG/#loss-functions","title":"Loss Functions","text":"<ul> <li>Focal loss for class imbalance</li> <li>Label smoothing regularization</li> <li>Contrastive loss for metric learning</li> <li>Triplet loss with margin</li> <li>Custom cross-entropy with temperature</li> <li>Instruction-aware loss for prompted models</li> <li>Distillation loss combining hard and soft targets</li> <li>Multi-task loss with task weighting</li> </ul>"},{"location":"CHANGELOG/#training-callbacks","title":"Training Callbacks","text":"<ul> <li>Early stopping with patience and delta thresholds</li> <li>Model checkpoint saving best and periodic checkpoints</li> <li>TensorBoard logging for training visualization</li> <li>Weights &amp; Biases integration for experiment tracking</li> <li>MLflow logger for model registry</li> <li>Learning rate monitoring and scheduling</li> <li>Overfitting monitor detecting train-validation divergence</li> <li>Complexity regularizer limiting model capacity</li> <li>Test protection callback preventing test set access</li> <li>LoRA rank callback tracking adapter efficiency</li> <li>Memory monitor for GPU memory usage</li> <li>Platform-specific callbacks</li> <li>Colab callback handling session timeouts</li> <li>Kaggle callback optimizing for kernel limits</li> <li>Platform callback with automatic detection</li> <li>Quota callback tracking resource usage</li> <li>Session callback managing long-running jobs</li> </ul>"},{"location":"CHANGELOG/#platform-adaptive-training","title":"Platform-Adaptive Training","text":"<ul> <li>Platform detector identifying execution environment</li> <li>Smart selector choosing optimal configuration</li> <li>Platform-specific training configurations</li> <li>Colab free tier: gradient accumulation, mixed precision, checkpoint frequency</li> <li>Colab Pro: larger batch sizes, longer training, advanced features</li> <li>Kaggle GPU: P100/T4 optimization, TPU support</li> <li>Kaggle TPU: XLA compilation, TPU-specific batching</li> <li>Local GPU: full feature utilization, multi-GPU training</li> <li>Local CPU: INT8 inference, CPU-optimized operations</li> <li>Cache manager with platform-specific strategies</li> <li>Checkpoint manager with automatic save/resume</li> <li>Quota tracker monitoring GPU/TPU hours and quotas</li> <li>Storage sync for Google Drive and Kaggle Datasets</li> <li>Session manager handling disconnections and resumption</li> <li>Resource monitor for real-time resource tracking</li> </ul>"},{"location":"CHANGELOG/#overfitting-prevention-system","title":"Overfitting Prevention System","text":""},{"location":"CHANGELOG/#validation-framework","title":"Validation Framework","text":"<ul> <li>Test set validator with SHA-256 hash verification</li> <li>Data leakage detector using statistical independence tests</li> <li>Configuration validator ensuring safe training settings</li> <li>Hyperparameter validator with reasonable bounds</li> <li>Split validator ensuring proper data partitioning</li> <li>Model size validator based on dataset size guidelines</li> <li>LoRA configuration validator recommending safe ranks</li> <li>Ensemble validator checking diversity requirements</li> <li>Constraint validator enforcing overfitting prevention policies</li> </ul>"},{"location":"CHANGELOG/#real-time-monitoring","title":"Real-time Monitoring","text":"<ul> <li>Training monitor tracking loss and metrics</li> <li>Overfitting detector measuring train-validation gap</li> <li>Complexity monitor computing model capacity metrics</li> <li>Benchmark comparator against established baselines</li> <li>Metrics tracker for comprehensive metric logging</li> <li>Gradient monitor detecting training instabilities</li> <li>LoRA rank monitor analyzing adapter efficiency</li> <li>Ensemble diversity monitor ensuring complementary models</li> </ul>"},{"location":"CHANGELOG/#constraint-enforcement","title":"Constraint Enforcement","text":"<ul> <li>Model size constraints based on dataset size</li> <li>Small datasets (under 10K): maximum 100M parameters</li> <li>Medium datasets (10K-100K): maximum 500M parameters</li> <li>Large datasets (over 100K): unlimited with monitoring</li> <li>XLarge model constraints for billion-parameter models</li> <li>LLM constraints for multi-billion parameter models</li> <li>Ensemble constraints limiting model count and diversity requirements</li> <li>Training constraints on epochs and early stopping</li> <li>Parameter efficiency requirements enforcing PEFT usage</li> <li>Augmentation constraints preventing over-augmentation</li> <li>Constraint enforcer with automatic violation handling</li> </ul>"},{"location":"CHANGELOG/#access-control-and-guards","title":"Access Control and Guards","text":"<ul> <li>Test set guard preventing unauthorized access</li> <li>Validation guard ensuring proper validation strategy</li> <li>Experiment guard for reproducibility requirements</li> <li>Access control logging all test set interactions</li> <li>Parameter freeze guard preventing backbone updates</li> <li>Configuration guard validating before training</li> </ul>"},{"location":"CHANGELOG/#recommendation-system","title":"Recommendation System","text":"<ul> <li>Model recommender based on dataset characteristics</li> <li>Configuration recommender suggesting safe hyperparameters</li> <li>Prevention technique recommender for overfitting risks</li> <li>Ensemble recommender for model combination</li> <li>LoRA recommender suggesting optimal rank</li> <li>Distillation recommender for compression strategies</li> <li>Parameter efficiency recommender optimizing trainable parameters</li> <li>Dataset-specific recommendations for AG News</li> </ul>"},{"location":"CHANGELOG/#reporting-and-analytics","title":"Reporting and Analytics","text":"<ul> <li>Overfitting reporter generating comprehensive reports</li> <li>Risk scorer quantifying overfitting probability</li> <li>Comparison reporter analyzing train/validation/test metrics</li> <li>HTML report generator with visualizations</li> <li>Parameter efficiency reporter comparing methods</li> <li>Benchmark comparison against published results</li> <li>Statistical significance testing for result validation</li> </ul>"},{"location":"CHANGELOG/#evaluation-and-analysis","title":"Evaluation and Analysis","text":""},{"location":"CHANGELOG/#metrics-computation","title":"Metrics Computation","text":"<ul> <li>Classification metrics (accuracy, precision, recall, F1-score)</li> <li>Per-class metrics for fine-grained analysis</li> <li>Confusion matrix computation and visualization</li> <li>ROC-AUC and PR-AUC for probabilistic evaluation</li> <li>Calibration metrics (Expected Calibration Error, Maximum Calibration Error)</li> <li>Overfitting metrics (train-validation gap, generalization gap)</li> <li>Diversity metrics for ensemble evaluation</li> <li>Efficiency metrics (parameters, FLOPs, inference time, memory)</li> </ul>"},{"location":"CHANGELOG/#error-analysis","title":"Error Analysis","text":"<ul> <li>Misclassification analysis identifying error patterns</li> <li>Confidence distribution analysis across predictions</li> <li>Hard example identification for targeted improvement</li> <li>Failure case analysis with error categorization</li> <li>Per-class error breakdown</li> <li>Confusion pattern detection</li> <li>Error correlation across ensemble members</li> </ul>"},{"location":"CHANGELOG/#model-interpretability","title":"Model Interpretability","text":"<ul> <li>Attention visualization using BertViz</li> <li>Attention weight extraction and analysis</li> <li>SHAP value computation for feature importance</li> <li>LIME explanations for individual predictions</li> <li>Integrated gradients for attribution analysis</li> <li>Feature importance ranking</li> <li>Layer-wise relevance propagation</li> <li>Saliency maps for input importance</li> </ul>"},{"location":"CHANGELOG/#lora-specific-analysis","title":"LoRA-Specific Analysis","text":"<ul> <li>LoRA rank impact analysis across tasks</li> <li>Weight distribution visualization for A and B matrices</li> <li>Adapter efficiency comparison across methods</li> <li>Parameter efficiency metrics</li> <li>Rank ablation studies</li> <li>LoRA weight visualization</li> </ul>"},{"location":"CHANGELOG/#ensemble-analysis","title":"Ensemble Analysis","text":"<ul> <li>Diversity measurement using multiple metrics</li> <li>Component contribution analysis via ablation</li> <li>Disagreement analysis across ensemble members</li> <li>Ensemble confidence calibration</li> <li>Member correlation analysis</li> <li>Ensemble pruning analysis</li> </ul>"},{"location":"CHANGELOG/#visualization-tools","title":"Visualization Tools","text":"<ul> <li>Training curves (loss, accuracy, learning rate)</li> <li>Confusion matrix heatmaps</li> <li>Attention maps with head-level analysis</li> <li>Embedding visualizations using t-SNE and UMAP</li> <li>LoRA weight distribution plots</li> <li>Ensemble diversity plots</li> <li>Performance comparison charts</li> </ul>"},{"location":"CHANGELOG/#experiment-management","title":"Experiment Management","text":""},{"location":"CHANGELOG/#experiment-infrastructure","title":"Experiment Infrastructure","text":"<ul> <li>Experiment runner with configuration management</li> <li>Experiment tagger for organization and retrieval</li> <li>Result aggregator combining multiple runs</li> <li>Leaderboard generator ranking models</li> <li>Reproducibility utilities (seed setting, deterministic operations)</li> <li>Experiment tracking with metadata</li> <li>Version control integration</li> </ul>"},{"location":"CHANGELOG/#hyperparameter-optimization","title":"Hyperparameter Optimization","text":"<ul> <li>Optuna integration with pruning algorithms</li> <li>Ray Tune distributed hyperparameter search</li> <li>Bayesian optimization with Gaussian processes</li> <li>Hyperband for efficient resource allocation</li> <li>LoRA rank search experiments</li> <li>Ensemble weight optimization</li> <li>Learning rate finder</li> <li>Batch size optimization</li> </ul>"},{"location":"CHANGELOG/#ablation-studies","title":"Ablation Studies","text":"<ul> <li>Model size ablation (base, large, xlarge, xxlarge)</li> <li>Data amount ablation (10%, 25%, 50%, 75%, 100%)</li> <li>LoRA rank ablation (4, 8, 16, 32, 64, 128)</li> <li>QLoRA bits ablation (4-bit vs 8-bit quantization)</li> <li>Regularization ablation (dropout, weight decay, R-Drop, Mixout)</li> <li>Augmentation impact analysis</li> <li>Ensemble size ablation (1, 3, 5, 7, 10 models)</li> <li>Ensemble component ablation (removing individual models)</li> <li>Prompt ablation (zero-shot, few-shot, instruction-tuned)</li> <li>Distillation temperature ablation (1.0, 2.0, 4.0, 8.0)</li> <li>Feature ablation (text only vs text with metadata)</li> </ul>"},{"location":"CHANGELOG/#sota-experiment-pipeline","title":"SOTA Experiment Pipeline","text":"<ul> <li>Phase 1: XLarge models with LoRA fine-tuning</li> <li>Phase 2: LLM models with QLoRA quantization</li> <li>Phase 3: LLM distillation to XLarge student models</li> <li>Phase 4: Ensemble of top XLarge models</li> <li>Phase 5: Ultimate SOTA combining all techniques</li> <li>Phase 6: Production-ready SOTA with optimization</li> <li>Single model SOTA experiments</li> <li>Ensemble SOTA experiments</li> <li>Full pipeline SOTA validation</li> <li>Production deployment experiments</li> <li>Prompt-based SOTA approaches</li> <li>Comprehensive approach comparison</li> </ul>"},{"location":"CHANGELOG/#baseline-experiments","title":"Baseline Experiments","text":"<ul> <li>Classical ML baselines (Naive Bayes, SVM, Random Forest, Logistic Regression)</li> <li>Neural baselines (LSTM, CNN, vanilla BERT)</li> <li>Transformer baselines (BERT base, RoBERTa base)</li> <li>Benchmark comparisons against published results</li> </ul>"},{"location":"CHANGELOG/#integration-with-tracking-platforms","title":"Integration with Tracking Platforms","text":"<ul> <li>Weights &amp; Biases integration</li> <li>Automatic experiment logging</li> <li>Hyperparameter tracking</li> <li>Artifact management</li> <li>Model versioning</li> <li>Custom dashboards</li> <li>MLflow integration</li> <li>Experiment tracking</li> <li>Model registry</li> <li>Model deployment</li> <li>Metric comparison</li> <li>TensorBoard logging</li> <li>Scalar metrics</li> <li>Image logging</li> <li>Embedding projector</li> <li>Hyperparameter tuning</li> <li>Custom scalars configuration</li> <li>Local monitoring</li> <li>File-based metrics storage</li> <li>Local TensorBoard server</li> <li>Local MLflow server</li> <li>SQLite-based tracking</li> </ul>"},{"location":"CHANGELOG/#api-and-serving","title":"API and Serving","text":""},{"location":"CHANGELOG/#restful-api","title":"RESTful API","text":"<ul> <li>FastAPI application with automatic OpenAPI documentation</li> <li>API routers</li> <li>Classification router for inference endpoints</li> <li>Training router for model training</li> <li>Models router for model management</li> <li>Data router for dataset operations</li> <li>Health router for system monitoring</li> <li>Metrics router for performance statistics</li> <li>Overfitting router for prevention system</li> <li>LLM router for large model operations</li> <li>Platform router for environment info</li> <li>Admin router for administrative tasks</li> <li>Request/Response schemas with Pydantic validation</li> <li>Error handling with detailed error messages</li> <li>CORS configuration for cross-origin requests</li> <li>Rate limiting preventing abuse</li> <li>Request validation and sanitization</li> <li>WebSocket handler for streaming predictions</li> <li>Server-sent events for real-time updates</li> </ul>"},{"location":"CHANGELOG/#authentication-and-security","title":"Authentication and Security","text":"<ul> <li>Token-based authentication with JWT</li> <li>API key management</li> <li>Role-based access control (RBAC)</li> <li>Rate limiting per user/IP</li> <li>Input validation and sanitization</li> <li>CORS policy enforcement</li> <li>Request logging and auditing</li> <li>Security headers configuration</li> </ul>"},{"location":"CHANGELOG/#middleware","title":"Middleware","text":"<ul> <li>Logging middleware tracking requests</li> <li>Metrics middleware collecting statistics</li> <li>Security middleware enforcing policies</li> <li>Error handling middleware</li> <li>Request ID middleware for tracing</li> <li>Compression middleware for responses</li> </ul>"},{"location":"CHANGELOG/#local-api","title":"Local API","text":"<ul> <li>Simplified API for offline deployment</li> <li>Batch API for processing multiple inputs</li> <li>Streaming API for real-time predictions</li> <li>File-based API for document classification</li> </ul>"},{"location":"CHANGELOG/#service-layer","title":"Service Layer","text":""},{"location":"CHANGELOG/#core-services","title":"Core Services","text":"<ul> <li>Prediction service handling inference requests</li> <li>Training service managing training jobs</li> <li>Data service for dataset operations</li> <li>Model management service for model lifecycle</li> <li>LLM service for large language model operations</li> <li>Service registry for dependency injection</li> <li>Base service with common functionality</li> </ul>"},{"location":"CHANGELOG/#local-services","title":"Local Services","text":"<ul> <li>Local cache service using diskcache</li> <li>Local queue service for background tasks</li> <li>File storage service for model artifacts</li> <li>SQLite-based tracking service</li> </ul>"},{"location":"CHANGELOG/#monitoring-services","title":"Monitoring Services","text":"<ul> <li>Monitoring router aggregating metrics</li> <li>TensorBoard service for visualization</li> <li>MLflow service for experiment tracking</li> <li>Weights &amp; Biases service integration</li> <li>Local metrics service for offline monitoring</li> <li>Logging service with structured logging</li> </ul>"},{"location":"CHANGELOG/#user-interfaces","title":"User Interfaces","text":""},{"location":"CHANGELOG/#streamlit-application","title":"Streamlit Application","text":"<ul> <li>20 interactive pages</li> <li>Home page with project overview</li> <li>Single prediction interface</li> <li>Batch analysis tool</li> <li>Model comparison dashboard</li> <li>Overfitting monitoring dashboard</li> <li>Model recommender system</li> <li>Parameter efficiency dashboard</li> <li>Interpretability viewer</li> <li>Performance dashboard</li> <li>Real-time demo</li> <li>Model selection wizard</li> <li>Documentation browser</li> <li>Prompt testing interface</li> <li>Local monitoring dashboard</li> <li>IDE setup guide</li> <li>Experiment tracker</li> <li>Platform information</li> <li>Quota dashboard</li> <li>Platform selector</li> <li>Auto-training UI</li> <li>Custom components</li> <li>Prediction component</li> <li>Overfitting monitor component</li> <li>LoRA config selector</li> <li>Ensemble builder</li> <li>Visualization component</li> <li>Model selector</li> <li>File uploader</li> <li>Result display</li> <li>Performance monitor</li> <li>Prompt builder</li> <li>IDE configurator</li> <li>Platform info component</li> <li>Quota monitor component</li> <li>Resource gauge</li> <li>Session management for state persistence</li> <li>Caching for performance optimization</li> <li>Custom theming and styling</li> <li>Helper utilities</li> </ul>"},{"location":"CHANGELOG/#gradio-application","title":"Gradio Application","text":"<ul> <li>Quick demo interface</li> <li>Model comparison tool</li> <li>Interactive prediction</li> <li>Visualization dashboard</li> </ul>"},{"location":"CHANGELOG/#command-line-interface","title":"Command-Line Interface","text":"<ul> <li>Main CLI with subcommands</li> <li>Rich formatting for output</li> <li>Progress bars for long operations</li> <li>Interactive prompts</li> <li>ASCII art for branding</li> <li>Comprehensive help messages</li> <li>Command aliases</li> </ul>"},{"location":"CHANGELOG/#documentation","title":"Documentation","text":""},{"location":"CHANGELOG/#top-level-documentation","title":"Top-Level Documentation","text":"<ul> <li>README.md with project overview and quick start</li> <li>ARCHITECTURE.md describing system design</li> <li>PERFORMANCE.md with benchmark results</li> <li>SECURITY.md covering security considerations</li> <li>TROUBLESHOOTING.md for common issues</li> <li>SOTA_MODELS_GUIDE.md for model selection</li> <li>OVERFITTING_PREVENTION.md for prevention strategies</li> <li>ROADMAP.md with future plans</li> <li>FREE_DEPLOYMENT_GUIDE.md for free-tier deployment</li> <li>PLATFORM_OPTIMIZATION_GUIDE.md for platform-specific optimization</li> <li>IDE_SETUP_GUIDE.md for multi-IDE support</li> <li>LOCAL_MONITORING_GUIDE.md for local monitoring setup</li> <li>QUICK_START.md for 5-minute getting started</li> <li>HEALTH_CHECK.md for system validation</li> <li>CHANGELOG.md (this file)</li> </ul>"},{"location":"CHANGELOG/#user-documentation","title":"User Documentation","text":"<ul> <li>Multi-level guides</li> <li>Level 1 Beginner: Installation, first model, evaluation, deployment</li> <li>Level 2 Intermediate: LoRA/QLoRA, ensemble, distillation, optimization</li> <li>Level 3 Advanced: SOTA pipeline, custom models, research workflow</li> <li>Platform guides</li> <li>Colab guide with free and Pro optimization</li> <li>Colab advanced features</li> <li>Kaggle guide with GPU and TPU support</li> <li>Kaggle TPU-specific guide</li> <li>Local deployment guide</li> <li>Gitpod cloud IDE setup</li> <li>Platform comparison matrix</li> <li>User guides</li> <li>Data preparation workflow</li> <li>Model training procedures</li> <li>Auto-training system</li> <li>LoRA configuration guide</li> <li>QLoRA setup guide</li> <li>Distillation guide</li> <li>Ensemble building guide</li> <li>Overfitting prevention practices</li> <li>Safe training procedures</li> <li>Evaluation methodology</li> <li>Local deployment instructions</li> <li>Quota management strategies</li> <li>Platform optimization techniques</li> <li>Prompt engineering guide</li> <li>Advanced techniques compendium</li> </ul>"},{"location":"CHANGELOG/#developer-documentation","title":"Developer Documentation","text":"<ul> <li>Architecture documentation</li> <li>Adding custom models guide</li> <li>Custom dataset integration</li> <li>Local API development</li> <li>Contributing guidelines</li> <li>Code organization principles</li> <li>Design patterns used</li> </ul>"},{"location":"CHANGELOG/#api-reference","title":"API Reference","text":"<ul> <li>REST API documentation</li> <li>Data API reference</li> <li>Models API reference</li> <li>Training API reference</li> <li>LoRA API reference</li> <li>Ensemble API reference</li> <li>Overfitting prevention API reference</li> <li>Platform API reference</li> <li>Quota API reference</li> <li>Evaluation API reference</li> </ul>"},{"location":"CHANGELOG/#ide-guides","title":"IDE Guides","text":"<ul> <li>Visual Studio Code setup with extensions and tasks</li> <li>PyCharm configuration with run configurations</li> <li>Jupyter Notebook/Lab setup with kernels</li> <li>Vim setup with CoC LSP</li> <li>Sublime Text project configuration</li> <li>IDE comparison and recommendations</li> </ul>"},{"location":"CHANGELOG/#tutorials","title":"Tutorials","text":"<ul> <li>Basic usage tutorial</li> <li>XLarge model training tutorial</li> <li>LLM fine-tuning tutorial</li> <li>Distillation tutorial</li> <li>SOTA pipeline tutorial</li> <li>Local training tutorial</li> <li>Free deployment tutorial</li> <li>Best practices guide</li> </ul>"},{"location":"CHANGELOG/#examples","title":"Examples","text":"<ul> <li>Hello world example</li> <li>Training baseline example</li> <li>SOTA pipeline example</li> <li>Custom model example</li> </ul>"},{"location":"CHANGELOG/#cheatsheets","title":"Cheatsheets","text":"<ul> <li>Model selection cheatsheet (PDF)</li> <li>Overfitting prevention checklist (PDF)</li> <li>Free deployment comparison (PDF)</li> <li>Platform comparison chart (PDF)</li> <li>Auto-training cheatsheet (PDF)</li> <li>Quota limits reference (PDF)</li> <li>CLI commands reference (PDF)</li> </ul>"},{"location":"CHANGELOG/#academic-documentation","title":"Academic Documentation","text":"<ul> <li>Architecture decision records (ADRs)</li> <li>Design patterns documentation</li> <li>System diagrams with PlantUML</li> <li>Best practices documentation</li> </ul>"},{"location":"CHANGELOG/#multi-ide-support","title":"Multi-IDE Support","text":""},{"location":"CHANGELOG/#ide-configurations","title":"IDE Configurations","text":"<ul> <li>Visual Studio Code</li> <li>Settings.json with Python configuration</li> <li>Launch.json with debugging configurations</li> <li>Tasks.json for build and test tasks</li> <li>Extensions.json recommending extensions</li> <li>Snippets for Python and YAML</li> <li>PyCharm</li> <li>Workspace configuration</li> <li>Inspection profiles</li> <li>Run configurations (train, test, API)</li> <li>Code style configuration</li> <li>Module settings</li> <li>Jupyter</li> <li>Notebook configuration</li> <li>Lab configuration</li> <li>Custom CSS styling</li> <li>Custom JavaScript extensions</li> <li>Nbextensions configuration</li> <li>User settings</li> <li>Workspace configuration</li> <li>Custom kernel configuration</li> <li>Vim</li> <li>Vimrc configuration</li> <li>CoC settings for LSP</li> <li>UltiSnips for code snippets</li> <li>Plugin recommendations</li> <li>Neovim</li> <li>Init.lua with Lua configuration</li> <li>Plugin management with Packer</li> <li>LSP configuration</li> <li>Keymaps for common tasks</li> <li>Custom commands</li> <li>Sublime Text</li> <li>Project file configuration</li> <li>Workspace settings</li> <li>Preferences for Python</li> <li>Code snippets</li> <li>Build systems for training and testing</li> <li>Cloud IDEs</li> <li>Gitpod configuration with Docker image</li> <li>GitHub Codespaces devcontainer</li> <li>Google Colab setup script</li> <li>Kaggle Kernels setup script</li> </ul>"},{"location":"CHANGELOG/#configuration-management","title":"Configuration Management","text":"<ul> <li>SOURCE_OF_TRUTH.yaml for canonical settings</li> <li>Automatic synchronization scripts</li> <li>IDE-specific README files</li> <li>Setup scripts per IDE</li> </ul>"},{"location":"CHANGELOG/#local-deployment-and-monitoring","title":"Local Deployment and Monitoring","text":""},{"location":"CHANGELOG/#docker-support","title":"Docker Support","text":"<ul> <li>Multi-stage Dockerfiles</li> <li>Base image with dependencies</li> <li>CPU-optimized image</li> <li>GPU-optimized image with CUDA</li> <li>Docker Compose orchestration</li> <li>API service</li> <li>TensorBoard service</li> <li>MLflow service</li> <li>Redis cache</li> <li>Nginx reverse proxy</li> <li>Docker ignore file</li> <li>Build optimization with layer caching</li> </ul>"},{"location":"CHANGELOG/#local-monitoring-stack","title":"Local Monitoring Stack","text":"<ul> <li>TensorBoard configuration</li> <li>Scalar metrics logging</li> <li>Image logging</li> <li>Embedding projector</li> <li>Custom scalars</li> <li>Hyperparameter tuning</li> <li>MLflow configuration</li> <li>Experiment tracking</li> <li>Model registry</li> <li>Artifact storage</li> <li>Metric comparison</li> <li>Dashboard customization</li> <li>Custom dashboards</li> <li>Training monitoring</li> <li>Overfitting detection</li> <li>Parameter efficiency tracking</li> <li>Platform metrics</li> <li>Quota monitoring</li> <li>Metrics collectors</li> <li>Custom metrics implementation</li> <li>Local metrics storage</li> <li>Model metrics tracking</li> <li>Training metrics collection</li> <li>Overfitting metrics</li> <li>Platform metrics</li> <li>Quota metrics</li> </ul>"},{"location":"CHANGELOG/#system-services","title":"System Services","text":"<ul> <li>Systemd service files</li> <li>API service</li> <li>Monitoring service</li> <li>Background worker service</li> <li>Nginx configuration</li> <li>Reverse proxy setup</li> <li>SSL/TLS termination</li> <li>Load balancing</li> <li>Static file serving</li> <li>Startup scripts</li> <li>TensorBoard launcher</li> <li>MLflow server launcher</li> <li>Weights &amp; Biases sync</li> <li>Platform monitoring</li> <li>Metrics export</li> <li>Quota export</li> <li>Report generation</li> </ul>"},{"location":"CHANGELOG/#caching-and-storage","title":"Caching and Storage","text":"<ul> <li>Local caching strategies</li> <li>Disk cache for models</li> <li>Memory cache for frequently accessed data</li> <li>LRU cache for limited memory</li> <li>SQLite database for tracking</li> <li>Experiment metadata</li> <li>Metrics history</li> <li>Model versions</li> <li>Quota tracking</li> <li>Backup and recovery</li> <li>Incremental backup strategy</li> <li>Local backup scripts</li> <li>Restore procedures</li> <li>Recovery plan documentation</li> </ul>"},{"location":"CHANGELOG/#testing-and-quality-assurance","title":"Testing and Quality Assurance","text":""},{"location":"CHANGELOG/#test-suite-organization","title":"Test Suite Organization","text":"<ul> <li>Unit tests (200+ tests)</li> <li>Data module tests</li> <li>Model module tests</li> <li>Training module tests</li> <li>Deployment module tests</li> <li>API tests</li> <li>Overfitting prevention tests</li> <li>Utility tests</li> <li>Integration tests (100+ tests)</li> <li>Full pipeline testing</li> <li>Auto-training flow</li> <li>Ensemble pipeline</li> <li>Inference pipeline</li> <li>Local API flow</li> <li>Prompt pipeline</li> <li>LLM integration</li> <li>Platform workflows</li> <li>Quota tracking flow</li> <li>Overfitting prevention flow</li> <li>Platform-specific tests</li> <li>Colab integration tests</li> <li>Kaggle integration tests</li> <li>Local environment tests</li> <li>Performance tests</li> <li>Model speed benchmarks</li> <li>Memory usage tests</li> <li>Accuracy benchmarks</li> <li>Local performance tests</li> <li>SLA compliance tests</li> <li>Throughput tests</li> <li>End-to-end tests</li> <li>Complete workflow testing</li> <li>User scenario tests</li> <li>Local deployment tests</li> <li>Free deployment tests</li> <li>Quickstart pipeline tests</li> <li>SOTA pipeline tests</li> <li>Auto-training on Colab</li> <li>Auto-training on Kaggle</li> <li>Quota enforcement tests</li> <li>Regression tests</li> <li>Model accuracy regression</li> <li>Ensemble diversity regression</li> <li>Inference speed regression</li> <li>Baseline comparison</li> <li>Chaos engineering tests</li> <li>Fault tolerance testing</li> <li>Corrupted configuration handling</li> <li>Out-of-memory handling</li> <li>Network failure resilience</li> <li>Compatibility tests</li> <li>PyTorch version compatibility</li> <li>Transformers version compatibility</li> <li>Cross-platform testing</li> <li>Python version matrix</li> </ul>"},{"location":"CHANGELOG/#test-infrastructure","title":"Test Infrastructure","text":"<ul> <li>Pytest configuration with markers</li> <li>Fixtures for test data</li> <li>Sample data fixtures</li> <li>Mock models</li> <li>Test configurations</li> <li>Local-specific fixtures</li> <li>Conftest with shared setup</li> <li>Test utilities and helpers</li> </ul>"},{"location":"CHANGELOG/#code-quality-tools","title":"Code Quality Tools","text":"<ul> <li>Black for code formatting (line length 100)</li> <li>isort for import sorting</li> <li>flake8 for linting with custom rules</li> <li>pylint for code analysis</li> <li>mypy for static type checking</li> <li>ruff for fast linting</li> <li>pre-commit hooks</li> <li>Black formatting</li> <li>isort import sorting</li> <li>flake8 linting</li> <li>mypy type checking</li> <li>Trailing whitespace removal</li> <li>YAML validation</li> <li>Large file prevention</li> <li>Commitlint for conventional commits</li> </ul>"},{"location":"CHANGELOG/#security-and-safety","title":"Security and Safety","text":"<ul> <li>Bandit for security scanning</li> <li>Safety for dependency vulnerability checking</li> <li>Secrets detection preventing credential leaks</li> <li>PII detection in data</li> <li>Data masking utilities</li> <li>Model checksum verification</li> <li>Dependency auditing</li> </ul>"},{"location":"CHANGELOG/#coverage-and-reporting","title":"Coverage and Reporting","text":"<ul> <li>pytest-cov for coverage tracking</li> <li>Coverage reports (term, HTML, XML)</li> <li>Branch coverage enabled</li> <li>Coverage thresholds enforced</li> <li>Coverage exclusions documented</li> </ul>"},{"location":"CHANGELOG/#configuration-management_1","title":"Configuration Management","text":""},{"location":"CHANGELOG/#configuration-structure","title":"Configuration Structure","text":"<ul> <li>300+ YAML configuration files</li> <li>Hierarchical organization</li> <li>API configurations</li> <li>Service configurations</li> <li>Environment configurations</li> <li>Feature flags</li> <li>Secrets templates</li> <li>Model configurations (60+ files)</li> <li>Training configurations (40+ files)</li> <li>Overfitting prevention configurations</li> <li>Data configurations</li> <li>Deployment configurations</li> <li>Quota configurations</li> <li>Experiment configurations</li> </ul>"},{"location":"CHANGELOG/#model-configurations","title":"Model Configurations","text":"<ul> <li>Recommended configurations</li> <li>Quick start configuration</li> <li>Balanced configuration</li> <li>SOTA accuracy configuration</li> <li>Tier 1 SOTA (XLarge with LoRA)</li> <li>Tier 2 LLM (QLoRA)</li> <li>Tier 3 Ensemble</li> <li>Tier 4 Distilled</li> <li>Tier 5 Free-optimized<ul> <li>Auto-selected for platforms</li> <li>Platform-specific optimizations</li> <li>Colab-friendly configurations</li> <li>CPU-friendly configurations</li> </ul> </li> <li>Single model configurations</li> <li>Transformer variants (30+ configs)</li> <li>LLM variants (15+ configs)</li> <li>Ensemble configurations</li> <li>Ensemble selection guide</li> <li>Presets (quick start, SOTA, balanced)</li> <li>Voting ensembles</li> <li>Stacking ensembles</li> <li>Blending ensembles</li> <li>Advanced ensembles</li> </ul>"},{"location":"CHANGELOG/#training-configurations","title":"Training Configurations","text":"<ul> <li>Standard training configurations</li> <li>Platform-adaptive configurations</li> <li>Colab free training</li> <li>Colab Pro training</li> <li>Kaggle GPU training</li> <li>Kaggle TPU training</li> <li>Local GPU training</li> <li>Local CPU training</li> <li>Efficient training (LoRA, QLoRA, Adapters, Prefix, Prompt, IA3, Combined)</li> <li>TPU optimization</li> <li>Advanced training (curriculum, adversarial, multitask, contrastive, distillation, meta-learning, instruction tuning, multi-stage)</li> <li>Regularization configurations (dropout, advanced regularization, data regularization, combined)</li> <li>Safe training configurations</li> </ul>"},{"location":"CHANGELOG/#configuration-tools","title":"Configuration Tools","text":"<ul> <li>Configuration loader with validation</li> <li>Configuration validator with schemas</li> <li>Configuration generator from templates</li> <li>Smart defaults system</li> <li>Configuration explainer</li> <li>Configuration comparator</li> <li>Configuration optimizer</li> <li>Sync manager for IDE configs</li> <li>Validation for all configs</li> </ul>"},{"location":"CHANGELOG/#platform-specific-features","title":"Platform-Specific Features","text":""},{"location":"CHANGELOG/#platform-detection","title":"Platform Detection","text":"<ul> <li>Automatic environment detection</li> <li>Google Colab (free and Pro)</li> <li>Kaggle Kernels (GPU and TPU)</li> <li>Local machine (CPU and GPU)</li> <li>Gitpod cloud IDE</li> <li>GitHub Codespaces</li> <li>HuggingFace Spaces</li> <li>Platform profiles with resource limits</li> <li>Smart selector choosing optimal configuration</li> </ul>"},{"location":"CHANGELOG/#quota-management","title":"Quota Management","text":"<ul> <li>Quota tracking system</li> <li>GPU hour tracking</li> <li>TPU hour tracking</li> <li>Session duration monitoring</li> <li>Resource usage logging</li> <li>Quota limits per platform</li> <li>Colab free: 12-15 GPU hours per week</li> <li>Colab Pro: 50-100 GPU hours per month</li> <li>Kaggle: 30 GPU hours + 30 TPU hours per week</li> <li>Platform quotas configuration</li> <li>Quota callbacks during training</li> <li>Quota dashboard in UI</li> <li>Usage history tracking</li> <li>Session logs</li> <li>Platform usage database</li> </ul>"},{"location":"CHANGELOG/#session-management","title":"Session Management","text":"<ul> <li>Session timeout handling</li> <li>Checkpoint auto-save before timeout</li> <li>Session recovery after disconnect</li> <li>Keep-alive utilities for Colab</li> <li>Progress persistence</li> <li>State synchronization</li> </ul>"},{"location":"CHANGELOG/#resource-monitoring","title":"Resource Monitoring","text":"<ul> <li>Real-time resource monitoring</li> <li>GPU memory tracking</li> <li>CPU usage monitoring</li> <li>Disk space monitoring</li> <li>Network bandwidth tracking</li> <li>Resource alerts and warnings</li> </ul>"},{"location":"CHANGELOG/#platform-optimization","title":"Platform Optimization","text":"<ul> <li>Colab optimizations</li> <li>Drive mounting and caching</li> <li>Session keep-alive</li> <li>Checkpoint frequency adjustment</li> <li>Memory-efficient training</li> <li>Kaggle optimizations</li> <li>Dataset caching</li> <li>TPU utilization</li> <li>Kernel time management</li> <li>Output size management</li> <li>Local optimizations</li> <li>Multi-GPU utilization</li> <li>CPU parallelization</li> <li>Memory management</li> <li>Disk I/O optimization</li> </ul>"},{"location":"CHANGELOG/#deployment-support","title":"Deployment Support","text":""},{"location":"CHANGELOG/#free-tier-deployment","title":"Free-Tier Deployment","text":"<ul> <li>Google Colab deployment</li> <li>Free tier (T4 GPU, 12GB RAM)</li> <li>Pro tier (V100/A100, 32GB RAM)</li> <li>Drive integration</li> <li>Session management</li> <li>Kaggle deployment</li> <li>GPU kernels (P100/T4, 16GB RAM)</li> <li>TPU kernels (TPU v3-8)</li> <li>Dataset integration</li> <li>Notebook scheduling</li> <li>HuggingFace Spaces</li> <li>Gradio app deployment</li> <li>Streamlit app deployment</li> <li>Model hosting</li> <li>Inference API</li> <li>Streamlit Cloud</li> <li>Free community tier</li> <li>Resource limitations</li> <li>GitHub integration</li> <li>GitHub Codespaces</li> <li>Development environment</li> <li>GPU support (paid)</li> <li>Integration with VS Code</li> <li>Gitpod</li> <li>Cloud IDE</li> <li>Prebuilt environments</li> <li>Docker-based workspace</li> </ul>"},{"location":"CHANGELOG/#local-deployment","title":"Local Deployment","text":"<ul> <li>Docker containerization</li> <li>Multi-stage builds</li> <li>CPU and GPU images</li> <li>Compose orchestration</li> <li>Systemd services</li> <li>API service</li> <li>Monitoring service</li> <li>Worker service</li> <li>Nginx reverse proxy</li> <li>SSL/TLS setup</li> <li>Load balancing</li> <li>Static file serving</li> <li>Process management</li> <li>Gunicorn for production</li> <li>Uvicorn for ASGI</li> <li>Supervisor for process control</li> </ul>"},{"location":"CHANGELOG/#model-optimization-for-deployment","title":"Model Optimization for Deployment","text":"<ul> <li>ONNX export for cross-platform inference</li> <li>Quantization (INT8, INT4) for reduced size</li> <li>Pruning for model compression</li> <li>Knowledge distillation to smaller models</li> <li>TensorRT optimization for NVIDIA GPUs</li> <li>OpenVINO optimization for Intel hardware</li> <li>Model caching for faster loading</li> <li>Batch inference for throughput</li> </ul>"},{"location":"CHANGELOG/#build-and-packaging","title":"Build and Packaging","text":""},{"location":"CHANGELOG/#python-packaging","title":"Python Packaging","text":"<ul> <li>setup.py with comprehensive metadata</li> <li>setup.cfg for declarative configuration</li> <li>pyproject.toml for modern packaging</li> <li>MANIFEST.in for additional files</li> <li>Version management in version.py</li> <li>Automatic version from git tags with setuptools-scm</li> </ul>"},{"location":"CHANGELOG/#requirements-management","title":"Requirements Management","text":"<ul> <li>Modular requirements files (15+ files)</li> <li>base.txt: Core dependencies</li> <li>ml.txt: Machine learning libraries</li> <li>llm.txt: Large language model support</li> <li>efficient.txt: Parameter-efficient fine-tuning</li> <li>data.txt: Data processing tools</li> <li>ui.txt: User interface libraries</li> <li>dev.txt: Development tools</li> <li>docs.txt: Documentation generation</li> <li>research.txt: Research and experimentation</li> <li>robustness.txt: Robustness testing</li> <li>local_prod.txt: Local production deployment</li> <li>all_local.txt: Complete local installation</li> <li>colab.txt: Google Colab specific</li> <li>kaggle.txt: Kaggle Kernels specific</li> <li>free_tier.txt: Free-tier platforms</li> <li>local_monitoring.txt: Local monitoring stack</li> <li>minimal.txt: Minimal installation</li> <li>platform_minimal.txt: Platform-specific minimal</li> <li>Locked requirements for reproducibility</li> <li>base.lock</li> <li>ml.lock</li> <li>llm.lock</li> <li>all.lock</li> </ul>"},{"location":"CHANGELOG/#build-automation","title":"Build Automation","text":"<ul> <li>Makefile with 70+ targets</li> <li>Installation targets</li> <li>Testing targets</li> <li>Linting and formatting targets</li> <li>Documentation building targets</li> <li>Deployment targets</li> <li>Cleaning targets</li> <li>Installation scripts</li> <li>install.sh for automated setup</li> <li>Platform-specific setup scripts</li> <li>Environment validation scripts</li> <li>Dependency verification</li> </ul>"},{"location":"CHANGELOG/#research-and-experimentation-tools","title":"Research and Experimentation Tools","text":""},{"location":"CHANGELOG/#benchmarking","title":"Benchmarking","text":"<ul> <li>Accuracy benchmarks</li> <li>Model comparison results</li> <li>XLarge model benchmarks</li> <li>LLM model benchmarks</li> <li>Ensemble results</li> <li>SOTA benchmarks</li> <li>Efficiency benchmarks</li> <li>Parameter efficiency comparison</li> <li>Memory usage profiling</li> <li>Training time measurements</li> <li>Inference speed testing</li> <li>Platform comparison</li> <li>Robustness benchmarks</li> <li>Adversarial robustness results</li> <li>Out-of-distribution detection</li> <li>Contrast set evaluation</li> <li>Overfitting benchmarks</li> <li>Train-validation gap analysis</li> <li>LoRA rank impact</li> <li>Prevention effectiveness</li> </ul>"},{"location":"CHANGELOG/#statistical-analysis","title":"Statistical Analysis","text":"<ul> <li>Significance testing (t-tests, Mann-Whitney U)</li> <li>Confidence interval computation</li> <li>Effect size calculation (Cohen's d)</li> <li>Multiple comparison correction (Bonferroni, Holm)</li> <li>Bootstrap resampling</li> <li>Cross-validation analysis</li> <li>Ablation study statistics</li> </ul>"},{"location":"CHANGELOG/#visualization","title":"Visualization","text":"<ul> <li>Training curves with smoothing</li> <li>Confusion matrix heatmaps</li> <li>ROC and PR curves</li> <li>Calibration plots</li> <li>Attention visualization</li> <li>Embedding projections (t-SNE, UMAP)</li> <li>LoRA weight distributions</li> <li>Ensemble diversity plots</li> <li>Performance comparison charts</li> </ul>"},{"location":"CHANGELOG/#profiling","title":"Profiling","text":"<ul> <li>Memory profiler tracking allocation</li> <li>Speed profiler identifying bottlenecks</li> <li>GPU profiler using NVIDIA tools</li> <li>Parameter counter for model analysis</li> <li>Local profiler for deployment testing</li> </ul>"},{"location":"CHANGELOG/#debugging-tools","title":"Debugging Tools","text":"<ul> <li>Model debugger for architecture inspection</li> <li>Overfitting debugger analyzing prevention</li> <li>LoRA debugger for adapter analysis</li> <li>Data validator ensuring quality</li> <li>Platform debugger for environment issues</li> <li>Quota debugger for resource tracking</li> <li>Local debugger for deployment issues</li> </ul>"},{"location":"CHANGELOG/#security-features","title":"Security Features","text":""},{"location":"CHANGELOG/#input-security","title":"Input Security","text":"<ul> <li>Input validation for all endpoints</li> <li>Request sanitization preventing injection</li> <li>File upload validation</li> <li>Size limits on inputs</li> <li>Type checking and schema validation</li> </ul>"},{"location":"CHANGELOG/#authentication","title":"Authentication","text":"<ul> <li>Token-based authentication with JWT</li> <li>API key management</li> <li>Local RBAC for role-based access</li> <li>Session management with expiration</li> </ul>"},{"location":"CHANGELOG/#data-privacy","title":"Data Privacy","text":"<ul> <li>PII detection in text data</li> <li>Data masking utilities</li> <li>Anonymization for logging</li> <li>Secure secret storage</li> <li>Environment variable management</li> </ul>"},{"location":"CHANGELOG/#model-security","title":"Model Security","text":"<ul> <li>Adversarial defense mechanisms</li> <li>Model checksum verification</li> <li>Input perturbation detection</li> <li>Output confidence filtering</li> <li>Rate limiting per user</li> </ul>"},{"location":"CHANGELOG/#development-tools","title":"Development Tools","text":""},{"location":"CHANGELOG/#automation","title":"Automation","text":"<ul> <li>Health check runner for validation</li> <li>Auto-fix runner for common issues</li> <li>Batch configuration generator</li> <li>Platform health monitoring</li> <li>Nightly tasks automation</li> </ul>"},{"location":"CHANGELOG/#cli-helpers","title":"CLI Helpers","text":"<ul> <li>Rich console for formatting</li> <li>Progress bars with rich</li> <li>Interactive prompts with questionary</li> <li>ASCII art for branding</li> <li>Colored output for readability</li> </ul>"},{"location":"CHANGELOG/#compatibility-tools","title":"Compatibility Tools","text":"<ul> <li>Compatibility checker for versions</li> <li>Version matrix tester</li> <li>Upgrade path finder</li> <li>Dependency conflict resolver</li> </ul>"},{"location":"CHANGELOG/#cost-tools","title":"Cost Tools","text":"<ul> <li>Cost estimator for cloud resources</li> <li>Cost comparator across platforms</li> <li>Free-tier optimization recommendations</li> </ul>"},{"location":"CHANGELOG/#performance-achievements","title":"Performance Achievements","text":""},{"location":"CHANGELOG/#accuracy-results-on-ag-news-dataset","title":"Accuracy Results on AG News Dataset","text":"<ul> <li>DeBERTa v3 base: 94.5% test accuracy (baseline)</li> <li>DeBERTa v3 large: 95.8% test accuracy</li> <li>DeBERTa v3 xlarge with LoRA (r=32): 96.7% test accuracy</li> <li>DeBERTa v2 xxlarge with QLoRA (4-bit): 97.1% test accuracy</li> <li>RoBERTa large with LoRA (r=16): 95.9% test accuracy</li> <li>ELECTRA large with LoRA (r=32): 95.7% test accuracy</li> <li>XLNet large with LoRA (r=32): 95.6% test accuracy</li> <li>LLaMA 2 7B with QLoRA (r=64): 95.4% test accuracy</li> <li>LLaMA 2 13B with QLoRA (r=64): 96.2% test accuracy</li> <li>Mistral 7B with QLoRA (r=64): 95.8% test accuracy</li> <li>Ensemble (5 XLarge models, soft voting): 97.8% test accuracy</li> <li>Ensemble (5 XLarge models, stacking): 97.9% test accuracy</li> <li>Ultimate SOTA (Ensemble + Knowledge Distillation): 98.0% test accuracy</li> </ul>"},{"location":"CHANGELOG/#parameter-efficiency","title":"Parameter Efficiency","text":"<ul> <li>LoRA reduces trainable parameters by 99% (from 900M to 9M for DeBERTa-xlarge with r=32)</li> <li>QLoRA enables 70B parameter models on 40GB GPU (vs 280GB required for full precision)</li> <li>Adapter methods: 0.5-2% trainable parameters of full model</li> <li>Prefix tuning: 0.1-0.5% trainable parameters</li> <li>Prompt tuning: under 0.1% trainable parameters</li> <li>IA3: under 0.01% trainable parameters</li> </ul>"},{"location":"CHANGELOG/#training-efficiency","title":"Training Efficiency","text":"<ul> <li>Mixed precision training: 2x speedup with FP16, 1.8x with BF16</li> <li>Gradient checkpointing: 40-50% memory reduction with 20% time overhead</li> <li>Gradient accumulation: enables effective batch size 256 on 16GB GPU</li> <li>LoRA training: 3x faster than full fine-tuning</li> <li>QLoRA training: enables 13B models on consumer GPUs (24GB VRAM)</li> </ul>"},{"location":"CHANGELOG/#inference-performance","title":"Inference Performance","text":"<ul> <li>Single model latency: 10-50ms on GPU, 50-200ms on CPU</li> <li>Ensemble latency: 50-200ms on GPU (parallel execution)</li> <li>Batch inference throughput: 100-500 samples/sec (CPU), 500-2000 samples/sec (GPU)</li> <li>ONNX optimized inference: 2-3x speedup over PyTorch</li> <li>INT8 quantized inference: 4x speedup with minimal accuracy loss (under 0.5%)</li> <li>Model loading time: under 5 seconds for LoRA adapters</li> </ul>"},{"location":"CHANGELOG/#resource-requirements","title":"Resource Requirements","text":"<ul> <li>Minimum for inference only: 4GB RAM, 2 CPU cores</li> <li>Recommended for development: 16GB RAM, 4 CPU cores, 8GB GPU</li> <li>SOTA training: 32GB RAM, 8 CPU cores, 24GB GPU</li> <li>Free tier compatibility: Colab (T4 12GB), Kaggle (P100 16GB)</li> </ul>"},{"location":"CHANGELOG/#generalization-performance","title":"Generalization Performance","text":"<ul> <li>Train-validation gap: under 0.5% for properly regularized models</li> <li>Cross-validation standard deviation: under 0.3% across 5 folds</li> <li>Performance on contrast sets: 90%+ accuracy (robustness test)</li> <li>Calibration error (ECE): under 5% for ensemble models</li> <li>Out-of-distribution detection AUROC: 85%+ using confidence thresholding</li> </ul>"},{"location":"CHANGELOG/#documentation-statistics","title":"Documentation Statistics","text":""},{"location":"CHANGELOG/#documentation-files","title":"Documentation Files","text":"<ul> <li>15 top-level documentation files</li> <li>100+ markdown documentation pages</li> <li>50+ tutorial notebooks</li> <li>300+ YAML configuration files</li> <li>1000+ docstrings in code</li> <li>API reference for all modules</li> <li>Comprehensive README files in each directory</li> </ul>"},{"location":"CHANGELOG/#code-statistics","title":"Code Statistics","text":"<ul> <li>50,000+ lines of Python code</li> <li>700+ files in project structure</li> <li>200+ unit tests</li> <li>100+ integration tests</li> <li>Type hints on 90%+ of functions</li> <li>Docstring coverage: 95%+</li> </ul>"},{"location":"CHANGELOG/#fixed","title":"Fixed","text":""},{"location":"CHANGELOG/#initial-release-fixes","title":"Initial Release Fixes","text":"<ul> <li>None (initial release baseline)</li> </ul>"},{"location":"CHANGELOG/#security","title":"Security","text":""},{"location":"CHANGELOG/#security-measures-implemented","title":"Security Measures Implemented","text":"<ul> <li>Input validation on all API endpoints preventing injection attacks</li> <li>Rate limiting (100 requests per minute per IP) preventing abuse</li> <li>Token-based authentication with JWT and configurable expiration</li> <li>CORS configuration restricting origins</li> <li>Secrets management using environment variables and templates</li> <li>PII detection and masking in data processing</li> <li>Model checksum verification ensuring integrity</li> <li>Dependency vulnerability scanning with safety and bandit</li> <li>SQL injection prevention through parameterized queries</li> <li>XSS protection through output encoding</li> <li>Secure headers configuration (HSTS, CSP, X-Frame-Options)</li> <li>File upload size limits (10MB default)</li> <li>Request timeout enforcement (30 seconds default)</li> <li>Logging of security events for auditing</li> </ul>"},{"location":"CHANGELOG/#known-issues-and-limitations","title":"Known Issues and Limitations","text":""},{"location":"CHANGELOG/#platform-limitations","title":"Platform Limitations","text":"<ul> <li>Flash Attention 2 only supported on Linux with CUDA 11.8+</li> <li>DeepSpeed not available on Windows platforms</li> <li>Some packages incompatible with Python 3.12 (maximum 3.11)</li> <li>ROCm (AMD GPU) support experimental and not fully tested</li> <li>Apple Silicon (M1/M2) support limited for some quantization features</li> <li>Google Colab free tier has session timeout (12 hours)</li> <li>Kaggle Kernels limited to 9 hours per session</li> <li>HuggingFace Spaces free tier CPU-only with 16GB RAM limit</li> </ul>"},{"location":"CHANGELOG/#model-limitations","title":"Model Limitations","text":"<ul> <li>Maximum sequence length: 512 tokens (standard models), 4096 tokens (Longformer)</li> <li>LLM inference requires significant memory (7B model minimum 4GB VRAM with QLoRA)</li> <li>Very large ensembles (10+ models) have slow inference (over 500ms latency)</li> <li>Quantization may cause 0.5-2% accuracy degradation</li> <li>Some models not compatible with ONNX export (e.g., Mixtral MoE)</li> </ul>"},{"location":"CHANGELOG/#data-limitations","title":"Data Limitations","text":"<ul> <li>AG News dataset limited to English language</li> <li>Four class categories (World, Sports, Business, Technology)</li> <li>Training set: 120,000 samples</li> <li>Test set: 7,600 samples</li> <li>No validation set provided (requires manual split)</li> <li>Text truncation needed for documents over 512 tokens</li> </ul>"},{"location":"CHANGELOG/#known-bugs","title":"Known Bugs","text":"<ul> <li>None identified in this release</li> </ul>"},{"location":"CHANGELOG/#future-improvements","title":"Future Improvements","text":"<ul> <li>Support for additional languages beyond English</li> <li>Integration with more experiment tracking platforms</li> <li>Enhanced AutoML capabilities</li> <li>Mobile deployment tools (TFLite, Core ML)</li> <li>Real-time learning pipelines</li> <li>Federated learning support</li> </ul>"},{"location":"CHANGELOG/#dependencies","title":"Dependencies","text":""},{"location":"CHANGELOG/#core-dependencies","title":"Core Dependencies","text":"<ul> <li>Python: 3.8, 3.9, 3.10, or 3.11</li> <li>PyTorch: 2.1.0 to 2.2.x</li> <li>Transformers: 4.36.0 to 4.40.x</li> <li>Tokenizers: 0.15.0 to 0.15.x</li> <li>Datasets: 2.16.0 to 2.19.x</li> <li>Accelerate: 0.25.0 to 0.30.x</li> <li>PEFT: 0.7.0 to 0.11.x</li> </ul>"},{"location":"CHANGELOG/#optional-dependencies","title":"Optional Dependencies","text":"<ul> <li>CUDA: 11.8 or 12.1 (for GPU training)</li> <li>cuDNN: 8.x (for GPU optimization)</li> <li>Flash Attention: 2.4.0+ (Linux only, for faster attention)</li> <li>DeepSpeed: 0.12.0+ (Linux only, for advanced training)</li> <li>bitsandbytes: 0.41.0+ (for quantization)</li> <li>ONNX: 1.15.0+ (for model export)</li> <li>TensorRT: 8.x (for NVIDIA inference optimization)</li> <li>OpenVINO: 2023.x (for Intel optimization)</li> </ul>"},{"location":"CHANGELOG/#development-dependencies","title":"Development Dependencies","text":"<ul> <li>pytest: 7.4.0+</li> <li>black: 23.12.0+</li> <li>mypy: 1.8.0+</li> <li>flake8: 7.0.0+</li> <li>pre-commit: 3.6.0+</li> </ul>"},{"location":"CHANGELOG/#total-dependencies-by-profile","title":"Total Dependencies by Profile","text":"<ul> <li>Base installation: 50+ packages</li> <li>ML profile: 150+ packages</li> <li>LLM profile: 200+ packages</li> <li>All dependencies: 400+ packages</li> </ul>"},{"location":"CHANGELOG/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>None (initial release)</li> </ul>"},{"location":"CHANGELOG/#deprecations","title":"Deprecations","text":"<ul> <li>None (initial release)</li> </ul>"},{"location":"CHANGELOG/#migration-guide","title":"Migration Guide","text":"<ul> <li>Not applicable for initial release</li> </ul>"},{"location":"CHANGELOG/#version-numbering-scheme","title":"Version Numbering Scheme","text":"<p>This project follows Semantic Versioning 2.0.0 (https://semver.org/):</p> <ul> <li>MAJOR version (X.0.0): Incompatible API changes breaking backward compatibility</li> <li>MINOR version (0.X.0): New functionality added in backward-compatible manner</li> <li>PATCH version (0.0.X): Backward-compatible bug fixes and minor improvements</li> </ul>"},{"location":"CHANGELOG/#pre-release-version-suffixes","title":"Pre-release Version Suffixes","text":"<ul> <li>Alpha (X.Y.Z-alpha.N): Early development stage, unstable, not feature-complete</li> <li>Beta (X.Y.Z-beta.N): Feature-complete, undergoing testing, may have bugs</li> <li>Release Candidate (X.Y.Z-rc.N): Final testing before release, minimal changes expected</li> </ul>"},{"location":"CHANGELOG/#version-increment-guidelines","title":"Version Increment Guidelines","text":"<ul> <li>Increment MAJOR when making incompatible API changes</li> <li>Increment MINOR when adding backward-compatible functionality</li> <li>Increment PATCH when making backward-compatible bug fixes</li> <li>Use pre-release suffixes for development versions</li> </ul>"},{"location":"CHANGELOG/#changelog-categories","title":"Changelog Categories","text":""},{"location":"CHANGELOG/#added_1","title":"Added","text":"<p>New features, capabilities, or documentation added to the project.</p>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<p>Changes to existing functionality, behavior, or documentation.</p>"},{"location":"CHANGELOG/#deprecated","title":"Deprecated","text":"<p>Features marked for removal in future versions with migration path provided.</p>"},{"location":"CHANGELOG/#removed","title":"Removed","text":"<p>Features or capabilities removed from the project.</p>"},{"location":"CHANGELOG/#fixed_1","title":"Fixed","text":"<p>Bug fixes, error corrections, or improvements to existing functionality.</p>"},{"location":"CHANGELOG/#security_1","title":"Security","text":"<p>Security-related changes, vulnerability fixes, or security improvements.</p>"},{"location":"CHANGELOG/#contributing-to-this-changelog","title":"Contributing to This Changelog","text":"<p>When making changes to the project, contributors should:</p> <ol> <li>Add entries to the [Unreleased] section under appropriate category</li> <li>Use clear, concise descriptions explaining the change and its impact</li> <li>Reference issue numbers using #issue_number format when applicable</li> <li>Follow conventional commit message format for consistency</li> <li>Update changelog with each significant commit or pull request</li> <li>Ensure changes are documented before release</li> </ol>"},{"location":"CHANGELOG/#release-process","title":"Release Process","text":"<p>Standard release workflow:</p> <ol> <li>Update version number in src/version.py</li> <li>Move [Unreleased] changes to new version section with release date</li> <li>Add comprehensive release notes summarizing changes</li> <li>Update comparison links at bottom of file</li> <li>Commit changelog with message \"chore: update changelog for vX.Y.Z\"</li> <li>Create annotated git tag: git tag -a vX.Y.Z -m \"Release vX.Y.Z\"</li> <li>Push commits and tags: git push origin main --tags</li> <li>Create GitHub release with changelog excerpt</li> <li>Build and upload package to PyPI</li> <li>Update documentation with new version</li> </ol>"},{"location":"CHANGELOG/#links-and-references","title":"Links and References","text":"<ul> <li>Repository: https://github.com/VoHaiDung/ag-news-text-classification</li> <li>Documentation: https://github.com/VoHaiDung/ag-news-text-classification#readme</li> <li>Issue Tracker: https://github.com/VoHaiDung/ag-news-text-classification/issues</li> <li>Discussions: https://github.com/VoHaiDung/ag-news-text-classification/discussions</li> <li>Keep a Changelog: https://keepachangelog.com/en/1.0.0/</li> <li>Semantic Versioning: https://semver.org/spec/v2.0.0.html</li> <li>Conventional Commits: https://www.conventionalcommits.org/</li> </ul>"},{"location":"CHANGELOG/#acknowledgments","title":"Acknowledgments","text":"<p>This project builds upon foundational research and open-source contributions:</p> <ul> <li>HuggingFace Transformers library for transformer model implementations</li> <li>PyTorch framework for deep learning infrastructure</li> <li>AG News dataset (Zhang et al., 2015) \"Character-level Convolutional Networks for Text Classification\"</li> <li>LoRA (Hu et al., 2021) \"LoRA: Low-Rank Adaptation of Large Language Models\"</li> <li>QLoRA (Dettmers et al., 2023) \"QLoRA: Efficient Finetuning of Quantized LLMs\"</li> <li>DeBERTa (He et al., 2020) \"DeBERTa: Decoding-enhanced BERT with Disentangled Attention\"</li> <li>DeBERTa v3 (He et al., 2021) \"DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training\"</li> <li>LLaMA (Touvron et al., 2023) \"LLaMA: Open and Efficient Foundation Language Models\"</li> <li>LLaMA 2 (Touvron et al., 2023) \"LLaMA 2: Open Foundation and Fine-Tuned Chat Models\"</li> <li>Mistral (Jiang et al., 2023) \"Mistral 7B\"</li> <li>RoBERTa (Liu et al., 2019) \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\"</li> <li>ELECTRA (Clark et al., 2020) \"ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators\"</li> </ul>"},{"location":"CHANGELOG/#citation","title":"Citation","text":"<p>If you use this project in your research or applications, please cite:</p> BibTeX<pre><code>@software{vo2025agnews,\n  author = {V\u00f5 H\u1ea3i D\u0169ng},\n  title = {AG News Text Classification: A Comprehensive Framework with Overfitting Prevention},\n  year = {2025},\n  url = {https://github.com/VoHaiDung/ag-news-text-classification},\n  version = {1.0.0},\n  license = {MIT}\n}\n</code></pre> <p>For specific components or techniques, please also cite the original research papers.</p>"},{"location":"CHANGELOG/#license","title":"License","text":"<p>This project is licensed under the MIT License. See the LICENSE file for complete details.</p> <p>The MIT License grants permission to use, copy, modify, merge, publish, distribute, sublicense, and sell copies of the software, subject to including the copyright notice and permission notice in all copies or substantial portions.</p> <p>Maintained by: V\u00f5 H\u1ea3i D\u0169ng Email: vohaidung.work@gmail.com Last Updated: 2025-09-19  </p>"},{"location":"FREE_DEPLOYMENT_GUIDE/","title":"FREE_DEPLOYMENT_GUIDE","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"FREE_DEPLOYMENT_GUIDE/#overview","title":"Overview","text":"<p>Comprehensive guide for FREE_DEPLOYMENT_GUIDE.</p>"},{"location":"FREE_DEPLOYMENT_GUIDE/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"FREE_DEPLOYMENT_GUIDE/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"FREE_DEPLOYMENT_GUIDE/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"HEALTH_CHECK/","title":"HEALTH_CHECK","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"HEALTH_CHECK/#overview","title":"Overview","text":"<p>Comprehensive guide for HEALTH_CHECK.</p>"},{"location":"HEALTH_CHECK/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"HEALTH_CHECK/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"HEALTH_CHECK/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"IDE_SETUP_GUIDE/","title":"IDE_SETUP_GUIDE","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"IDE_SETUP_GUIDE/#overview","title":"Overview","text":"<p>Comprehensive guide for IDE_SETUP_GUIDE.</p>"},{"location":"IDE_SETUP_GUIDE/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"IDE_SETUP_GUIDE/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"IDE_SETUP_GUIDE/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"LOCAL_MONITORING_GUIDE/","title":"LOCAL_MONITORING_GUIDE","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"LOCAL_MONITORING_GUIDE/#overview","title":"Overview","text":"<p>Comprehensive guide for LOCAL_MONITORING_GUIDE.</p>"},{"location":"LOCAL_MONITORING_GUIDE/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"LOCAL_MONITORING_GUIDE/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"LOCAL_MONITORING_GUIDE/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"OVERFITTING_PREVENTION/","title":"OVERFITTING_PREVENTION","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"OVERFITTING_PREVENTION/#overview","title":"Overview","text":"<p>Comprehensive guide for OVERFITTING_PREVENTION.</p>"},{"location":"OVERFITTING_PREVENTION/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"OVERFITTING_PREVENTION/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"OVERFITTING_PREVENTION/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"PERFORMANCE/","title":"PERFORMANCE","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"PERFORMANCE/#overview","title":"Overview","text":"<p>Comprehensive guide for PERFORMANCE.</p>"},{"location":"PERFORMANCE/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"PERFORMANCE/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"PERFORMANCE/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"PLATFORM_OPTIMIZATION_GUIDE/","title":"PLATFORM_OPTIMIZATION_GUIDE","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"PLATFORM_OPTIMIZATION_GUIDE/#overview","title":"Overview","text":"<p>Comprehensive guide for PLATFORM_OPTIMIZATION_GUIDE.</p>"},{"location":"PLATFORM_OPTIMIZATION_GUIDE/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"PLATFORM_OPTIMIZATION_GUIDE/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"PLATFORM_OPTIMIZATION_GUIDE/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"QUICK_START/","title":"QUICK_START","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"QUICK_START/#overview","title":"Overview","text":"<p>Comprehensive guide for QUICK_START.</p>"},{"location":"QUICK_START/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"QUICK_START/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"QUICK_START/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"ROADMAP/","title":"ROADMAP","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"ROADMAP/#overview","title":"Overview","text":"<p>Comprehensive guide for ROADMAP.</p>"},{"location":"ROADMAP/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"ROADMAP/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"ROADMAP/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"SECURITY/","title":"SECURITY","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"SECURITY/#overview","title":"Overview","text":"<p>Comprehensive guide for SECURITY.</p>"},{"location":"SECURITY/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"SECURITY/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"SECURITY/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"SOTA_MODELS_GUIDE/","title":"SOTA_MODELS_GUIDE","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"SOTA_MODELS_GUIDE/#overview","title":"Overview","text":"<p>Comprehensive guide for SOTA_MODELS_GUIDE.</p>"},{"location":"SOTA_MODELS_GUIDE/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"SOTA_MODELS_GUIDE/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"SOTA_MODELS_GUIDE/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"TROUBLESHOOTING/","title":"TROUBLESHOOTING","text":"<p>This documentation is under development for AG News Text Classification.</p>"},{"location":"TROUBLESHOOTING/#overview","title":"Overview","text":"<p>Comprehensive guide for TROUBLESHOOTING.</p>"},{"location":"TROUBLESHOOTING/#contents","title":"Contents","text":"<p>Documentation content will be added here.</p>"},{"location":"TROUBLESHOOTING/#author","title":"Author","text":"<p>V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"TROUBLESHOOTING/#contact","title":"Contact","text":"<p>For questions or support, contact: vohaidung.work@gmail.com</p>"},{"location":"getting_started/choosing_platform/","title":"Platform Selection Guide","text":"<p>Choose the best platform for your needs in AG News Text Classification.</p>"},{"location":"getting_started/choosing_platform/#available-platforms","title":"Available Platforms","text":""},{"location":"getting_started/choosing_platform/#google-colab","title":"Google Colab","text":"<ul> <li>Free GPU access (T4)</li> <li>Easy to start</li> <li>Session limits (12 hours)</li> <li>Recommended for: Quick experiments, learning</li> </ul>"},{"location":"getting_started/choosing_platform/#kaggle","title":"Kaggle","text":"<ul> <li>Free GPU/TPU access</li> <li>Longer sessions (9-12 hours)</li> <li>Dataset integration</li> <li>Recommended for: Training, competitions</li> </ul>"},{"location":"getting_started/choosing_platform/#local","title":"Local","text":"<ul> <li>Full control</li> <li>No time limits</li> <li>Hardware dependent</li> <li>Recommended for: Development, production</li> </ul>"},{"location":"getting_started/choosing_platform/#platform-comparison","title":"Platform Comparison","text":"<p>See PLATFORM_OPTIMIZATION_GUIDE.md for detailed comparison.</p> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"getting_started/free_deployment/","title":"Free Deployment Guide","text":"<p>Deploy AG News Text Classification without monthly costs.</p>"},{"location":"getting_started/free_deployment/#deployment-options","title":"Deployment Options","text":""},{"location":"getting_started/free_deployment/#hugging-face-spaces","title":"Hugging Face Spaces","text":"<ul> <li>Free hosting</li> <li>Automatic deployment</li> <li>Community visibility</li> </ul>"},{"location":"getting_started/free_deployment/#streamlit-cloud","title":"Streamlit Cloud","text":"<ul> <li>Free tier available</li> <li>Easy deployment</li> <li>Streamlit integration</li> </ul>"},{"location":"getting_started/free_deployment/#local-deployment","title":"Local Deployment","text":"<ul> <li>No cost</li> <li>Full control</li> <li>Self-hosted</li> </ul>"},{"location":"getting_started/free_deployment/#setup-instructions","title":"Setup Instructions","text":"<p>See FREE_DEPLOYMENT_GUIDE.md for detailed instructions.</p> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"getting_started/installation/","title":"Installation Guide","text":"<p>Comprehensive installation instructions for AG News Text Classification.</p>"},{"location":"getting_started/installation/#quick-installation","title":"Quick Installation","text":"Bash<pre><code>git clone https://github.com/VoHaiDung/ag-news-text-classification.git\ncd ag-news-text-classification\npip install -r requirements/base.txt\n</code></pre>"},{"location":"getting_started/installation/#platform-specific-installation","title":"Platform-Specific Installation","text":""},{"location":"getting_started/installation/#google-colab","title":"Google Colab","text":"<p>See Colab Guide for setup instructions.</p>"},{"location":"getting_started/installation/#kaggle","title":"Kaggle","text":"<p>See Kaggle Guide for setup instructions.</p>"},{"location":"getting_started/installation/#local-setup","title":"Local Setup","text":"<p>See Local Guide for detailed local installation.</p>"},{"location":"getting_started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.8+</li> <li>PyTorch 2.0+</li> <li>Transformers 4.30+</li> </ul>"},{"location":"getting_started/installation/#verification","title":"Verification","text":"Python<pre><code>python scripts/setup/verify_installation.py\n</code></pre> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"ide_guides/jupyter_guide/","title":"Jupyter Setup Guide","text":"<p>Setup Jupyter for AG News Text Classification development.</p> <p>See IDE_SETUP_GUIDE.md for details.</p> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"ide_guides/pycharm_guide/","title":"PyCharm Setup Guide","text":"<p>Setup PyCharm for AG News Text Classification development.</p> <p>See IDE_SETUP_GUIDE.md for details.</p> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"ide_guides/vscode_guide/","title":"VS Code Setup Guide","text":"<p>Setup Visual Studio Code for AG News Text Classification development.</p> <p>See IDE_SETUP_GUIDE.md for details.</p> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"platform_guides/colab_guide/","title":"Google Colab Guide","text":"<p>Setup and usage guide for Google Colab platform.</p> <p>See PLATFORM_OPTIMIZATION_GUIDE.md for details.</p> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"platform_guides/kaggle_guide/","title":"Kaggle Guide","text":"<p>Setup and usage guide for Kaggle platform.</p> <p>See PLATFORM_OPTIMIZATION_GUIDE.md for details.</p> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"platform_guides/local_guide/","title":"Local Setup Guide","text":"<p>Setup and usage guide for local development.</p> <p>See PLATFORM_OPTIMIZATION_GUIDE.md for details.</p> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"user_guide/data_preparation/","title":"Data Preparation Guide","text":"<p>Prepare data for training and evaluation in AG News Text Classification.</p>"},{"location":"user_guide/data_preparation/#data-loading","title":"Data Loading","text":"Python<pre><code>from src.data.datasets.ag_news import AGNewsDataset\n\ndataset = AGNewsDataset()\ntrain_data, val_data, test_data = dataset.load_splits()\n</code></pre>"},{"location":"user_guide/data_preparation/#preprocessing","title":"Preprocessing","text":"Python<pre><code>from src.data.preprocessing.text_cleaner import TextCleaner\n\ncleaner = TextCleaner()\ncleaned_texts = cleaner.clean(texts)\n</code></pre>"},{"location":"user_guide/data_preparation/#data-augmentation","title":"Data Augmentation","text":"Python<pre><code>from src.data.augmentation.back_translation import BackTranslator\n\naugmenter = BackTranslator()\naugmented_data = augmenter.augment(train_data)\n</code></pre> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"user_guide/evaluation/","title":"Model Evaluation Guide","text":"<p>Evaluate trained models on AG News dataset.</p>"},{"location":"user_guide/evaluation/#basic-evaluation","title":"Basic Evaluation","text":"Python<pre><code>python scripts/evaluation/evaluate_all_models.py\n</code></pre>"},{"location":"user_guide/evaluation/#metrics","title":"Metrics","text":"<ul> <li>Accuracy</li> <li>F1 Score</li> <li>Precision</li> <li>Recall</li> </ul>"},{"location":"user_guide/evaluation/#overfitting-check","title":"Overfitting Check","text":"Python<pre><code>python scripts/overfitting_prevention/check_data_leakage.py\n</code></pre> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"},{"location":"user_guide/model_training/","title":"Model Training Guide","text":"<p>Train models on AG News dataset.</p>"},{"location":"user_guide/model_training/#basic-training","title":"Basic Training","text":"Python<pre><code>python scripts/training/train_single_model.py \\\n  --config configs/models/recommended/tier_1_sota/deberta_v3_xlarge_lora.yaml\n</code></pre>"},{"location":"user_guide/model_training/#advanced-training","title":"Advanced Training","text":""},{"location":"user_guide/model_training/#with-lora","title":"With LoRA","text":"Python<pre><code>python scripts/training/single_model/train_xlarge_lora.py\n</code></pre>"},{"location":"user_guide/model_training/#with-qlora","title":"With QLoRA","text":"Python<pre><code>python scripts/training/single_model/train_xxlarge_qlora.py\n</code></pre>"},{"location":"user_guide/model_training/#monitoring","title":"Monitoring","text":"Bash<pre><code>tensorboard --logdir outputs/logs/tensorboard\n</code></pre> <p>Author: V\u00f5 H\u1ea3i D\u0169ng</p>"}]}