"""
Generated Protocol Buffer code for Model Management Service
================================================================================
This file is automatically generated by the Protocol Buffer compiler.
DO NOT EDIT MANUALLY - changes will be overwritten.

Generated from: src/api/grpc/protos/model_management.proto

Defines messages for model lifecycle management, versioning, and deployment.
"""

import sys
from typing import Optional, List, Dict, Any
from datetime import datetime

_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode('latin1'))

from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import timestamp_pb2

# Symbol database
_sym_db = _symbol_database.Default()

# Import common types
from .common import types_pb2, status_pb2


class ModelInfo(_message.Message):
    """
    Model information message
    
    Attributes:
        model_id: Unique model identifier
        name: Model name
        version: Model version
        type: Model type (transformer, ensemble, etc.)
        status: Model status (training, ready, deployed, deprecated)
        metadata: Model metadata
        metrics: Model performance metrics
        created_at: Creation timestamp
        updated_at: Last update timestamp
    """
    
    class Status:
        """Model status enumeration"""
        UNKNOWN = 0
        TRAINING = 1
        VALIDATING = 2
        READY = 3
        DEPLOYED = 4
        FAILED = 5
        DEPRECATED = 6
    
    class ModelType:
        """Model type enumeration"""
        UNSPECIFIED = 0
        TRANSFORMER = 1
        ENSEMBLE = 2
        CLASSICAL = 3
        HYBRID = 4
        DISTILLED = 5
    
    __slots__ = ['model_id', 'name', 'version', 'type', 'status', 
                 'metadata', 'metrics', 'created_at', 'updated_at']
    
    def __init__(self,
                 model_id: str = "",
                 name: str = "",
                 version: str = "",
                 type: int = 0,
                 status: int = 0,
                 metadata: Optional[Dict[str, str]] = None,
                 metrics: Optional[Dict[str, float]] = None,
                 created_at: Optional[timestamp_pb2.Timestamp] = None,
                 updated_at: Optional[timestamp_pb2.Timestamp] = None):
        super(ModelInfo, self).__init__()
        self.model_id = model_id
        self.name = name
        self.version = version
        self.type = type
        self.status = status
        if metadata:
            self.metadata.update(metadata)
        if metrics:
            self.metrics.update(metrics)
        if created_at:
            self.created_at.CopyFrom(created_at)
        if updated_at:
            self.updated_at.CopyFrom(updated_at)


class GetModelRequest(_message.Message):
    """
    Request for retrieving model information
    
    Attributes:
        model_id: Model identifier
        version: Optional specific version
        include_metrics: Include performance metrics
        include_config: Include model configuration
    """
    __slots__ = ['model_id', 'version', 'include_metrics', 'include_config']
    
    def __init__(self,
                 model_id: str = "",
                 version: str = "",
                 include_metrics: bool = True,
                 include_config: bool = False):
        super(GetModelRequest, self).__init__()
        self.model_id = model_id
        self.version = version
        self.include_metrics = include_metrics
        self.include_config = include_config


class GetModelResponse(_message.Message):
    """
    Response containing model information
    
    Attributes:
        model: Model information
        config: Model configuration (if requested)
        deployment_info: Deployment information
        metadata: Response metadata
    """
    __slots__ = ['model', 'config', 'deployment_info', 'metadata']
    
    class DeploymentInfo(_message.Message):
        """Deployment information"""
        __slots__ = ['environment', 'endpoint', 'replicas', 'deployed_at']
        
        def __init__(self,
                     environment: str = "",
                     endpoint: str = "",
                     replicas: int = 0,
                     deployed_at: Optional[timestamp_pb2.Timestamp] = None):
            super(GetModelResponse.DeploymentInfo, self).__init__()
            self.environment = environment
            self.endpoint = endpoint
            self.replicas = replicas
            if deployed_at:
                self.deployed_at.CopyFrom(deployed_at)
    
    def __init__(self,
                 model: Optional[ModelInfo] = None,
                 config: Optional[Dict[str, Any]] = None,
                 deployment_info: Optional[DeploymentInfo] = None,
                 metadata: Optional[types_pb2.ResponseMetadata] = None):
        super(GetModelResponse, self).__init__()
        if model:
            self.model.CopyFrom(model)
        if config:
            self.config.update(config)
        if deployment_info:
            self.deployment_info.CopyFrom(deployment_info)
        if metadata:
            self.metadata.CopyFrom(metadata)


class ListModelsRequest(_message.Message):
    """
    Request for listing models
    
    Attributes:
        filter: Filter expression
        page_size: Number of models per page
        page_token: Pagination token
        sort_by: Sort field
        sort_order: Sort order (ASC/DESC)
        include_deprecated: Include deprecated models
    """
    __slots__ = ['filter', 'page_size', 'page_token', 'sort_by', 
                 'sort_order', 'include_deprecated']
    
    def __init__(self,
                 filter: str = "",
                 page_size: int = 10,
                 page_token: str = "",
                 sort_by: str = "created_at",
                 sort_order: str = "DESC",
                 include_deprecated: bool = False):
        super(ListModelsRequest, self).__init__()
        self.filter = filter
        self.page_size = page_size
        self.page_token = page_token
        self.sort_by = sort_by
        self.sort_order = sort_order
        self.include_deprecated = include_deprecated


class ListModelsResponse(_message.Message):
    """
    Response containing list of models
    
    Attributes:
        models: List of model information
        next_page_token: Token for next page
        total_count: Total number of models
        metadata: Response metadata
    """
    __slots__ = ['models', 'next_page_token', 'total_count', 'metadata']
    
    def __init__(self,
                 models: Optional[List[ModelInfo]] = None,
                 next_page_token: str = "",
                 total_count: int = 0,
                 metadata: Optional[types_pb2.ResponseMetadata] = None):
        super(ListModelsResponse, self).__init__()
        if models:
            self.models.extend(models)
        self.next_page_token = next_page_token
        self.total_count = total_count
        if metadata:
            self.metadata.CopyFrom(metadata)


class DeployModelRequest(_message.Message):
    """
    Request for model deployment
    
    Attributes:
        model_id: Model to deploy
        environment: Target environment (dev, staging, prod)
        replicas: Number of replicas
        resources: Resource requirements
        auto_scaling: Auto-scaling configuration
        canary_config: Canary deployment configuration
    """
    
    class Resources(_message.Message):
        """Resource requirements"""
        __slots__ = ['cpu', 'memory', 'gpu', 'gpu_type']
        
        def __init__(self,
                     cpu: str = "2",
                     memory: str = "4Gi",
                     gpu: int = 0,
                     gpu_type: str = ""):
            super(DeployModelRequest.Resources, self).__init__()
            self.cpu = cpu
            self.memory = memory
            self.gpu = gpu
            self.gpu_type = gpu_type
    
    class AutoScaling(_message.Message):
        """Auto-scaling configuration"""
        __slots__ = ['min_replicas', 'max_replicas', 'target_cpu_utilization']
        
        def __init__(self,
                     min_replicas: int = 1,
                     max_replicas: int = 10,
                     target_cpu_utilization: int = 70):
            super(DeployModelRequest.AutoScaling, self).__init__()
            self.min_replicas = min_replicas
            self.max_replicas = max_replicas
            self.target_cpu_utilization = target_cpu_utilization
    
    class CanaryConfig(_message.Message):
        """Canary deployment configuration"""
        __slots__ = ['enabled', 'percentage', 'duration_minutes', 'metrics_threshold']
        
        def __init__(self,
                     enabled: bool = False,
                     percentage: int = 10,
                     duration_minutes: int = 30,
                     metrics_threshold: Optional[Dict[str, float]] = None):
            super(DeployModelRequest.CanaryConfig, self).__init__()
            self.enabled = enabled
            self.percentage = percentage
            self.duration_minutes = duration_minutes
            if metrics_threshold:
                self.metrics_threshold.update(metrics_threshold)
    
    __slots__ = ['model_id', 'environment', 'replicas', 'resources', 
                 'auto_scaling', 'canary_config']
    
    def __init__(self,
                 model_id: str = "",
                 environment: str = "staging",
                 replicas: int = 1,
                 resources: Optional[Resources] = None,
                 auto_scaling: Optional[AutoScaling] = None,
                 canary_config: Optional[CanaryConfig] = None):
        super(DeployModelRequest, self).__init__()
        self.model_id = model_id
        self.environment = environment
        self.replicas = replicas
        if resources:
            self.resources.CopyFrom(resources)
        if auto_scaling:
            self.auto_scaling.CopyFrom(auto_scaling)
        if canary_config:
            self.canary_config.CopyFrom(canary_config)


class DeployModelResponse(_message.Message):
    """
    Response for model deployment
    
    Attributes:
        deployment_id: Unique deployment identifier
        status: Deployment status
        endpoint: Service endpoint
        health_check_url: Health check URL
        metadata: Response metadata
    """
    __slots__ = ['deployment_id', 'status', 'endpoint', 'health_check_url', 'metadata']
    
    def __init__(self,
                 deployment_id: str = "",
                 status: str = "",
                 endpoint: str = "",
                 health_check_url: str = "",
                 metadata: Optional[types_pb2.ResponseMetadata] = None):
        super(DeployModelResponse, self).__init__()
        self.deployment_id = deployment_id
        self.status = status
        self.endpoint = endpoint
        self.health_check_url = health_check_url
        if metadata:
            self.metadata.CopyFrom(metadata)


class UpdateModelRequest(_message.Message):
    """
    Request for updating model information
    
    Attributes:
        model_id: Model to update
        update_mask: Fields to update
        name: Updated name
        metadata: Updated metadata
        status: Updated status
    """
    __slots__ = ['model_id', 'update_mask', 'name', 'metadata', 'status']
    
    def __init__(self,
                 model_id: str = "",
                 update_mask: Optional[types_pb2.FieldMask] = None,
                 name: str = "",
                 metadata: Optional[Dict[str, str]] = None,
                 status: int = 0):
        super(UpdateModelRequest, self).__init__()
        self.model_id = model_id
        if update_mask:
            self.update_mask.CopyFrom(update_mask)
        self.name = name
        if metadata:
            self.metadata.update(metadata)
        self.status = status


class UpdateModelResponse(_message.Message):
    """
    Response for model update
    
    Attributes:
        model: Updated model information
        metadata: Response metadata
    """
    __slots__ = ['model', 'metadata']
    
    def __init__(self,
                 model: Optional[ModelInfo] = None,
                 metadata: Optional[types_pb2.ResponseMetadata] = None):
        super(UpdateModelResponse, self).__init__()
        if model:
            self.model.CopyFrom(model)
        if metadata:
            self.metadata.CopyFrom(metadata)


class DeleteModelRequest(_message.Message):
    """
    Request for deleting a model
    
    Attributes:
        model_id: Model to delete
        force: Force deletion even if deployed
    """
    __slots__ = ['model_id', 'force']
    
    def __init__(self, model_id: str = "", force: bool = False):
        super(DeleteModelRequest, self).__init__()
        self.model_id = model_id
        self.force = force


class DeleteModelResponse(_message.Message):
    """
    Response for model deletion
    
    Attributes:
        success: Whether deletion was successful
        message: Status message
        metadata: Response metadata
    """
    __slots__ = ['success', 'message', 'metadata']
    
    def __init__(self,
                 success: bool = False,
                 message: str = "",
                 metadata: Optional[types_pb2.ResponseMetadata] = None):
        super(DeleteModelResponse, self).__init__()
        self.success = success
        self.message = message
        if metadata:
            self.metadata.CopyFrom(metadata)


# Register message types
_sym_db.RegisterMessage(ModelInfo)
_sym_db.RegisterMessage(GetModelRequest)
_sym_db.RegisterMessage(GetModelResponse)
_sym_db.RegisterMessage(ListModelsRequest)
_sym_db.RegisterMessage(ListModelsResponse)
_sym_db.RegisterMessage(DeployModelRequest)
_sym_db.RegisterMessage(UpdateModelRequest)
_sym_db.RegisterMessage(UpdateModelResponse)
_sym_db.RegisterMessage(DeleteModelRequest)
_sym_db.RegisterMessage(DeleteModelResponse)
