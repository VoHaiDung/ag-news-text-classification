"""
Generated Protocol Buffer code for Classification Service
================================================================================
This file is automatically generated by the Protocol Buffer compiler.
DO NOT EDIT MANUALLY - changes will be overwritten.

Generated from: src/api/grpc/protos/classification.proto
"""

import sys
_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import timestamp_pb2

# Symbol database initialization
_sym_db = _symbol_database.Default()

# Import common types
from . import common

# Descriptor pool
DESCRIPTOR = _descriptor.FileDescriptor(
    name='classification.proto',
    package='agnews.classification.v1',
    syntax='proto3',
    serialized_options=None,
    serialized_pb=_b('\n\x14classification.proto\x12\x18agnews.classification.v1\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x13common/types.proto\x1a\x14common/status.proto')
)

# Classification Request Message
class ClassificationRequest(_message.Message):
    """
    Request message for text classification
    
    Attributes:
        text: Input text to classify
        model_id: Optional model identifier
        options: Classification options
    """
    __slots__ = ['text', 'model_id', 'options', 'metadata']
    
    def __init__(self, text=None, model_id=None, options=None, metadata=None):
        super(ClassificationRequest, self).__init__()
        if text is not None:
            self.text = text
        if model_id is not None:
            self.model_id = model_id
        if options is not None:
            self.options = options
        if metadata is not None:
            self.metadata = metadata

# Classification Response Message
class ClassificationResponse(_message.Message):
    """
    Response message for text classification
    
    Attributes:
        predictions: List of predicted classes with scores
        model_id: Model used for prediction
        processing_time_ms: Processing time in milliseconds
        metadata: Response metadata
    """
    __slots__ = ['predictions', 'model_id', 'processing_time_ms', 'metadata']
    
    class Prediction(_message.Message):
        """Single prediction with confidence score"""
        __slots__ = ['label', 'score', 'class_id']
        
        def __init__(self, label=None, score=None, class_id=None):
            super(ClassificationResponse.Prediction, self).__init__()
            if label is not None:
                self.label = label
            if score is not None:
                self.score = score
            if class_id is not None:
                self.class_id = class_id
    
    def __init__(self, predictions=None, model_id=None, processing_time_ms=None, metadata=None):
        super(ClassificationResponse, self).__init__()
        if predictions is not None:
            self.predictions.extend(predictions)
        if model_id is not None:
            self.model_id = model_id
        if processing_time_ms is not None:
            self.processing_time_ms = processing_time_ms
        if metadata is not None:
            self.metadata = metadata

# Batch Classification Request
class BatchClassificationRequest(_message.Message):
    """
    Request for batch text classification
    
    Attributes:
        texts: List of texts to classify
        model_id: Optional model identifier
        options: Batch processing options
    """
    __slots__ = ['texts', 'model_id', 'options']
    
    def __init__(self, texts=None, model_id=None, options=None):
        super(BatchClassificationRequest, self).__init__()
        if texts is not None:
            self.texts.extend(texts)
        if model_id is not None:
            self.model_id = model_id
        if options is not None:
            self.options = options

# Batch Classification Response
class BatchClassificationResponse(_message.Message):
    """
    Response for batch text classification
    
    Attributes:
        results: List of classification results
        model_id: Model used for predictions
        total_processing_time_ms: Total processing time
        failed_indices: Indices of failed classifications
    """
    __slots__ = ['results', 'model_id', 'total_processing_time_ms', 'failed_indices']
    
    def __init__(self, results=None, model_id=None, total_processing_time_ms=None, failed_indices=None):
        super(BatchClassificationResponse, self).__init__()
        if results is not None:
            self.results.extend(results)
        if model_id is not None:
            self.model_id = model_id
        if total_processing_time_ms is not None:
            self.total_processing_time_ms = total_processing_time_ms
        if failed_indices is not None:
            self.failed_indices.extend(failed_indices)

# Stream Classification Request
class StreamClassificationRequest(_message.Message):
    """Request for streaming classification"""
    __slots__ = ['text', 'model_id', 'stream_id']
    
    def __init__(self, text=None, model_id=None, stream_id=None):
        super(StreamClassificationRequest, self).__init__()
        if text is not None:
            self.text = text
        if model_id is not None:
            self.model_id = model_id
        if stream_id is not None:
            self.stream_id = stream_id

# Register messages with symbol database
_sym_db.RegisterFileDescriptor(DESCRIPTOR)
