{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Land Classification â€” CNN-Transformer Integration Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Define the dataset directory, dataloader, and model hyperparameters. The dataloader and model hyperparameters should be the same as those used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Define dataset directory, dataloader, and model hyperparameters\n",
    "\n",
    "# ========== Dataset Directory ==========\n",
    "dataset_path = './images_dataSAT/'\n",
    "\n",
    "# ========== Dataloader Hyperparameters ==========\n",
    "IMG_SIZE = 64\n",
    "IMG_SIZE_KERAS = (64, 64)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# ========== Model Hyperparameters (same as training) ==========\n",
    "# Baseline model\n",
    "MODEL_EMBED_DIM = 64\n",
    "MODEL_NUM_HEADS = 4\n",
    "MODEL_DEPTH = 4\n",
    "MODEL_MLP_DIM = 128\n",
    "MODEL_DROPOUT = 0.1\n",
    "\n",
    "# Model test (larger)\n",
    "MODEL_TEST_EMBED_DIM = 768\n",
    "MODEL_TEST_NUM_HEADS = 12\n",
    "MODEL_TEST_DEPTH = 12\n",
    "MODEL_TEST_MLP_DIM = 3072\n",
    "MODEL_TEST_DROPOUT = 0.1\n",
    "\n",
    "print(\"Configuration Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print()\n",
    "print(\"Baseline Model Hyperparameters:\")\n",
    "print(f\"  embed_dim={MODEL_EMBED_DIM}, num_heads={MODEL_NUM_HEADS}, depth={MODEL_DEPTH}, mlp_dim={MODEL_MLP_DIM}\")\n",
    "print()\n",
    "print(\"Model Test Hyperparameters:\")\n",
    "print(f\"  embed_dim={MODEL_TEST_EMBED_DIM}, num_heads={MODEL_TEST_NUM_HEADS}, depth={MODEL_TEST_DEPTH}, mlp_dim={MODEL_TEST_MLP_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define print_metrics function\n",
    "def print_metrics(y_true, y_pred, model_name='Model'):\n",
    "    \"\"\"\n",
    "    Print comprehensive performance metrics for a given model.\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{'='*55}\")\n",
    "    print(f\" Performance Metrics: {model_name}\")\n",
    "    print(f\"{'='*55}\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"\\n  Confusion Matrix:\")\n",
    "    print(f\"                    Predicted\")\n",
    "    print(f\"                    Neg(0)  Pos(1)\")\n",
    "    print(f\"  Actual Neg(0):   TN={cm[0][0]:5d}  FP={cm[0][1]:5d}\")\n",
    "    print(f\"  Actual Pos(1):   FN={cm[1][0]:5d}  TP={cm[1][1]:5d}\")\n",
    "    print(f\"\\n  Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred,\n",
    "                                target_names=['Non-Agricultural', 'Agricultural']))\n",
    "    \n",
    "    return {'accuracy': acc, 'precision': prec, 'recall': rec, \n",
    "            'f1': f1, 'confusion_matrix': cm}\n",
    "\n",
    "print(\"print_metrics function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== KERAS: Load model and prepare data ==========\n",
    "# Keras validation generator\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "keras_val_generator = val_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=IMG_SIZE_KERAS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Keras validation samples: {keras_val_generator.samples}\")\n",
    "print(f\"Keras class indices: {keras_val_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Keras hybrid model\n",
    "try:\n",
    "    keras_vit_model = load_model('best_hybrid_model.keras')\n",
    "    print(\"Keras CNN-ViT Hybrid model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Keras model: {e}\")\n",
    "    print(\"Attempting to load alternative model...\")\n",
    "    try:\n",
    "        keras_vit_model = load_model('best_model.keras')\n",
    "        print(\"Loaded fallback Keras model.\")\n",
    "    except:\n",
    "        print(\"No Keras model found. Please ensure the model file exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Keras predictions\n",
    "keras_val_generator.reset()\n",
    "keras_preds_prob = keras_vit_model.predict(keras_val_generator, verbose=1)\n",
    "keras_preds = (keras_preds_prob > 0.5).astype(int).flatten()\n",
    "keras_true_labels = keras_val_generator.classes\n",
    "\n",
    "print(f\"Keras predictions: {len(keras_preds)}\")\n",
    "print(f\"Keras true labels: {len(keras_true_labels)}\")\n",
    "print(f\"First 10 predictions: {keras_preds[:10]}\")\n",
    "print(f\"First 10 true labels:  {keras_true_labels[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Instantiate the PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PyTorch Model Definitions (same as training)\n",
    "# ============================================================\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, mlp_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dim, embed_dim), nn.Dropout(dropout)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        x_norm = self.norm1(x)\n",
    "        attn_out, _ = self.attn(x_norm, x_norm, x_norm)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x_norm = self.norm2(x)\n",
    "        x = x + self.mlp(x_norm)\n",
    "        return x\n",
    "\n",
    "class CNNViTHybrid(nn.Module):\n",
    "    def __init__(self, num_classes=2, embed_dim=64, num_heads=4,\n",
    "                 depth=4, mlp_dim=128, dropout=0.1):\n",
    "        super(CNNViTHybrid, self).__init__()\n",
    "        self.cnn = CNNFeatureExtractor()\n",
    "        self.seq_length = 4 * 4\n",
    "        self.cnn_feature_dim = 256\n",
    "        self.projection = nn.Linear(self.cnn_feature_dim, embed_dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.seq_length, embed_dim))\n",
    "        self.pos_dropout = nn.Dropout(dropout)\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlock(embed_dim, num_heads, mlp_dim, dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 256), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.projection(x)\n",
    "        x = x + self.pos_embedding\n",
    "        x = self.pos_dropout(x)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "        x = self.norm(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "print(\"PyTorch model classes defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Instantiate the PyTorch model\n",
    "\n",
    "# Instantiate the PyTorch CNN-ViT Hybrid model with SAME hyperparameters as training\n",
    "pytorch_vit_model = CNNViTHybrid(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    embed_dim=MODEL_EMBED_DIM,\n",
    "    num_heads=MODEL_NUM_HEADS,\n",
    "    depth=MODEL_DEPTH,\n",
    "    mlp_dim=MODEL_MLP_DIM,\n",
    "    dropout=MODEL_DROPOUT\n",
    ").to(device)\n",
    "\n",
    "# Load trained weights\n",
    "try:\n",
    "    pytorch_vit_model.load_state_dict(\n",
    "        torch.load('best_model.pth', map_location=device)\n",
    "    )\n",
    "    print(\"PyTorch CNN-ViT model weights loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not load weights: {e}\")\n",
    "    print(\"Using randomly initialized model.\")\n",
    "\n",
    "pytorch_vit_model.eval()\n",
    "\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"  embed_dim={MODEL_EMBED_DIM}, num_heads={MODEL_NUM_HEADS}, \"\n",
    "      f\"depth={MODEL_DEPTH}, mlp_dim={MODEL_MLP_DIM}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in pytorch_vit_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare PyTorch validation data\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=val_transform)\n",
    "total_size = len(full_dataset)\n",
    "val_size = int(0.2 * total_size)\n",
    "train_size = total_size - val_size\n",
    "\n",
    "_, val_subset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "pytorch_val_loader = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"PyTorch validation samples: {len(val_subset)}\")\n",
    "print(f\"PyTorch validation batches: {len(pytorch_val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PyTorch predictions\n",
    "pytorch_all_preds = []\n",
    "pytorch_all_labels = []\n",
    "\n",
    "pytorch_vit_model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(pytorch_val_loader, desc='PyTorch Evaluation'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = pytorch_vit_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pytorch_all_preds.extend(predicted.cpu().numpy())\n",
    "        pytorch_all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "pytorch_all_preds = np.array(pytorch_all_preds)\n",
    "pytorch_all_labels = np.array(pytorch_all_labels)\n",
    "\n",
    "print(f\"\\nPyTorch predictions: {len(pytorch_all_preds)}\")\n",
    "print(f\"PyTorch true labels: {len(pytorch_all_labels)}\")\n",
    "print(f\"First 10 predictions: {pytorch_all_preds[:10]}\")\n",
    "print(f\"First 10 true labels:  {pytorch_all_labels[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Print the evaluation metrics using the print_metrics function for the Keras ViT model named Keras CNN-ViT Hybrid Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Print Keras ViT model metrics\n",
    "keras_metrics = print_metrics(\n",
    "    keras_true_labels, \n",
    "    keras_preds, \n",
    "    model_name='Keras CNN-Vit Hybrid Model'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Print the evaluation metrics using the print_metrics function for the PyTorch ViT model named PyTorch CNN-ViT Hybrid Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Print PyTorch ViT model metrics\n",
    "pytorch_metrics = print_metrics(\n",
    "    pytorch_all_labels, \n",
    "    pytorch_all_preds, \n",
    "    model_name='PyTorch CNN-Vit Hybrid Model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Final Comparative Visualization\n",
    "# ============================================================\n",
    "\n",
    "# Bar chart comparison\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "keras_vals = [keras_metrics['accuracy'], keras_metrics['precision'],\n",
    "              keras_metrics['recall'], keras_metrics['f1']]\n",
    "pytorch_vals = [pytorch_metrics['accuracy'], pytorch_metrics['precision'],\n",
    "                pytorch_metrics['recall'], pytorch_metrics['f1']]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Bar chart comparison\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "bars1 = axes[0].bar(x - width/2, keras_vals, width, label='Keras CNN-ViT', color='steelblue', edgecolor='black')\n",
    "bars2 = axes[0].bar(x + width/2, pytorch_vals, width, label='PyTorch CNN-ViT', color='coral', edgecolor='black')\n",
    "axes[0].set_ylabel('Score', fontsize=12)\n",
    "axes[0].set_title('Keras vs PyTorch CNN-ViT Hybrid Models', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics_names, fontsize=11)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].set_ylim(0, 1.15)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar in bars1:\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                 f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=9)\n",
    "for bar in bars2:\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                 f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 2: Confusion matrices side by side\n",
    "cm_keras = keras_metrics['confusion_matrix']\n",
    "cm_pytorch = pytorch_metrics['confusion_matrix']\n",
    "\n",
    "combined_text = f\"Keras CM:\\n{cm_keras}\\n\\nPyTorch CM:\\n{cm_pytorch}\"\n",
    "\n",
    "# Heatmap for Keras confusion matrix\n",
    "im = axes[1].imshow(cm_keras, interpolation='nearest', cmap='Blues', alpha=0.7)\n",
    "axes[1].set_title('Keras CNN-ViT Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_yticks([0, 1])\n",
    "axes[1].set_xticklabels(['Non-Agri', 'Agri'])\n",
    "axes[1].set_yticklabels(['Non-Agri', 'Agri'])\n",
    "\n",
    "# Add text to heatmap\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[1].text(j, i, str(cm_keras[i, j]),\n",
    "                     ha='center', va='center', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.suptitle('CNN-Transformer Integration: Final Evaluation', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Final Summary Table\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  FINAL COMPARATIVE SUMMARY\")\n",
    "print(\"  Keras CNN-ViT vs PyTorch CNN-ViT Hybrid Models\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"{'Metric':<20} {'Keras CNN-ViT':>18} {'PyTorch CNN-ViT':>18}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Accuracy':<20} {keras_metrics['accuracy']:>18.4f} {pytorch_metrics['accuracy']:>18.4f}\")\n",
    "print(f\"{'Precision':<20} {keras_metrics['precision']:>18.4f} {pytorch_metrics['precision']:>18.4f}\")\n",
    "print(f\"{'Recall':<20} {keras_metrics['recall']:>18.4f} {pytorch_metrics['recall']:>18.4f}\")\n",
    "print(f\"{'F1 Score':<20} {keras_metrics['f1']:>18.4f} {pytorch_metrics['f1']:>18.4f}\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Determine winner\n",
    "if keras_metrics['f1'] > pytorch_metrics['f1']:\n",
    "    print(f\"\\n>> Keras CNN-ViT Hybrid Model performs better (F1: {keras_metrics['f1']:.4f})\")\n",
    "elif pytorch_metrics['f1'] > keras_metrics['f1']:\n",
    "    print(f\"\\n>> PyTorch CNN-ViT Hybrid Model performs better (F1: {pytorch_metrics['f1']:.4f})\")\n",
    "else:\n",
    "    print(f\"\\n>> Both models have equal F1 scores: {keras_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## All 4 tasks completed successfully."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
