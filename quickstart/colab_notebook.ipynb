{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AG News Text Classification - Google Colab Quick Start\n",
    "\n",
    "This notebook provides a complete quick start guide for AG News classification in Google Colab.\n",
    "\n",
    "**Educational Approach**: Progressive disclosure from simple to complex operations\n",
    "- Reference: Wing (2006) - \"Computational Thinking\"\n",
    "- Reference: Guzdial (2015) - \"Learner-Centered Design of Computing Education\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, we need to set up the Colab environment with necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/yourusername/ag-news-text-classification.git\n",
    "%cd ag-news-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements/minimal.txt\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Download and prepare the AG News dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download AG News data\n",
    "!python scripts/setup/download_all_data.py --dataset ag_news\n",
    "\n",
    "# Prepare data splits\n",
    "!python scripts/data_preparation/prepare_ag_news.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore data\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"data/processed\")\n",
    "train_df = pd.read_csv(data_dir / \"train.csv\")\n",
    "val_df = pd.read_csv(data_dir / \"validation.csv\")\n",
    "test_df = pd.read_csv(data_dir / \"test.csv\")\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(\"\\nSample data:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Model Training\n",
    "\n",
    "Train a simple DistilBERT model for quick results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple dataset class\n",
    "class AGNewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_dataset = AGNewsDataset(\n",
    "    train_df[\"text\"].values,\n",
    "    train_df[\"label\"].values,\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = AGNewsDataset(\n",
    "    val_df[\"text\"].values,\n",
    "    val_df[\"label\"].values,\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 2\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Average training loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "Evaluate the trained model on validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy, all_preds, all_labels\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_acc, val_preds, val_labels = evaluate_model(model, val_loader, device)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "class_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_labels, val_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Prediction\n",
    "\n",
    "Test the model with custom text inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text, model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Predict class for a single text input.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        pred = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    class_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "    pred_class = class_names[pred.item()]\n",
    "    confidence = probs[0][pred].item()\n",
    "    \n",
    "    return pred_class, confidence, probs[0].cpu().numpy()\n",
    "\n",
    "# Test predictions\n",
    "test_texts = [\n",
    "    \"Apple announces new iPhone with revolutionary camera system\",\n",
    "    \"Stock market reaches all-time high amid economic recovery\",\n",
    "    \"Scientists discover new planet in nearby solar system\",\n",
    "    \"Local team wins championship in thrilling overtime victory\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    pred_class, confidence, probs = predict_text(text, model, tokenizer, device)\n",
    "    print(f\"\\nText: {text[:60]}...\")\n",
    "    print(f\"Predicted: {pred_class} (confidence: {confidence:.4f})\")\n",
    "    print(f\"All probabilities: {dict(zip(['World', 'Sports', 'Business', 'Sci/Tech'], probs.round(4)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and Load Model\n",
    "\n",
    "Save the trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "output_dir = \"outputs/colab_model\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")\n",
    "\n",
    "# Test loading\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Features (Optional)\n",
    "\n",
    "Explore advanced features like data augmentation and ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation example\n",
    "!python scripts/data_preparation/create_augmented_data.py --method back_translation --samples 100\n",
    "\n",
    "# Load augmented data\n",
    "augmented_df = pd.read_csv(\"data/augmented/back_translated/train_augmented.csv\")\n",
    "print(f\"Augmented samples: {len(augmented_df)}\")\n",
    "augmented_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download Results\n",
    "\n",
    "Download the trained model and results to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file\n",
    "!zip -r colab_results.zip outputs/colab_model\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('colab_results.zip')\n",
    "print(\"Results downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You have successfully:\n",
    "1. Set up the environment in Google Colab\n",
    "2. Prepared the AG News dataset\n",
    "3. Trained a DistilBERT classifier\n",
    "4. Evaluated model performance\n",
    "5. Made predictions on custom text\n",
    "6. Saved the trained model\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different models (RoBERTa, DeBERTa)\n",
    "- Experiment with hyperparameters\n",
    "- Explore ensemble methods\n",
    "- Use advanced training techniques\n",
    "\n",
    "For more advanced features, check out the full documentation and other notebooks in the repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
