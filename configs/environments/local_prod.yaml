# AG News Text Classification - Local Production Environment Configuration
#
# This configuration file defines comprehensive settings for the local production
# environment of the AG News Text Classification project. The configuration is
# meticulously optimized for production-grade performance, maximum accuracy,
# operational reliability, inference efficiency, and professional deployment on
# local infrastructure without any cloud dependencies or recurring costs.
#
# Local Production Environment Characteristics:
#   Purpose and Scope:
#     - Production-ready model training with full dataset utilization
#     - High-performance inference serving via REST API
#     - Professional monitoring and operational excellence
#     - Zero cloud costs with complete local deployment
#     - Enterprise-grade reliability and stability
#     - Academic rigor with strict overfitting prevention
#
#   Performance Characteristics:
#     - Maximum accuracy optimization with full training epochs
#     - Mixed precision training for GPU acceleration
#     - Model quantization for inference optimization
#     - Multi-GPU support for distributed training
#     - Production batch sizes for optimal throughput
#     - Efficient memory utilization and caching
#
#   Production Features:
#     - REST API with authentication and rate limiting
#     - Comprehensive monitoring via TensorBoard and MLflow
#     - Automated backup and disaster recovery
#     - Health checks and readiness probes
#     - Structured logging with audit trails
#     - Security hardening and access control
#     - Performance metrics tracking
#     - Model versioning and checksums
#
#   Resource Allocation:
#     - Local GPU cluster utilization
#     - Multi-GPU distributed training support
#     - Optimized CPU and memory management
#     - Persistent local storage for all artifacts
#     - No session timeouts or quota constraints
#     - Unlimited training duration
#
#   Operational Excellence:
#     - SLA target: 99.9% uptime
#     - Automated health monitoring
#     - Graceful shutdown and recovery
#     - Circuit breaker pattern for resilience
#     - Comprehensive error handling
#     - Professional logging and auditing
#     - Version control integration
#
# Project Structure Integration:
#   This configuration integrates with the following project components:
#
#   Core Modules:
#     - src/core/health/health_checker.py: Production health validation
#     - src/deployment/platform_detector.py: Local platform detection
#     - src/deployment/cache_manager.py: Production cache management
#     - src/deployment/checkpoint_manager.py: Reliable checkpointing
#     - src/utils/logging_config.py: Production-grade logging
#
#   Configuration System:
#     - configs/config_loader.py: Configuration loading with validation
#     - configs/config_validator.py: Strict schema validation
#     - configs/smart_defaults.py: Production-aware defaults
#     - configs/compatibility_matrix.yaml: Version verification
#
#   Training Infrastructure:
#     - src/training/trainers/auto_trainer.py: Production training
#     - src/training/callbacks/: Comprehensive callback system
#     - src/training/strategies/: Advanced training strategies
#     - src/evaluation/: Rigorous evaluation framework
#
#   API Infrastructure:
#     - src/api/rest/app.py: Production FastAPI application
#     - src/api/base/auth.py: Authentication middleware
#     - src/api/base/rate_limiter.py: Rate limiting
#     - src/api/rest/routers/: Complete API endpoints
#
#   Monitoring Systems:
#     - monitoring/local/: Complete monitoring stack
#     - monitoring/dashboards/: Production dashboards
#     - src/services/monitoring/tensorboard_service.py: TensorBoard
#     - src/services/monitoring/mlflow_service.py: MLflow tracking
#     - src/services/monitoring/local_metrics_service.py: Metrics
#
#   Overfitting Prevention:
#     - src/core/overfitting_prevention/: Full prevention system
#     - src/core/overfitting_prevention/monitors/: Real-time monitoring
#     - src/core/overfitting_prevention/constraints/: Strict enforcement
#     - configs/overfitting_prevention/: Prevention configurations
#
#   Security:
#     - security/local_auth/: Authentication system
#     - security/data_privacy/: Privacy protection
#     - security/model_security/: Model integrity
#
#   Deployment:
#     - deployment/docker/Dockerfile.local: Production Docker image
#     - deployment/docker/docker-compose.local.yml: Orchestration
#     - deployment/local/: Local deployment scripts
#
#   Backup and Recovery:
#     - backup/strategies/: Backup strategies
#     - backup/scripts/backup_local.sh: Automated backups
#     - backup/recovery/: Recovery procedures
#
# Usage Patterns:
#
#   Production Training:
#     export ENVIRONMENT=local_prod
#     python train.py
#
#   CLI-Based Training:
#     python src/cli.py train --env local_prod --model deberta-large-lora
#
#   Production API Serving:
#     python -m uvicorn src.api.rest.app:app --config configs/environments/local_prod.yaml
#
#   Docker Deployment:
#     docker-compose -f deployment/docker/docker-compose.local.yml up -d
#
#   Health Check:
#     curl http://localhost:8000/health
#
# Design Principles and Production Strategies:
#
#   1. Production Quality First:
#      Strategy: Maximum reliability and accuracy
#      Implementation:
#        - Full dataset training without sampling
#        - Extended training epochs (10 epochs vs 3 in dev)
#        - Strict validation with fail-fast on errors
#        - Comprehensive error handling and recovery
#        - Production-grade logging and monitoring
#      Rationale: Production systems require maximum quality; no compromises
#                 on accuracy or reliability
#
#   2. Security Hardening:
#      Strategy: Defense in depth with multiple security layers
#      Implementation:
#        - API authentication with token-based auth
#        - Rate limiting to prevent abuse (60 req/min)
#        - Input validation and sanitization
#        - CORS with strict origin control
#        - Model checksum verification
#        - Audit logging for all critical operations
#      Rationale: Production APIs are internet-facing; security is paramount
#                 to prevent unauthorized access and abuse
#
#   3. Operational Excellence:
#      Strategy: Comprehensive monitoring and observability
#      Implementation:
#        - TensorBoard for training visualization
#        - MLflow for experiment tracking and model registry
#        - Structured JSON logging for log aggregation
#        - Health checks and readiness probes
#        - Performance metrics tracking (latency, throughput)
#        - System resource monitoring (CPU, GPU, memory)
#      Rationale: Production systems require continuous monitoring; early
#                 detection prevents outages and degradation
#
#   4. Performance Optimization:
#      Strategy: Maximize throughput and minimize latency
#      Implementation:
#        - Mixed precision training (bfloat16 on Ampere GPUs)
#        - Gradient accumulation for larger effective batch size
#        - Multi-worker data loading (4 workers)
#        - Model quantization for inference (dynamic int8)
#        - Prediction caching for common queries
#        - TF32 enabled on compatible hardware
#      Rationale: Production inference requires low latency and high throughput;
#                 optimizations directly impact user experience
#
#   5. Strict Overfitting Prevention:
#      Strategy: Academic rigor with competition-grade validation
#      Implementation:
#        - Test set protection with single access limit
#        - K-fold cross-validation (5 folds)
#        - Train-validation gap threshold: 0.02 (very strict)
#        - Continuous overfitting monitoring
#        - Fail on overfitting detection
#        - Label smoothing (0.1) for regularization
#      Rationale: Production models must generalize; overfitting undermines
#                 real-world performance and scientific validity
#
#   6. Zero Cloud Costs:
#      Strategy: Complete local deployment without cloud dependencies
#      Implementation:
#        - All data cached locally
#        - Models stored on local infrastructure
#        - No API keys or cloud authentication
#        - Local monitoring stack (TensorBoard, MLflow)
#        - Persistent local storage for all artifacts
#        - No network egress charges
#      Rationale: Cloud costs accumulate rapidly in production; local deployment
#                 eliminates recurring expenses
#
#   7. Disaster Recovery:
#      Strategy: Automated backups with tested recovery procedures
#      Implementation:
#        - Daily automated backups at 2 AM
#        - 30-day retention policy
#        - Compressed backup archives (tar.gz)
#        - Backup verification on creation
#        - Checkpoint-based training recovery
#        - Rollback to previous model version
#      Rationale: Production systems must be resilient to failures; backups
#                 ensure business continuity
#
# Production Best Practices and References:
#
#   Production Machine Learning Systems:
#     Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D.,
#     Chaudhary, V., Young, M., Crespo, J. F., & Dennison, D. (2015). Hidden
#     technical debt in machine learning systems. Advances in Neural Information
#     Processing Systems, 28, 2503-2511.
#     - Technical debt unique to ML systems
#     - Importance of monitoring and testing
#     - Configuration management challenges
#
#     Polyzotis, N., Roy, S., Whang, S. E., & Zinkevich, M. (2018). Data
#     lifecycle challenges in production machine learning: A survey. ACM
#     SIGMOD Record, 47(2), 17-28.
#     https://doi.org/10.1145/3299887.3299891
#     - Data management in production ML
#     - Data validation and monitoring
#     - Schema evolution and versioning
#
#     Baylor, D., Breck, E., Cheng, H. T., Fiedel, N., Foo, C. Y., Haque, Z.,
#     Haykal, S., Ispir, M., Jain, V., Koc, L., Koo, C. Y., Lew, L., Mewald,
#     C., Modi, A. N., Polyzotis, N., Ramesh, S., Roy, S., Whang, S. E.,
#     Wicke, M., Wilkiewicz, J., Zhang, X., & Zinkevich, M. (2017). TFX: A
#     TensorFlow-based production-scale machine learning platform. Proceedings
#     of the 23rd ACM SIGKDD International Conference on Knowledge Discovery
#     and Data Mining, 1387-1395.
#     https://doi.org/10.1145/3097983.3098021
#     - End-to-end ML platform architecture
#     - Data validation and transformation
#     - Model analysis and serving
#
#   MLOps and ML Engineering:
#     Makinen, S., Skogstrom, H., Laaksonen, E., & Mikkonen, T. (2021). Who
#     needs MLOps: What data scientists seek to accomplish and how can MLOps
#     help? arXiv preprint arXiv:2103.08942.
#     https://arxiv.org/abs/2103.08942
#     - MLOps practices and tools
#     - Data scientist needs and pain points
#     - MLOps maturity model
#
#     Kreuzberger, D., Kuchler, N., & Denker, S. (2023). Machine Learning
#     Operations (MLOps): Overview, definition, and architecture. IEEE Access,
#     11, 31866-31879.
#     https://doi.org/10.1109/ACCESS.2023.3262138
#     - Comprehensive MLOps overview
#     - Architecture patterns and principles
#     - Tool landscape and selection
#
#   Model Serving and Deployment:
#     Crankshaw, D., Wang, X., Zhou, G., Franklin, M. J., Gonzalez, J. E., &
#     Stoica, I. (2017). Clipper: A low-latency online prediction serving
#     system. Proceedings of the 14th USENIX Symposium on Networked Systems
#     Design and Implementation (NSDI), 613-627.
#     - Low-latency prediction serving
#     - Model selection and caching
#     - Adaptive batching strategies
#
#     Olston, C., Fiedel, N., Gorovoy, K., Harmsen, J., Lao, L., Li, F.,
#     Rajashekhar, V., Ramesh, S., & Soyke, J. (2017). TensorFlow-Serving:
#     Flexible, high-performance ML serving. NIPS Workshop on ML Systems.
#     - Production model serving architecture
#     - Versioning and A/B testing
#     - Performance optimization
#
#   Site Reliability Engineering:
#     Beyer, B., Jones, C., Petoff, J., & Murphy, N. R. (2016). Site
#     Reliability Engineering: How Google Runs Production Systems. O'Reilly
#     Media.
#     - SLA and error budgets
#     - Monitoring and alerting
#     - Incident response and postmortems
#
#     Kleppmann, M. (2017). Designing Data-Intensive Applications: The Big
#     Ideas Behind Reliable, Scalable, and Maintainable Systems. O'Reilly Media.
#     - Data system architecture patterns
#     - Reliability and consistency
#     - Distributed systems principles
#
#   ML Testing and Validation:
#     Breck, E., Cai, S., Nielsen, E., Salib, M., & Sculley, D. (2017). The ML
#     test score: A rubric for ML production readiness and technical debt
#     reduction. IEEE International Conference on Big Data, 1123-1132.
#     https://doi.org/10.1109/BigData.2017.8258038
#     - ML testing best practices
#     - Production readiness assessment
#     - Technical debt measurement
#
#   Model Optimization:
#     Micikevicius, P., Narang, S., Alben, J., Diamos, G., Elsen, E., Garcia,
#     D., Ginsburg, B., Houston, M., Kuchaiev, O., Venkatesh, G., & Wu, H.
#     (2018). Mixed precision training. International Conference on Learning
#     Representations (ICLR).
#     https://openreview.net/forum?id=r1gs9JgRZ
#
#     Gholami, A., Kim, S., Dong, Z., Yao, Z., Mahoney, M. W., & Keutzer, K.
#     (2022). A survey of quantization methods for efficient neural network
#     inference. In Low-Power Computer Vision (pp. 291-326). Chapman and
#     Hall/CRC.
#     - Quantization techniques for inference
#     - Trade-offs between accuracy and speed
#
# Author: Võ Hải Dũng
# Email: vohaidung.work@gmail.com
# License: MIT License
# Project: AG News Text Classification (ag-news-text-classification)
# Repository: https://github.com/VoHaiDung/ag-news-text-classification
# Documentation: https://github.com/VoHaiDung/ag-news-text-classification/blob/main/docs/

metadata:
  name: "Local Production Environment Configuration"
  description: "Production-grade configuration for local deployment of AG News Text Classification"
  
  project:
    name_display: "AG News Text Classification"
    name_full: "AG News Text Classification (ag-news-text-classification)"
    name_slug: "ag-news-text-classification"
    name_package: "ag_news_text_classification"
    abbreviation: "AGNTC"
  
  version:
    config_version: "1.0.0"
    project_version: "1.0.0"
    schema_version: "1.0.0"
    api_version: "v1"
  
  environment:
    type: "local_prod"
    platform: "local_production"
    tier: "production"
    mode: "local_infrastructure"
    deployment_type: "production_local"
  
  authorship:
    author: "Võ Hải Dũng"
    email: "vohaidung.work@gmail.com"
    affiliation: null
    orcid: null
  
  legal:
    license: "MIT"
    copyright: "Copyright (c) 2025 Võ Hải Dũng"
    terms_of_use: "https://github.com/VoHaiDung/ag-news-text-classification/blob/main/LICENSE"
  
  repository:
    url: "https://github.com/VoHaiDung/ag-news-text-classification"
    branch: "main"
    commit: null
    documentation: "https://github.com/VoHaiDung/ag-news-text-classification/blob/main/docs/"
    issues: "https://github.com/VoHaiDung/ag-news-text-classification/issues"
  
  timestamps:
    created: "2025-09-19"
    modified: "2025-09-19"
    reviewed: "2025-09-19"
    expires: null
  
  validation:
    schema_validation: true
    strict_mode: true
    allow_unknown_fields: false
    validate_on_load: true
    fail_on_error: true
  
  maintenance:
    maintainer: "Võ Hải Dũng"
    support_email: "vohaidung.work@gmail.com"
    status: "stable"
    stability_level: "production"
  
  production_specifications:
    sla_target: "99.9%"
    max_downtime_minutes_monthly: 43
    optimization_target: "accuracy"
    security_level: "hardened"
    monitoring_level: "comprehensive"
    backup_frequency: "daily"

environment:
  name: "local_production"
  type: "production"
  mode: "production"
  
  runtime:
    debug: false
    verbose: false
    testing: false
    profiling: false
  
  features:
    auto_reload: false
    hot_reload: false
    fail_fast: true
    strict_mode: true
    warnings_as_errors: false
  
  optimization:
    optimize_for: "accuracy"
    performance_profile: "production"
    resource_priority: "quality"
    memory_strategy: "efficient"
  
  protection:
    protect_test_set: true
    prevent_data_leakage: true
    enforce_overfitting_constraints: true
    validate_checkpoints: true
  
  reproducibility:
    deterministic: true
    seed: 42
    enable_cudnn_deterministic: false
    enable_cudnn_benchmark: true
  
  cleanup:
    auto_cleanup: true
    cleanup_on_exit: true
    cleanup_interval_seconds: 86400
    clear_cuda_cache: true
    garbage_collect: true
  
  production:
    graceful_shutdown: true
    shutdown_timeout_seconds: 300
    health_check_enabled: true
    health_check_interval_seconds: 60
    readiness_check_enabled: true

platform:
  detector:
    module: "src.deployment.platform_detector"
    class: "PlatformDetector"
    auto_detect: false
    detection_method: "environment_inspection"
    fallback_platform: "local"
  
  identifier:
    platform_type: "local"
    platform_name: "Local Production"
    platform_version: "1.0.0"
    cloud_provider: null
    region: "local"
  
  capabilities:
    gpu_available: true
    tpu_available: false
    multi_gpu: true
    distributed_training: true
    mixed_precision: true
    gradient_checkpointing: true
  
  resources:
    tier: "production"
    gpu:
      type: "auto_detect"
      count: "auto_detect"
      vram_gb: "auto_detect"
      architecture: "auto_detect"
      compute_capability: "auto_detect"
      tensor_cores: "auto_detect"
      fp16_supported: true
      bf16_supported: "auto_detect"
      tf32_supported: "auto_detect"
    
    cpu:
      cores: "auto_detect"
      threads: "auto_detect"
      architecture: "auto_detect"
      model: "auto_detect"
      frequency_ghz: "auto_detect"
    
    memory:
      ram_gb: "auto_detect"
      swap_gb: "auto_detect"
      shared_memory_gb: "auto_detect"
    
    storage:
      available_gb: "auto_detect"
      type: "local_ssd"
      iops: "auto_detect"
      throughput_mbps: "auto_detect"
    
    network:
      bandwidth_mbps: "auto_detect"
      latency_ms: "auto_detect"
      egress_limited: false
  
  limitations:
    session_timeout_hours: null
    idle_timeout_minutes: null
    gpu_quota_limited: false
    storage_ephemeral: false
    ip_changes: false
    network_restrictions: false
  
  optimization:
    auto_detect_capabilities: true
    optimize_for_hardware: true
    enable_platform_specific: true
    use_all_available_gpus: true

paths:
  project_root: "."
  
  source:
    root: "src"
    configs: "configs"
    scripts: "scripts"
    notebooks: "notebooks"
    tests: "tests"
    docs: "docs"
  
  data:
    root: "data"
    
    raw:
      root: "data/raw"
      ag_news: "data/raw/ag_news"
    
    processed:
      root: "data/processed"
      train: "data/processed/train"
      validation: "data/processed/validation"
      test: "data/processed/test"
      stratified_folds: "data/processed/stratified_folds"
    
    augmented:
      root: "data/augmented"
      back_translated: "data/augmented/back_translated"
      paraphrased: "data/augmented/paraphrased"
      synthetic: "data/augmented/synthetic"
    
    metadata:
      root: "data/metadata"
      split_info: "data/metadata/split_info.json"
      statistics: "data/metadata/statistics.json"
      test_set_hash: "data/processed/.test_set_hash"
    
    platform_cache:
      root: "data/platform_cache"
      local_cache: "data/platform_cache/local_cache"
    
    quota_tracking:
      root: "data/quota_tracking"
      quota_history: "data/quota_tracking/quota_history.json"
      session_logs: "data/quota_tracking/session_logs.json"
      platform_usage_db: "data/quota_tracking/platform_usage.db"
  
  outputs:
    root: "outputs"
    
    models:
      root: "outputs/models"
      checkpoints: "outputs/models/checkpoints"
      fine_tuned: "outputs/models/fine_tuned"
      lora_adapters: "outputs/models/lora_adapters"
      exported: "outputs/models/exported"
      optimized: "outputs/models/optimized"
      production: "outputs/models/production"
    
    results:
      root: "outputs/results"
      experiments: "outputs/results/experiments"
      benchmarks: "outputs/results/benchmarks"
      overfitting_reports: "outputs/results/overfitting_reports"
      reports: "outputs/results/reports"
      production: "outputs/results/production"
    
    logs:
      root: "outputs/logs"
      training: "outputs/logs/training"
      tensorboard: "outputs/logs/tensorboard"
      mlflow: "outputs/logs/mlflow"
      local: "outputs/logs/local"
      production: "outputs/logs/production"
      audits: "outputs/logs/production/audits"
    
    artifacts:
      root: "outputs/artifacts"
      figures: "outputs/artifacts/figures"
      tables: "outputs/artifacts/tables"
    
    profiling:
      root: "outputs/profiling"
      memory: "outputs/profiling/memory"
      speed: "outputs/profiling/speed"
      traces: "outputs/profiling/traces"
  
  cache:
    root: "cache"
    
    huggingface:
      root: "cache/huggingface"
      models: "cache/huggingface/models"
      datasets: "cache/huggingface/datasets"
      transformers: "cache/huggingface/transformers"
    
    local:
      root: "cache/local"
      preprocessing: "cache/local/preprocessing"
      tokenization: "cache/local/tokenization"
    
    models:
      root: "cache/models"
      pretrained: "cache/models/pretrained"
      temporary: "cache/models/temporary"
    
    inference:
      root: "cache/inference"
      predictions: "cache/inference/predictions"
  
  temp:
    root: "temp"
    processing: "temp/processing"
    downloads: "temp/downloads"
    extraction: "temp/extraction"
  
  backup:
    root: "backup"
    models: "backup/models"
    checkpoints: "backup/checkpoints"
    logs: "backup/logs"
    configs: "backup/configs"
  
  deployment:
    docker: "deployment/docker"
    local: "deployment/local"
    systemd: "deployment/local/systemd"
    nginx: "deployment/local/nginx"

model:
  selection:
    strategy: "production_optimized"
    tier: "tier_1_sota"
    config_source: "configs/models/recommended/tier_1_sota/deberta_v3_xlarge_lora.yaml"
    fallback_config: "configs/models/recommended/tier_1_sota/roberta_large_lora.yaml"
  
  architecture:
    base_model: "microsoft/deberta-v3-large"
    model_type: "deberta"
    model_family: "transformers"
    variant: "v3-large"
    
    parameters:
      total_params: 434000000
      trainable_params: 1835008
      frozen_params: 432164992
      trainable_ratio: 0.00423
    
    specifications:
      num_labels: 4
      num_hidden_layers: 24
      hidden_size: 1024
      num_attention_heads: 16
      intermediate_size: 4096
      max_position_embeddings: 512
      vocab_size: 128100
  
  tokenizer:
    name: "microsoft/deberta-v3-large"
    type: "DebertaV2Tokenizer"
    
    configuration:
      max_length: 512
      padding: "max_length"
      truncation: true
      truncation_strategy: "longest_first"
      return_tensors: "pt"
      return_attention_mask: true
      return_token_type_ids: false
      add_special_tokens: true
    
    special_tokens:
      cls_token: "[CLS]"
      sep_token: "[SEP]"
      pad_token: "[PAD]"
      unk_token: "[UNK]"
      mask_token: "[MASK]"
  
  loading:
    pretrained: true
    cache_dir: "cache/huggingface/models"
    
    options:
      trust_remote_code: false
      force_download: false
      resume_download: true
      local_files_only: false
      use_auth_token: false
      revision: "main"
    
    memory:
      device_map: "auto"
      low_cpu_mem_usage: true
      torch_dtype: "auto"
      load_in_8bit: false
      load_in_4bit: false
  
  configuration:
    hidden_dropout_prob: 0.1
    attention_probs_dropout_prob: 0.1
    classifier_dropout: 0.1
    
    pooling:
      type: "cls"
      mean_pooling: false
      max_pooling: false
      attention_pooling: false
    
    head:
      type: "classification"
      num_layers: 1
      hidden_size: 1024
      activation: "gelu"
      dropout: 0.1
      initializer_range: 0.02
  
  versioning:
    enabled: true
    version: "1.0.0"
    compute_signature: true
    compute_hash: true
    hash_algorithm: "sha256"

peft:
  enabled: true
  method: "lora"
  config_source: "configs/training/efficient/lora/lora_xlarge.yaml"
  
  lora:
    rank: 16
    alpha: 32
    dropout: 0.1
    
    target_modules:
      - "query_proj"
      - "value_proj"
      - "key_proj"
      - "dense"
    
    configuration:
      bias: "none"
      task_type: "SEQ_CLS"
      inference_mode: false
      r: 16
      lora_alpha: 32
      lora_dropout: 0.1
      fan_in_fan_out: false
      merge_weights: true
    
    modules_to_save:
      - "classifier"
      - "pooler"
    
    init_lora_weights: true
    
    constraints:
      max_rank: 64
      min_rank: 4
      recommended_rank_range: [8, 32]
      rank_selection_strategy: "production_accuracy"
  
  memory_efficiency:
    trainable_params_ratio: 0.00423
    memory_reduction_factor: 236.4
    estimated_vram_usage_gb: 10.5
  
  production:
    merge_for_inference: true
    save_pretrained_separately: true

training:
  trainer:
    module: "src.training.trainers.auto_trainer"
    class: "AutoTrainer"
    backend: "huggingface"
    strategy: "production_optimized"
  
  regime:
    num_epochs: 10
    max_steps: -1
    total_steps: null
    warmup_steps: null
    
    evaluation_strategy: "epoch"
    save_strategy: "epoch"
    logging_strategy: "steps"
    
    logging_steps: 100
    eval_steps: null
    save_steps: null
    
    logging_first_step: false
    eval_on_start: true
    save_on_each_node: false
  
  batching:
    per_device_train_batch_size: 32
    per_device_eval_batch_size: 64
    gradient_accumulation_steps: 2
    
    effective_batch_size: 64
    auto_find_batch_size: false
    
    dataloader_num_workers: 4
    dataloader_pin_memory: true
    dataloader_drop_last: false
    dataloader_prefetch_factor: 2
    dataloader_persistent_workers: true
  
  optimization:
    optimizer:
      type: "adamw_torch_fused"
      
      parameters:
        lr: 0.00001
        betas: [0.9, 0.999]
        eps: 0.00000001
        weight_decay: 0.01
        amsgrad: false
      
      clip_grad_norm: 1.0
      clip_grad_value: null
    
    scheduler:
      type: "cosine"
      
      parameters:
        num_warmup_steps: 0
        warmup_ratio: 0.1
        num_cycles: 1.0
        min_lr_ratio: 0.0
      
      warmup_strategy: "linear"
  
  precision:
    mixed_precision: "bf16"
    fp16: false
    bf16: true
    fp16_opt_level: "O2"
    fp16_backend: "auto"
    fp16_full_eval: false
    
    half_precision_backend: "cuda_amp"
    
    loss_scaling:
      enabled: false
  
  memory:
    gradient_checkpointing: false
    gradient_checkpointing_kwargs:
      use_reentrant: false
    
    max_grad_norm: 1.0
    
    optimization:
      empty_cache_steps: 100
      garbage_collect_steps: 200
      low_memory_mode: false
  
  checkpointing:
    save_total_limit: 5
    save_safetensors: true
    load_best_model_at_end: true
    
    checkpoint_manager:
      module: "src.deployment.checkpoint_manager"
      class: "CheckpointManager"
      
      strategy: "epoch_based"
      interval_minutes: null
      save_on_interrupt: true
      verify_integrity: true
      compress_checkpoints: false
    
    recovery:
      resume_from_checkpoint: true
      auto_resume: true
      ignore_data_skip: false
      strict_loading: true
  
  metrics:
    metric_for_best_model: "eval_f1"
    greater_is_better: true
    
    metrics_to_compute:
      - "accuracy"
      - "precision"
      - "recall"
      - "f1"
      - "loss"
    
    evaluation:
      prediction_loss_only: false
      include_inputs_for_metrics: false
      include_num_input_tokens_seen: true
  
  early_stopping:
    enabled: true
    
    callback:
      module: "src.training.callbacks.early_stopping"
      class: "EarlyStoppingCallback"
    
    parameters:
      patience: 3
      min_delta: 0.001
      monitor: "eval_f1"
      mode: "max"
      restore_best_weights: true
      verbose: true
  
  regularization:
    dropout:
      hidden_dropout: 0.1
      attention_dropout: 0.1
      classifier_dropout: 0.1
      lora_dropout: 0.1
    
    weight_decay: 0.01
    
    label_smoothing: 0.1
    label_smoothing_factor: 0.1
    
    gradient_clipping:
      enabled: true
      max_norm: 1.0
      norm_type: 2
  
  reproducibility:
    seed: 42
    data_seed: 42
    full_determinism: false
    
    torch_deterministic: true
    cudnn_deterministic: false
    cudnn_benchmark: true
  
  callbacks:
    enabled_callbacks:
      - module: "src.training.callbacks.platform_callback"
        class: "PlatformCallback"
        priority: 1
      
      - module: "src.training.callbacks.overfitting_monitor"
        class: "OverfittingMonitorCallback"
        priority: 2
      
      - module: "src.training.callbacks.memory_monitor_callback"
        class: "MemoryMonitorCallback"
        priority: 3
      
      - module: "transformers.trainer_callback"
        class: "PrinterCallback"
        priority: 10
    
    disable_default_callbacks: false
  
  reporting:
    report_to:
      - "tensorboard"
      - "mlflow"
    
    run_name: "production_run"
    output_dir: "outputs/models/checkpoints"
    logging_dir: "outputs/logs/tensorboard"
    
    push_to_hub: false
    hub_model_id: null
    hub_strategy: "every_save"
    hub_token: null
    hub_private_repo: false
  
  distributed:
    enabled: false
    ddp_backend: "nccl"
    ddp_find_unused_parameters: false
    ddp_bucket_cap_mb: 25
  
  performance:
    tf32: true
    auto_find_batch_size: false

data:
  dataset:
    name: "ag_news"
    source: "huggingface"
    dataset_name: "ag_news"
    dataset_config: null
    
    loader:
      module: "src.data.datasets.ag_news"
      class: "AGNewsDataset"
    
    cache:
      use_cache: true
      cache_dir: "data/cache/local_cache"
      overwrite_cache: false
      download_mode: "reuse_cache_if_exists"
      verify_cache: true
  
  splits:
    strategy: "stratified"
    
    ratios:
      train: 0.8
      validation: 0.1
      test: 0.1
    
    configuration:
      stratify: true
      shuffle: true
      random_seed: 42
    
    validator:
      module: "src.core.overfitting_prevention.validators.split_validator"
      class: "SplitValidator"
      
      checks:
        - "minimum_split_size"
        - "label_distribution"
        - "no_data_leakage"
  
  sampling:
    max_samples:
      train: null
      validation: null
      test: null
  
  preprocessing:
    pipeline:
      module: "src.data.preprocessing.text_cleaner"
      steps:
        - name: "normalize_whitespace"
          enabled: true
        - name: "strip"
          enabled: true
        - name: "remove_html"
          enabled: true
        - name: "remove_duplicates"
          enabled: true
        - name: "lowercase"
          enabled: false
    
    configuration:
      lowercase: false
      remove_html: true
      remove_urls: false
      remove_special_chars: false
      normalize_whitespace: true
      strip: true
      remove_duplicates: true
      min_length: 10
      max_length: 10000
    
    cache_processed: true
  
  augmentation:
    enabled: false
    
    methods: []
    
    constraints:
      module: "src.core.overfitting_prevention.constraints.augmentation_constraints"
      max_augmentation_ratio: 2.0
      preserve_label_distribution: true
  
  validation:
    checks:
      - "label_validity"
      - "text_length"
      - "encoding_validity"
      - "duplicate_detection"
      - "missing_values"
    
    actions:
      remove_invalid: true
      log_invalid: true
      fail_on_invalid: true
    
    validator:
      module: "src.data.validation.split_strategies"
      class: "DataValidator"
    
    thresholds:
      max_invalid_ratio: 0.01
  
  loading:
    num_proc: 4
    keep_in_memory: false
    streaming: false
    
    batch_size: 1000
    writer_batch_size: 1000
  
  versioning:
    enabled: true
    data_version: "1.0.0"
    compute_hash: true
    hash_algorithm: "sha256"

api:
  enabled: true
  
  server:
    host: "0.0.0.0"
    port: 8000
    workers: 4
    reload: false
    debug: false
    log_level: "info"
    access_log: true
  
  cors:
    enabled: true
    origins:
      - "http://localhost:3000"
      - "http://127.0.0.1:3000"
    methods:
      - "GET"
      - "POST"
    headers:
      - "Content-Type"
      - "Authorization"
    credentials: false
    max_age: 3600
  
  rate_limit:
    enabled: true
    requests_per_minute: 60
    requests_per_hour: 1000
    requests_per_day: 10000
    burst: 10
    strategy: "fixed_window"
  
  authentication:
    enabled: true
    type: "token"
    token_expiry_hours: 24
    require_https: false
  
  request:
    max_size_bytes: 1048576
    timeout_seconds: 60
    max_batch_size: 100
  
  endpoints:
    predict: "/api/v1/predict"
    batch_predict: "/api/v1/batch_predict"
    health: "/health"
    ready: "/ready"
    metrics: "/metrics"
    docs: "/docs"
    redoc: "/redoc"
  
  response:
    format: "json"
    include_metadata: false
    include_timing: true
    include_version: true
  
  production_features:
    enable_playground: false
    enable_api_docs: true
    enable_metrics: true
    enable_tracing: false
  
  circuit_breaker:
    enabled: true
    failure_threshold: 5
    timeout_seconds: 60
    half_open_max_requests: 3

monitoring:
  enabled: true
  
  tensorboard:
    enabled: true
    
    service:
      module: "src.services.monitoring.tensorboard_service"
      class: "TensorBoardService"
    
    configuration:
      log_dir: "outputs/logs/tensorboard"
      update_freq: "epoch"
      profile_batch: 0
      histogram_freq: 0
      write_graph: false
      write_images: false
      embeddings_freq: 0
  
  mlflow:
    enabled: true
    
    service:
      module: "src.services.monitoring.mlflow_service"
      class: "MLflowService"
    
    configuration:
      tracking_uri: "outputs/logs/mlflow"
      experiment_name: "ag_news_production"
      run_name: "production_run"
      log_artifacts: true
      log_models: true
      log_params: true
      log_metrics: true
      autolog: false
  
  wandb:
    enabled: false
  
  local_metrics:
    enabled: true
    
    service:
      module: "src.services.monitoring.local_metrics_service"
      class: "LocalMetricsService"
    
    configuration:
      save_dir: "outputs/logs/local"
      save_interval_steps: 100
      
      metrics_to_track:
        - "train_loss"
        - "eval_loss"
        - "eval_accuracy"
        - "eval_f1"
        - "eval_precision"
        - "eval_recall"
        - "learning_rate"
        - "epoch"
        - "step"
        - "gpu_memory_allocated"
        - "gpu_memory_reserved"
        - "training_time"
        - "throughput"
        - "latency"
      
      export_formats:
        - "json"
        - "csv"
  
  overfitting:
    monitor:
      module: "src.core.overfitting_prevention.monitors.training_monitor"
      class: "TrainingMonitor"
    
    configuration:
      track_train_val_gap: true
      gap_threshold: 0.02
      gap_metric: "loss"
      
      alert_on_overfitting: true
      fail_on_overfitting: true
      alert_threshold_consecutive: 3
      
      generate_reports: true
      report_frequency_steps: 500
  
  performance:
    track_memory: true
    track_gpu_utilization: true
    track_training_speed: true
    track_throughput: true
    track_latency: true
    
    alerts:
      memory_threshold_percent: 90
      gpu_memory_threshold_percent: 90
      cpu_threshold_percent: 90
  
  system:
    track_cpu: true
    track_memory: true
    track_disk: true
    track_network: false
    
    alert_thresholds:
      cpu_percent: 90
      memory_percent: 90
      disk_percent: 85
  
  alerts:
    enabled: true
    email_enabled: false
    webhook_enabled: false
    log_enabled: true
    alert_on_errors: true
    alert_on_performance_degradation: true

overfitting_prevention:
  enabled: true
  
  system:
    module: "src.core.overfitting_prevention"
    strict_mode: true
    config_source: "configs/overfitting_prevention"
  
  test_set_protection:
    enabled: true
    
    guard:
      module: "src.core.overfitting_prevention.guards.test_set_guard"
      class: "TestSetGuard"
    
    configuration:
      hash_verification: true
      hash_algorithm: "sha256"
      hash_file: "data/metadata/.test_set_hash"
      
      access_logging: true
      log_file: "data/test_access_log.json"
      
      prevent_access_during_training: true
      allow_final_evaluation: true
      max_accesses: 1
      lock_after_use: true
  
  monitoring:
    real_time:
      module: "src.core.overfitting_prevention.monitors.overfitting_detector"
      class: "OverfittingDetector"
    
    configuration:
      track_train_val_gap: true
      gap_metrics:
        - "loss"
        - "accuracy"
        - "f1"
      
      thresholds:
        loss_gap: 0.02
        accuracy_gap: 0.02
        f1_gap: 0.02
      
      consecutive_violations: 3
      
      actions:
        alert: true
        log: true
        stop_training: true
        recommend_adjustments: true
  
  constraints:
    enforcer:
      module: "src.core.overfitting_prevention.constraints.constraint_enforcer"
      class: "ConstraintEnforcer"
    
    model_constraints:
      max_model_parameters: 1000000000
      max_trainable_parameters: 50000000
      min_parameter_efficiency_ratio: 0.001
      
      lora_constraints:
        max_rank: 64
        recommended_rank: 16
        max_alpha: 64
    
    training_constraints:
      min_validation_ratio: 0.1
      max_epochs_without_improvement: 5
      
      required_regularization:
        - "dropout"
        - "weight_decay"
    
    data_constraints:
      min_train_samples: 1000
      min_validation_samples: 100
      prevent_data_augmentation_in_validation: true
  
  validation:
    data_leakage:
      detector:
        module: "src.core.overfitting_prevention.validators.data_leakage_detector"
        class: "DataLeakageDetector"
      
      checks:
        - "train_val_overlap"
        - "train_test_overlap"
        - "val_test_overlap"
        - "duplicate_samples"
    
    hyperparameter:
      validator:
        module: "src.core.overfitting_prevention.validators.hyperparameter_validator"
        class: "HyperparameterValidator"
      
      rules:
        prevent_tuning_on_test: true
        limit_tuning_iterations: 50
        track_tuning_history: true
    
    cross_validation:
      enabled: true
      strategy: "k_fold"
      k_folds: 5
      stratified: true
  
  recommendations:
    recommender:
      module: "src.core.overfitting_prevention.recommendations.config_recommender"
      class: "ConfigRecommender"
    
    generation:
      auto_recommend: true
      recommend_on_overfitting: true
      
      suggestions:
        - "increase_dropout"
        - "increase_weight_decay"
        - "reduce_model_complexity"
        - "increase_data_augmentation"
        - "early_stopping"
  
  reporting:
    reporter:
      module: "src.core.overfitting_prevention.reporting.overfitting_reporter"
      class: "OverfittingReporter"
    
    configuration:
      generate_reports: true
      report_frequency_steps: 500
      output_dir: "outputs/results/overfitting_reports"
      
      report_format: "html"
      include_visualizations: true
      include_recommendations: true

logging:
  configuration:
    version: 1
    disable_existing_loggers: false
  
  formatters:
    standard:
      format: "[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s"
      datefmt: "%Y-%m-%d %H:%M:%S"
    
    detailed:
      format: "[%(asctime)s] [%(name)s] [%(levelname)s] [%(filename)s:%(lineno)d] %(message)s"
      datefmt: "%Y-%m-%d %H:%M:%S"
    
    json:
      class: "pythonjsonlogger.jsonlogger.JsonFormatter"
      format: "%(asctime)s %(name)s %(levelname)s %(message)s"
    
    simple:
      format: "%(levelname)s - %(message)s"
  
  handlers:
    console:
      class: "logging.StreamHandler"
      level: "INFO"
      formatter: "standard"
      stream: "ext://sys.stdout"
    
    file:
      class: "logging.handlers.RotatingFileHandler"
      level: "INFO"
      formatter: "detailed"
      filename: "outputs/logs/production/production.log"
      maxBytes: 104857600
      backupCount: 10
      encoding: "utf8"
    
    json_file:
      class: "logging.handlers.RotatingFileHandler"
      level: "INFO"
      formatter: "json"
      filename: "outputs/logs/production/production.json"
      maxBytes: 104857600
      backupCount: 10
      encoding: "utf8"
    
    error_file:
      class: "logging.handlers.RotatingFileHandler"
      level: "ERROR"
      formatter: "detailed"
      filename: "outputs/logs/production/errors.log"
      maxBytes: 104857600
      backupCount: 5
      encoding: "utf8"
    
    audit_file:
      class: "logging.handlers.RotatingFileHandler"
      level: "INFO"
      formatter: "json"
      filename: "outputs/logs/production/audits/audit.log"
      maxBytes: 104857600
      backupCount: 20
      encoding: "utf8"
  
  loggers:
    ag_news_text_classification:
      level: "INFO"
      handlers:
        - "console"
        - "file"
        - "json_file"
        - "error_file"
      propagate: false
    
    ag_news_text_classification.data:
      level: "INFO"
    
    ag_news_text_classification.models:
      level: "INFO"
    
    ag_news_text_classification.training:
      level: "INFO"
    
    ag_news_text_classification.deployment:
      level: "INFO"
    
    ag_news_text_classification.api:
      level: "INFO"
    
    ag_news_text_classification.security:
      level: "WARNING"
    
    transformers:
      level: "WARNING"
    
    datasets:
      level: "WARNING"
    
    torch:
      level: "WARNING"
    
    uvicorn:
      level: "INFO"
    
    fastapi:
      level: "INFO"
  
  root:
    level: "INFO"
    handlers:
      - "console"
      - "file"
      - "json_file"
  
  audit:
    enabled: true
    handler: "audit_file"
    log_api_calls: true
    log_model_predictions: false
    log_data_access: true
    log_authentication: true

security:
  authentication:
    enabled: true
    type: "token"
    token_length: 32
    hash_algorithm: "sha256"
    store_tokens_encrypted: true
  
  authorization:
    enabled: true
    rbac_enabled: true
    default_role: "user"
    admin_role: "admin"
  
  api:
    api_key_required: true
    token_required: true
    validate_origin: true
    validate_user_agent: false
  
  request_validation:
    validate_input: true
    sanitize_input: true
    max_input_length: 10000
    allowed_content_types:
      - "application/json"
      - "text/plain"
  
  data_privacy:
    pii_detection: true
    data_masking: true
    anonymize_logs: true
  
  model_security:
    checksum_verification: true
    signature_verification: true
    verify_on_load: true
  
  network:
    https_only: false
    ssl_cert: null
    ssl_key: null
    tls_version: "1.3"
  
  access_control:
    ip_whitelist: []
    ip_blacklist: []
  
  security_headers:
    x_content_type_options: "nosniff"
    x_frame_options: "DENY"
    x_xss_protection: "1; mode=block"
    strict_transport_security: "max-age=31536000; includeSubDomains"

deployment:
  type: "local_production"
  platform: "local"
  
  docker:
    enabled: true
    image_name: "ag-news-production"
    image_tag: "1.0.0"
    dockerfile: "deployment/docker/Dockerfile.local"
    
    build_args:
      PYTHON_VERSION: "3.10"
      PYTORCH_VERSION: "2.0.1"
    
    ports:
      - "8000:8000"
    
    volumes:
      - "./data:/app/data:ro"
      - "./outputs:/app/outputs"
      - "./cache:/app/cache"
    
    restart_policy: "unless-stopped"
  
  model_serving:
    framework: "pytorch"
    optimization: "full"
    quantization: true
    quantization_method: "dynamic"
    pruning: false
    onnx_export: false
    compile_model: false
  
  resources:
    cpu_limit: null
    memory_limit: null
    gpu_limit: null
    cpu_request: 4
    memory_request: "16Gi"
  
  health_check:
    enabled: true
    path: "/health"
    interval_seconds: 30
    timeout_seconds: 10
    retries: 3
    start_period_seconds: 60
  
  readiness:
    enabled: true
    path: "/ready"
    interval_seconds: 10
    timeout_seconds: 5

backup:
  enabled: true
  
  schedule:
    frequency: "daily"
    time: "02:00"
    retain_days: 30
  
  targets:
    models: true
    checkpoints: true
    logs: true
    configs: true
    results: true
  
  storage:
    backup_dir: "backup/production"
    compression: true
    compression_format: "tar.gz"
  
  verification:
    verify_backup: true
    test_restore: false

recovery:
  auto_resume: true
  resume_from_checkpoint: true
  checkpoint_recovery_enabled: true
  
  retry:
    retry_on_failure: true
    max_retries: 3
    retry_delay_seconds: 60
  
  rollback:
    enable_rollback: true
    rollback_on_failure: true
    keep_previous_version: true

performance:
  training:
    optimization_level: "high"
    
    compiler:
      torch_compile: false
      compile_mode: null
      compile_backend: null
    
    transformers:
      use_better_transformer: false
      flash_attention: false
    
    cuda:
      enable_tf32: true
      cudnn_benchmark: true
      cudnn_deterministic: false
    
    dataloader:
      pin_memory: true
      non_blocking: true
      prefetch_factor: 2
      persistent_workers: true
  
  inference:
    batch_size: 64
    precision: "fp16"
    optimization: "speed"
    dynamic_quantization: true
    cache_predictions: true
    cache_size: 10000
  
  profiling:
    enabled: false
    
    configuration:
      profile_memory: false
      profile_time: false
      with_stack: false
      record_shapes: false

features:
  experimental:
    flash_attention: false
    torch_compile: false
    better_transformer: false
  
  advanced:
    ensemble_models: false
    knowledge_distillation: false
    multi_task_learning: false
  
  optimization:
    mixed_precision: true
    gradient_accumulation: true
    gradient_checkpointing: false
    dynamic_batching: false
    model_quantization: true
  
  data:
    augmentation: false
    streaming: false
    caching: true
  
  platform:
    auto_detection: false
    platform_optimization: true
    quota_tracking: false
  
  production:
    model_versioning: true
    model_registry: true
    a_b_testing: false
    canary_deployment: false

validation:
  schema:
    validate_on_load: true
    strict_schema: true
    allow_unknown_fields: false
  
  dependencies:
    check_versions: true
    check_gpu: true
    check_cuda: true
    fail_on_missing: true
  
  paths:
    verify_existence: false
    create_missing: true

documentation:
  description: |
    Production-grade local deployment configuration for AG News Text Classification.
    Optimized for maximum accuracy, reliability, and operational excellence on
    local infrastructure with zero cloud costs.
    
    Features:
    - Full dataset training (10 epochs)
    - Production API with authentication
    - Comprehensive monitoring (TensorBoard, MLflow)
    - Strict overfitting prevention
    - Automated daily backups
    - Health checks and recovery
    - Security hardening
    - Model versioning
  
  quickstart: |
    Production deployment workflow:
    
    # Train production model
    export ENVIRONMENT=local_prod
    python src/cli.py train --env local_prod
    
    # Start production API
    python -m uvicorn src.api.rest.app:app --host 0.0.0.0 --port 8000
    
    # Docker deployment
    docker-compose -f deployment/docker/docker-compose.local.yml up -d
    
    # Health check
    curl http://localhost:8000/health
  
  references:
    project_documentation: "https://github.com/VoHaiDung/ag-news-text-classification/blob/main/docs/"
    troubleshooting: "https://github.com/VoHaiDung/ag-news-text-classification/blob/main/TROUBLESHOOTING.md"
  
  related_configs:
    - "configs/models/recommended/tier_1_sota/deberta_v3_xlarge_lora.yaml"
    - "configs/training/platform_adaptive/local_gpu_training.yaml"
    - "configs/overfitting_prevention/safe_defaults/beginner_safe_defaults.yaml"
    - "configs/deployment/local/api_local.yaml"

maintainer:
  name: "Võ Hải Dũng"
  email: "vohaidung.work@gmail.com"
  last_updated: "2025-09-19"
  version: "1.0.0"
