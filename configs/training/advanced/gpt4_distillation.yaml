# GPT-4 Knowledge Distillation Configuration
# ===========================================
# Configuration for distilling knowledge from GPT-4 following methodologies from:
# - Hinton et al. (2015): "Distilling the Knowledge in a Neural Network"
# - Hsieh et al. (2023): "Distilling Step-by-Step: Outperforming Larger Language Models"
# - West et al. (2022): "Symbolic Knowledge Distillation: from General Language Models to Commonsense Models"
# - Fu et al. (2023): "Specializing Smaller Language Models towards Multi-Step Reasoning"
#
# Mathematical Foundation:
# Distillation loss: L = α·CE(y_student, y_true) + (1-α)·KL(σ(z_s/T), σ(z_t/T))
# where z_s, z_t are student and teacher logits, T is temperature
#
# Chain-of-thought distillation: L_cot = L_answer + λ·L_rationale
# where L_rationale measures alignment of reasoning steps
#
# Author: Võ Hải Dũng
# License: MIT

name: gpt4_distillation
type: advanced_llm_distillation
description: "Distilling knowledge from GPT-4 into smaller models with reasoning capabilities"

# Base configuration inheritance
extends: ../standard/base_training.yaml

# GPT-4 Teacher Configuration
gpt4_teacher:
  # API configuration
  api:
    provider: openai  # Options: openai, azure, custom
    model: gpt-4  # Options: gpt-4, gpt-4-turbo, gpt-3.5-turbo
    api_key_env: OPENAI_API_KEY  # Environment variable for API key
    
    # Azure-specific (if using Azure)
    azure:
      endpoint: null
      deployment_name: null
      api_version: "2024-02-01"
    
    # Rate limiting
    rate_limit:
      requests_per_minute: 60
      tokens_per_minute: 90000
      retry_strategy: exponential_backoff
      max_retries: 3
      
    # Cost management
    cost_tracking:
      enabled: true
      max_cost_per_run: 100.0  # USD
      log_costs: true
  
  # Generation configuration
  generation:
    temperature: 0.3  # Lower for consistency
    top_p: 0.95
    max_tokens: 512
    
    # Few-shot configuration
    few_shot:
      enabled: true
      num_examples: 3
      example_selection: diverse  # Options: random, similar, diverse
      
    # System prompt
    system_prompt: |
      You are an expert at classifying news articles.
      Provide clear reasoning for your classifications.
      Be concise but thorough in your explanations.
  
  # Prompt templates
  prompts:
    # Classification prompt
    classification: |
      Classify the following news article into one of these categories:
      - World: International news, politics, global events
      - Sports: Athletic events, competitions, games
      - Business: Economy, finance, markets, companies
      - Science/Technology: Scientific discoveries, tech news, innovations
      
      Article: {text}
      
      Provide your answer in the following format:
      Category: [your classification]
      Confidence: [0-1 score]
      Reasoning: [brief explanation]
    
    # Chain-of-thought prompt
    chain_of_thought: |
      Let's classify this news article step by step.
      
      Article: {text}
      
      Step 1: Identify the main topic
      Step 2: Look for key indicators
      Step 3: Consider the context
      Step 4: Make final classification
      
      Format your response as:
      Thought Process: [your step-by-step reasoning]
      Final Category: [classification]
      Confidence: [0-1 score]
    
    # Rationale generation
    rationale: |
      Explain why this article belongs to the {label} category:
      
      Article: {text}
      
      Provide a clear, educational explanation that would help someone
      understand the classification criteria.
    
    # Multi-aspect analysis
    multi_aspect: |
      Analyze this article from multiple perspectives:
      1. Main topic
      2. Key entities mentioned
      3. Geographic scope
      4. Temporal aspects
      5. Impact/significance
      
      Article: {text}
      
      Based on your analysis, classify into: World/Sports/Business/Science-Technology

# Student Model Configuration
student_model:
  # Model selection
  base_model: distilbert-base-uncased  # Smaller, efficient model
  
  # Architecture modifications
  modifications:
    add_reasoning_head: true  # Additional head for rationale generation
    reasoning_hidden_dim: 512
    use_adapter_layers: false
    
  # Initialization
  initialization:
    from_pretrained: true
    reset_classifier: true
    
  # Capacity ratio (student/teacher)
  capacity_ratio: 0.1  # Student is ~10% of teacher size

# Distillation Strategy
distillation:
  # Distillation type
  type: progressive  # Options: standard, progressive, step_by_step, multi_stage
  
  # Loss configuration
  loss:
    # Loss weights
    alpha: 0.3  # Weight for hard labels
    beta: 0.7  # Weight for soft labels
    
    # Temperature for distillation
    temperature: 4.0
    temperature_scheduling:
      enabled: true
      initial: 5.0
      final: 1.0
      schedule: cosine  # Options: linear, cosine, exponential
    
    # Additional losses
    feature_matching:
      enabled: false
      layers: [-1, -2, -3]  # Match last 3 layers
      weight: 0.1
      
    attention_transfer:
      enabled: false
      weight: 0.1
      
    hidden_state_loss:
      enabled: false
      weight: 0.1
  
  # Progressive distillation
  progressive:
    enabled: true
    stages:
      - name: soft_targets_only
        epochs: 3
        alpha: 0.0
        temperature: 5.0
        
      - name: mixed_targets
        epochs: 5
        alpha: 0.3
        temperature: 3.0
        
      - name: fine_tuning
        epochs: 2
        alpha: 0.7
        temperature: 1.0
  
  # Step-by-step distillation (Hsieh et al., 2023)
  step_by_step:
    enabled: true
    
    # Rationale extraction
    extract_rationales: true
    rationale_generation_method: cot  # Options: cot, few_shot, zero_shot
    
    # Multi-step training
    steps:
      - name: rationale_prediction
        task: predict_rationale
        epochs: 5
        
      - name: label_prediction_with_rationale
        task: predict_label_given_rationale
        epochs: 5
        
      - name: joint_training
        task: predict_both
        epochs: 5
    
    # Rationale quality filtering
    filter_rationales:
      enabled: true
      min_quality_score: 0.7
      quality_metric: perplexity  # Options: perplexity, coherence, correctness

# Data Generation from GPT-4
data_generation:
  # Generation strategy
  strategy: active  # Options: all, active, uncertainty, diverse
  
  # Sample selection for labeling
  selection:
    method: uncertainty  # Options: random, uncertainty, diversity, hybrid
    num_samples: 10000  # Number of samples to label
    batch_size: 100  # Samples per API call batch
    
  # Caching
  cache:
    enabled: true
    cache_dir: ./cache/gpt4_responses
    cache_format: jsonl
    
  # Data augmentation using GPT-4
  augmentation:
    enabled: true
    methods:
      paraphrase:
        enabled: true
        num_paraphrases: 2
        
      explanation_augmentation:
        enabled: true
        generate_explanations: true
        
      counterfactual:
        enabled: false
        num_counterfactuals: 1
    
  # Quality control
  quality_control:
    filter_low_confidence: true
    confidence_threshold: 0.7
    
    verify_consistency: true
    num_verification_runs: 3
    
    human_validation:
      enabled: false
      sample_size: 100

# Chain-of-Thought Distillation
chain_of_thought:
  enabled: true
  
  # CoT generation
  generation:
    method: zero_shot  # Options: zero_shot, few_shot, auto_cot
    
    # Prompt engineering
    use_prompt_ensemble: true
    num_prompt_variations: 3
    
    # Self-consistency
    self_consistency:
      enabled: true
      num_samples: 5
      aggregation: majority_vote
  
  # CoT training
  training:
    # Rationale supervision
    use_rationale_supervision: true
    rationale_loss_weight: 0.5
    
    # Intermediate supervision
    supervise_intermediate_steps: false
    step_loss_weight: 0.3
    
    # Consistency loss
    consistency_loss:
      enabled: true
      weight: 0.2
      
  # CoT compression
  compression:
    enabled: false
    method: pruning  # Options: pruning, quantization, knowledge_distillation
    target_compression_ratio: 0.5

# Symbolic Knowledge Distillation
symbolic:
  enabled: false
  
  # Knowledge extraction
  extraction:
    extract_rules: true
    extract_patterns: true
    extract_constraints: true
    
  # Symbolic representation
  representation:
    format: logic  # Options: logic, graph, rules
    
  # Integration with neural model
  integration:
    method: hybrid  # Options: hybrid, neuro_symbolic, augmentation
    weight: 0.3

# Active Learning Integration
active_learning:
  enabled: true
  
  # Query strategy
  strategy: uncertainty  # Options: uncertainty, diversity, expected_gradient_length
  
  # Budget
  budget:
    total_queries: 1000
    queries_per_round: 100
    
  # GPT-4 as oracle
  oracle:
    use_gpt4: true
    fallback_to_human: false
    
  # Sample selection
  selection:
    pool_size: 10000
    selection_batch_size: 100
    
    # Uncertainty measures
    uncertainty_metric: entropy  # Options: entropy, margin, variation_ratio
    
    # Diversity
    diversity_weight: 0.3
    clustering_method: kmeans

# Curriculum for Distillation
curriculum:
  enabled: true
  
  # Difficulty scoring
  difficulty:
    source: gpt4_confidence  # Use GPT-4's confidence as difficulty
    inverse: true  # Low confidence = high difficulty
    
  # Pacing
  pacing:
    initial_fraction: 0.3
    final_fraction: 1.0
    schedule: linear
    
  # Curriculum stages
  stages:
    - name: easy
      fraction: 0.3
      temperature: 5.0
      
    - name: medium
      fraction: 0.6
      temperature: 3.0
      
    - name: hard
      fraction: 1.0
      temperature: 1.0

# Training Configuration
training:
  # Epochs and batching
  num_epochs: 20
  batch_size: 32
  gradient_accumulation_steps: 2
  
  # Learning rates
  learning_rate: 3e-5
  warmup_ratio: 0.1
  
  # Optimization
  optimizer: adamw
  weight_decay: 0.01
  max_grad_norm: 1.0
  
  # Mixed precision
  fp16: true
  
  # Checkpointing
  save_strategy: best
  save_total_limit: 3
  metric_for_best_model: f1_macro
  
  # Early stopping
  early_stopping: true
  early_stopping_patience: 5

# Evaluation
evaluation:
  # Metrics
  metrics:
    - accuracy
    - f1_macro
    - teacher_agreement  # Agreement with GPT-4
    - rationale_quality
    
  # Teacher agreement analysis
  teacher_agreement:
    compute_agreement: true
    agreement_threshold: 0.9
    
  # Rationale evaluation
  rationale_eval:
    enabled: true
    metrics:
      - bleu
      - rouge
      - semantic_similarity
      - factual_consistency
      
  # Cost-benefit analysis
  cost_analysis:
    compute_cost_reduction: true
    inference_speedup: true
    
  # Ablation studies
  ablation:
    without_rationales: true
    without_soft_labels: true
    different_temperatures: [1, 3, 5, 7]

# Efficiency Optimizations
efficiency:
  # Batch API calls
  batch_api_calls: true
  batch_size: 10
  
  # Async processing
  async_processing: true
  num_workers: 4
  
  # Response caching
  cache_responses: true
  cache_ttl: 86400  # 24 hours
  
  # Model optimization
  optimize_student:
    quantization: false
    pruning: false
    distillation_aware_training: true

# Cost Management
cost_management:
  # Budget limits
  max_api_cost: 100.0  # USD
  cost_per_1k_tokens: 0.03
  
  # Cost optimization
  optimization:
    use_gpt35_for_easy: true  # Use cheaper model for easy samples
    sample_prioritization: true
    
  # Monitoring
  track_costs: true
  alert_threshold: 80.0  # Alert at 80% budget

# Debugging and Analysis
debugging:
  # Sample logging
  log_sample_predictions: true
  num_samples_to_log: 20
  
  # GPT-4 response analysis
  analyze_gpt4_responses: true
  save_all_responses: false
  
  # Disagreement analysis
  analyze_disagreements: true
  save_disagreement_cases: true
  
  # Rationale analysis
  analyze_rationale_quality: true
  rationale_diversity: true
  
  # Visualization
  plot_confidence_distribution: true
  plot_agreement_matrix: true

# Notes
notes: |
  GPT-4 Distillation Configuration for AG News:
  
  Key strategies:
  1. Progressive distillation with temperature scheduling
  2. Chain-of-thought reasoning extraction
  3. Active learning for efficient labeling
  4. Multi-stage training with rationales
  
  Expected benefits:
  - 90%+ of GPT-4 performance
  - 100x faster inference
  - 10x smaller model size
  - Interpretable predictions with rationales
  
  Cost optimization:
  - Cache all GPT-4 responses
  - Use uncertainty sampling
  - Batch API calls
  - Progressive labeling
  
  Best practices:
  - Start with high temperature (T=5)
  - Use diverse prompts for robustness
  - Filter low-quality rationales
  - Monitor teacher-student agreement
  
  Common issues:
  - API rate limits: Implement proper throttling
  - Cost overruns: Set strict budgets
  - Rationale quality: Use self-consistency
  - Distribution shift: Regular validation
