{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Vision Transformers in PyTorch\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "dataset_path = './images_dataSAT/'\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Create train_transform transforms for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Create train_transform\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(degrees=45),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Training transformation pipeline created:\")\n",
    "print(train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Create val_transform transforms for the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Create val_transform\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Validation transformation pipeline created:\")\n",
    "print(val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Create the Dataloader train_loader and val_loader using train_dataset and val_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Create DataLoaders\n",
    "\n",
    "# Load datasets with respective transforms\n",
    "train_dataset_full = datasets.ImageFolder(root=dataset_path, transform=train_transform)\n",
    "val_dataset_full = datasets.ImageFolder(root=dataset_path, transform=val_transform)\n",
    "\n",
    "# Split indices\n",
    "total_size = len(train_dataset_full)\n",
    "val_size = int(0.2 * total_size)\n",
    "train_size = total_size - val_size\n",
    "\n",
    "# Generate consistent split indices\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_indices, val_indices = random_split(range(total_size), [train_size, val_size], generator=generator)\n",
    "\n",
    "# Create subsets\n",
    "train_dataset = torch.utils.data.Subset(train_dataset_full, train_indices.indices)\n",
    "val_dataset = torch.utils.data.Subset(val_dataset_full, val_indices.indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Classes: {train_dataset_full.classes}\")\n",
    "print(f\"Class to idx: {train_dataset_full.class_to_idx}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "\n",
    "# Verify a batch\n",
    "sample_images, sample_labels = next(iter(train_loader))\n",
    "print(f\"\\nSample batch - Images shape: {sample_images.shape}, Labels shape: {sample_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Define CNN Feature Extractor\n",
    "# ============================================================\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # Block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # Block 4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "print(\"CNNFeatureExtractor defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Define Transformer Encoder Block\n",
    "# ============================================================\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dim, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Self-Attention with residual\n",
    "        x_norm = self.norm1(x)\n",
    "        attn_out, _ = self.attn(x_norm, x_norm, x_norm)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        # MLP with residual\n",
    "        x_norm = self.norm2(x)\n",
    "        x = x + self.mlp(x_norm)\n",
    "        return x\n",
    "\n",
    "print(\"TransformerEncoderBlock defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Define CNN-ViT Hybrid Model\n",
    "# ============================================================\n",
    "class CNNViTHybrid(nn.Module):\n",
    "    def __init__(self, num_classes=2, embed_dim=64, num_heads=4, \n",
    "                 depth=4, mlp_dim=128, dropout=0.1):\n",
    "        super(CNNViTHybrid, self).__init__()\n",
    "        \n",
    "        # CNN Feature Extractor\n",
    "        self.cnn = CNNFeatureExtractor()\n",
    "        \n",
    "        # After CNN: (batch, 256, 4, 4) -> seq_length=16, feature_dim=256\n",
    "        self.seq_length = 4 * 4  # 16\n",
    "        self.cnn_feature_dim = 256\n",
    "        \n",
    "        # Linear projection\n",
    "        self.projection = nn.Linear(self.cnn_feature_dim, embed_dim)\n",
    "        \n",
    "        # Positional embedding\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.seq_length, embed_dim))\n",
    "        self.pos_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Transformer encoder blocks\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlock(embed_dim, num_heads, mlp_dim, dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "        # Final normalization\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # CNN features: (batch, 256, 4, 4)\n",
    "        x = self.cnn(x)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Reshape: (batch, 256, 4, 4) -> (batch, 16, 256)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        \n",
    "        # Project to embed_dim: (batch, 16, embed_dim)\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        # Add positional embedding\n",
    "        x = x + self.pos_embedding\n",
    "        x = self.pos_dropout(x)\n",
    "        \n",
    "        # Transformer blocks\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Normalize\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # Global average pooling: (batch, embed_dim)\n",
    "        x = x.mean(dim=1)\n",
    "        \n",
    "        # Classify\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "print(\"CNNViTHybrid model defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Define training function\n",
    "# ============================================================\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                epochs, device, model_name='model'):\n",
    "    \"\"\"\n",
    "    Train the model and return training history and total training time.\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': [],\n",
    "        'epoch_times': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # ===== Training =====\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_bar = tqdm(train_loader, desc=f'{model_name} Epoch {epoch+1}/{epochs} [Train]')\n",
    "        for images, labels in train_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_bar.set_postfix(loss=loss.item(), acc=train_correct/train_total)\n",
    "        \n",
    "        epoch_train_loss = train_loss / len(train_loader)\n",
    "        epoch_train_acc = train_correct / train_total\n",
    "        \n",
    "        # ===== Validation =====\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_val_loss = val_loss / len(val_loader)\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        history['epoch_times'].append(epoch_time)\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), f'best_{model_name}.pth')\n",
    "        \n",
    "        print(f'{model_name} Epoch {epoch+1}/{epochs} - '\n",
    "              f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f} | '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f} | '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "    \n",
    "    total_time = time.time() - total_start_time\n",
    "    history['total_time'] = total_time\n",
    "    \n",
    "    print(f\"\\n{model_name} Training completed! Total time: {total_time:.2f}s\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"Training function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Train Model 1 (baseline): smaller ViT\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"Training Model 1 (Baseline CNN-ViT)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model 1: Baseline with smaller hyperparameters\n",
    "model = CNNViTHybrid(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    embed_dim=64,\n",
    "    num_heads=4,\n",
    "    depth=4,\n",
    "    mlp_dim=128,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"Model 1 parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  embed_dim=64, num_heads=4, depth=4, mlp_dim=128\")\n",
    "\n",
    "# Train for 5 epochs\n",
    "history_model = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer,\n",
    "    epochs=5, device=device, model_name='model'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Design and train a CNN-ViT hybrid model model_test with the following hyperparameters: epochs=5, mlp_heads=12, embed_dim=768, transformer block depth=12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Train model_test with specified hyperparameters\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Model Test (Larger CNN-ViT)\")\n",
    "print(\"  epochs=5, mlp_heads(num_heads)=12, embed_dim=768, depth=12\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_test = CNNViTHybrid(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    embed_dim=768,\n",
    "    num_heads=12,\n",
    "    depth=12,\n",
    "    mlp_dim=3072,   # typically 4x embed_dim for ViT-Base\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "criterion_test = nn.CrossEntropyLoss()\n",
    "optimizer_test = optim.Adam(model_test.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"Model Test parameters: {sum(p.numel() for p in model_test.parameters()):,}\")\n",
    "print(f\"  embed_dim=768, num_heads=12, depth=12, mlp_dim=3072\")\n",
    "print()\n",
    "\n",
    "# Train for 5 epochs\n",
    "history_model_test = train_model(\n",
    "    model_test, train_loader, val_loader, criterion_test, optimizer_test,\n",
    "    epochs=5, device=device, model_name='model_test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Compare the performance of model with model_test by plotting the validation loss for model and model_test ViTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Compare validation loss\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "epochs_range = range(1, 6)\n",
    "\n",
    "# Plot 1: Validation Loss Comparison\n",
    "axes[0].plot(epochs_range, history_model['val_loss'], \n",
    "             label='Model (Baseline)', color='blue', linewidth=2, marker='o', markersize=6)\n",
    "axes[0].plot(epochs_range, history_model_test['val_loss'], \n",
    "             label='Model Test (Large)', color='red', linewidth=2, marker='s', markersize=6)\n",
    "axes[0].set_title('Validation Loss Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Validation Loss', fontsize=12)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(list(epochs_range))\n",
    "\n",
    "# Plot 2: Validation Accuracy Comparison\n",
    "axes[1].plot(epochs_range, history_model['val_acc'], \n",
    "             label='Model (Baseline)', color='blue', linewidth=2, marker='o', markersize=6)\n",
    "axes[1].plot(epochs_range, history_model_test['val_acc'], \n",
    "             label='Model Test (Large)', color='red', linewidth=2, marker='s', markersize=6)\n",
    "axes[1].set_title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Validation Accuracy', fontsize=12)\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(list(epochs_range))\n",
    "\n",
    "plt.suptitle('Model vs Model Test: Performance Comparison', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison table\n",
    "print(\"\\nPerformance Comparison Summary:\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"{'Metric':<25} {'Model (Baseline)':>18} {'Model Test (Large)':>18}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Best Val Loss':<25} {min(history_model['val_loss']):>18.4f} {min(history_model_test['val_loss']):>18.4f}\")\n",
    "print(f\"{'Best Val Accuracy':<25} {max(history_model['val_acc']):>18.4f} {max(history_model_test['val_acc']):>18.4f}\")\n",
    "print(f\"{'Final Val Loss':<25} {history_model['val_loss'][-1]:>18.4f} {history_model_test['val_loss'][-1]:>18.4f}\")\n",
    "print(f\"{'Final Val Accuracy':<25} {history_model['val_acc'][-1]:>18.4f} {history_model_test['val_acc'][-1]:>18.4f}\")\n",
    "print(f\"{'Total Parameters':<25} {sum(p.numel() for p in model.parameters()):>18,} {sum(p.numel() for p in model_test.parameters()):>18,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Compare the training times of model with model_test by plotting the training time for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: Compare training times\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Per-Epoch Training Time\n",
    "axes[0].plot(epochs_range, history_model['epoch_times'], \n",
    "             label='Model (Baseline)', color='blue', linewidth=2, marker='o', markersize=6)\n",
    "axes[0].plot(epochs_range, history_model_test['epoch_times'], \n",
    "             label='Model Test (Large)', color='red', linewidth=2, marker='s', markersize=6)\n",
    "axes[0].set_title('Per-Epoch Training Time', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Time (seconds)', fontsize=12)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(list(epochs_range))\n",
    "\n",
    "# Plot 2: Total Training Time Bar Chart\n",
    "model_names = ['Model\\n(Baseline)', 'Model Test\\n(Large)']\n",
    "total_times = [history_model['total_time'], history_model_test['total_time']]\n",
    "colors = ['steelblue', 'coral']\n",
    "\n",
    "bars = axes[1].bar(model_names, total_times, color=colors, width=0.5, edgecolor='black')\n",
    "axes[1].set_title('Total Training Time Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Total Time (seconds)', fontsize=12)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, t in zip(bars, total_times):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
    "                 f'{t:.2f}s', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Model vs Model Test: Training Time Comparison', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print timing summary\n",
    "print(\"\\nTraining Time Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Metric':<30} {'Model':>12} {'Model Test':>12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Total Training Time (s)':<30} {history_model['total_time']:>12.2f} {history_model_test['total_time']:>12.2f}\")\n",
    "print(f\"{'Avg Epoch Time (s)':<30} {np.mean(history_model['epoch_times']):>12.2f} {np.mean(history_model_test['epoch_times']):>12.2f}\")\n",
    "print(f\"{'Min Epoch Time (s)':<30} {min(history_model['epoch_times']):>12.2f} {min(history_model_test['epoch_times']):>12.2f}\")\n",
    "print(f\"{'Max Epoch Time (s)':<30} {max(history_model['epoch_times']):>12.2f} {max(history_model_test['epoch_times']):>12.2f}\")\n",
    "\n",
    "speedup = history_model_test['total_time'] / history_model['total_time']\n",
    "print(f\"\\nModel Test is {speedup:.2f}x {'slower' if speedup > 1 else 'faster'} than baseline Model.\")\n",
    "print(f\"Model Test has {sum(p.numel() for p in model_test.parameters()) / sum(p.numel() for p in model.parameters()):.1f}x more parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both models for use in Question 9\n",
    "torch.save(model.state_dict(), 'best_model.pth')\n",
    "torch.save(model_test.state_dict(), 'best_model_test.pth')\n",
    "print(\"Both models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## All 6 tasks completed successfully."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
