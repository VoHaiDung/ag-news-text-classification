# AG News Text Classification

<div align="center">

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/ðŸ¤—_Transformers-4.30+-yellow.svg)](https://huggingface.co/transformers/)
[![arXiv](https://img.shields.io/badge/arXiv-2025.xxxxx-b31b1b.svg)](https://arxiv.org/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

</div>

# Introduction

## 1.1 Research Motivation and Context

Text classification constitutes one of the fundamental tasks in natural language processing, serving as a cornerstone for applications ranging from sentiment analysis and spam detection to news categorization and intent recognition. The task is formally defined as learning a mapping function from a document space to a discrete set of predefined categories, where the objective is to minimize prediction error on unseen examples drawn from the same underlying distribution as the training data.

Over the past decade, the field has witnessed a paradigm shift from feature-engineering approaches based on bag-of-words representations and classical machine learning algorithms, to end-to-end neural architectures that learn hierarchical representations directly from raw text. The introduction of attention mechanisms and pre-trained transformer models has further revolutionized the landscape, enabling competitive accuracy on benchmark datasets through transfer learning from massive unsupervised corpora.

Despite these advances, a fundamental tension persists between the capacity of modern neural architectures and the size of available labeled datasets. Contemporary state-of-the-art models such as BERT, RoBERTa, DeBERTa, and large language models like LLaMA and Mistral contain parameters numbering in the hundreds of millions to tens of billions, while supervised classification datasets typically provide only thousands to hundreds of thousands of labeled examples. This disparity creates a severe risk of overfitting, where models achieve near-perfect accuracy on training data yet fail to generalize to held-out test sets.

This project addresses the challenge of developing text classification systems that achieve competitive accuracy while maintaining rigorous generalization guarantees. We focus specifically on the AG News dataset as an experimental testbedâ€”not because it represents the frontier of difficulty in modern NLP, but precisely because its moderate size and balanced structure provide an ideal controlled environment for studying the interplay between model capacity, training methodology, and generalization performance. The complete dataset characteristics and experimental protocols are detailed in [Dataset](#dataset).

## 1.2 The Generalization Challenge in Modern NLP

The core theoretical challenge in supervised machine learning is the minimization of expected risk, defined over an unknown data distribution. Let us denote the input space of text documents as $\mathcal{X}$ and the output space of class labels as $\mathcal{Y}$. Given a training dataset $\mathcal{D}$ consisting of $N$ independently and identically distributed samples:

$$\mathcal{D} = \{(x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N)\}$$

where each pair $(x_i, y_i)$ is drawn from an unknown joint distribution $P$ over $\mathcal{X} \times \mathcal{Y}$, the learning objective is to find a function $f: \mathcal{X} \rightarrow \mathcal{Y}$ that minimizes the expected risk:

$$R(f) = \mathbb{E}_{(x,y) \sim P}[\ell(f(x), y)]$$

Here, $\ell$ denotes a loss function quantifying the penalty for incorrect predictions. For classification tasks, this is commonly the zero-one loss, which equals one when the prediction differs from the true label and zero otherwise.

Since the true distribution $P$ is unknown and inaccessible, practical learning algorithms instead minimize the empirical risk computed on the observed training data:

$$R_{\text{emp}}(f) = \frac{1}{N} \sum_{i=1}^{N} \ell(f(x_i), y_i)$$

The fundamental question is whether a function $f$ that achieves low empirical risk will also achieve low expected risk on new, unseen examples. The difference between these two quantities is termed the **generalization gap**:

$$\Delta(f) = R(f) - R_{\text{emp}}(f)$$

This generalization gap represents the core challenge addressed throughout this framework. When $\Delta(f)$ is large, the model has overfit to the training data and will perform poorly on new examples despite excellent training accuracy.

Statistical learning theory provides bounds on this generalization gap. According to the Vapnik-Chervonenkis theory, with probability at least $1 - \delta$, the true risk is bounded by:

$$R(f) \leq R_{\text{emp}}(f) + \sqrt{\frac{d \log(2N/d) + \log(4/\delta)}{N}}$$

where $d$ represents the VC dimension, a measure of the model's capacity or expressiveness. 

**Interpreting this bound**: The inequality reveals a fundamental trade-off. The first term $R_{\text{emp}}(f)$ decreases as we use more expressive models with higher capacity (larger $d$), since such models can fit the training data better. However, the second termâ€”the generalization gapâ€”increases with model capacity $d$ and decreases with dataset size $N$. Models with high capacity can achieve low empirical risk but may suffer from a large generalization gap. Conversely, models with limited capacity have tighter generalization bounds but may be unable to capture the true underlying patterns, leading to high bias. The optimal model complexity minimizes the sum of both terms.

In the context of modern transformer-based language models, the effective capacity is enormous. For instance, DeBERTa-v3-XLarge contains approximately 710 million parameters, while the AG News training set provides 120,000 labeled examples. This yields a parameter-to-sample ratio of approximately 5,917:1, meaning each parameter is informed by fewer than 0.0002 training samples on average. Classical statistical learning theory would suggest that such models should catastrophically overfit, memorizing training examples without learning generalizable patterns.

However, empirical practice demonstrates that careful application of several techniques can mitigate this overfitting risk:

- **Transfer Learning**: Pre-training on large unsupervised corpora allows models to learn general linguistic representations before fine-tuning on task-specific data. This effectively reduces the number of parameters that must be learned from the supervised dataset alone, as discussed in [Section 1.6.2](#162-transfer-learning-and-pre-training).

- **Parameter-Efficient Fine-Tuning**: Methods such as Low-Rank Adaptation (LoRA) and Quantized LoRA (QLoRA) constrain the fine-tuning process to modify only a small subset of model parameters, dramatically reducing effective capacity. Theoretical foundations are provided in [Section 1.6.3](#163-parameter-efficient-fine-tuning-theory).

- **Regularization**: Techniques including dropout, weight decay, and early stopping impose explicit or implicit penalties on model complexity, encouraging simpler solutions that generalize better. Our regularization strategies are detailed in [configs/training/regularization/](./configs/training/regularization/).

- **Ensemble Methods**: Combining predictions from multiple diverse models reduces variance and improves robustness, even when individual models may overfit. The theoretical basis is explained in [Section 1.6.4](#164-ensemble-methods-and-diversity).

- **Knowledge Distillation**: Training smaller student models to mimic the behavior of larger teacher models or ensembles preserves much of the performance gain while reducing inference cost and overfitting risk, as detailed in [Section 1.6.5](#165-knowledge-distillation).

The challenge addressed by this project is to systematically combine these techniques within a unified framework that treats overfitting prevention not as an afterthought, but as a primary architectural consideration from the outset. The complete overfitting prevention architecture is documented in [OVERFITTING_PREVENTION.md](./OVERFITTING_PREVENTION.md).

## 1.3 Bridging Theory and Practice

A significant gap exists in the current landscape between theoretical understanding of generalization and practical implementation of text classification systems. Research papers often present novel architectures or training techniques with impressive benchmark results, yet the code repositories accompanying these papers frequently lack the infrastructure necessary to ensure that these results are reliable, reproducible, and generalizable.

Common issues include:

- **Inadequate Validation Protocols**: Using a single train-test split without proper validation set management, leading to potential overfitting to the validation set through repeated hyperparameter tuning.

- **Test Set Contamination**: Inadvertent exposure of test set information during development, such as through exploratory data analysis, error analysis on test samples, or repeated evaluation during model selection.

- **Unreported Hyperparameter Sensitivity**: Publishing results from a single random seed or configuration without acknowledging variance across runs, making results difficult to reproduce.

- **Platform-Specific Assumptions**: Code that assumes access to specific computational infrastructure (multi-GPU clusters, high-memory machines, fast storage) that is not available to many researchers and practitioners.

- **Lack of Systematic Overfitting Detection**: Relying on manual inspection of learning curves rather than automated monitoring systems that can detect subtle signs of overfitting early in training.

This project seeks to bridge this gap by providing not merely a collection of high-performing models, but a complete experimental framework that embeds best practices for generalization into every component of the system. The overfitting prevention mechanisms described in detail in [OVERFITTING_PREVENTION.md](./OVERFITTING_PREVENTION.md) are not separate modules to be optionally enabled, but rather integral parts of the training pipeline that operate by default.

Furthermore, we recognize that reproducibility requires more than fixing random seeds. It requires comprehensive logging of the complete experimental environment, including hardware specifications, software versions, data preprocessing steps, and the full hyperparameter configuration. It requires statistical rigor in comparing models, using multiple random seeds and appropriate significance testing. And it requires transparent reporting of all results, including negative results and failed experiments, to provide an honest assessment of what approaches work and under what conditions.

Our implementation of these principles includes:

- **Automated Environment Logging**: Capture of hardware specifications, CUDA versions, library versions, and platform characteristics. See [src/utils/experiment_tracking.py](./src/utils/experiment_tracking.py).

- **Multi-Seed Evaluation**: All reported results average over at least 3-5 random seeds with standard deviations. Configuration templates in [configs/experiments/reproducibility/](./configs/experiments/reproducibility/).

- **Statistical Significance Testing**: Paired t-tests with Bonferroni correction for comparing multiple models. Implementation in [src/evaluation/metrics/](./src/evaluation/metrics/).

- **Comprehensive Experiment Tracking**: Integration with TensorBoard, MLflow, and Weights & Biases for complete audit trails. Setup guides in [LOCAL_MONITORING_GUIDE.md](./LOCAL_MONITORING_GUIDE.md).

## 1.4 Research Gaps and Motivations

Through extensive review of existing text classification implementations and research codebases, we have identified several specific gaps that motivated the design decisions in this project.

### 1.4.1 Post-Hoc Versus Preventive Overfitting Management

**Current Practice**: The typical workflow in developing text classification systems treats overfitting as a problem to be diagnosed after it occurs. Researchers train models, observe divergence between training and validation metrics, and then apply corrective measures such as increasing regularization strength, reducing model capacity, or implementing early stopping.

**Limitation**: This reactive approach has several drawbacks. First, it wastes computational resources by allowing training to proceed even when the configuration is almost certain to overfit. Second, it creates opportunities for inadvertent test set leakage, as researchers may be tempted to check test performance to gauge whether their overfitting mitigation strategies are working. Third, it lacks systematic principles for determining appropriate hyperparameter values, leading to ad-hoc choices that may not generalize across different datasets or model architectures.

**Our Approach**: We implement a preventive overfitting management system that operates at multiple stages:

1. **Pre-Training Validation**: Before any GPU computation begins, the system analyzes the proposed configuration against a set of constraint rules based on dataset size, model capacity, and historical performance patterns. Configurations likely to result in severe overfitting are rejected with explanatory messages and recommended alternatives. Implementation in [src/core/overfitting_prevention/validators/](./src/core/overfitting_prevention/validators/).

2. **Real-Time Monitoring**: During training, multiple metrics are tracked to detect early warning signs of overfitting, including the train-validation gap in both loss and accuracy, the rate of change in these metrics, gradient magnitudes, and parameter norms. When predefined thresholds are exceeded, training can be automatically halted with diagnostic information. See [src/core/overfitting_prevention/monitors/](./src/core/overfitting_prevention/monitors/).

3. **Post-Training Analysis**: After training completes, comprehensive overfitting risk scores are computed based on multiple factors, and detailed reports are generated comparing the observed behavior to expected patterns for the given configuration. Report generation in [src/core/overfitting_prevention/reporting/](./src/core/overfitting_prevention/reporting/).

The theoretical foundations and implementation details of this system are described in [OVERFITTING_PREVENTION.md](./OVERFITTING_PREVENTION.md), while this document focuses on the high-level rationale and integration with the overall experimental workflow.

### 1.4.2 Fragmented State-of-the-Art Techniques

**Current Practice**: Achieving competitive results on text classification benchmarks increasingly requires combining multiple advanced techniques: large pre-trained transformers, parameter-efficient fine-tuning methods, ensemble approaches, and knowledge distillation. However, these techniques are often developed and published in separate research efforts, with implementations residing in different codebases using incompatible interfaces.

**Limitation**: A researcher wishing to reproduce state-of-the-art results must manually integrate code from multiple sources, resolve dependency conflicts, adapt to different configuration formats, and navigate undocumented assumptions about data formats and training procedures. This integration burden is particularly challenging for researchers who are domain experts but not deep learning engineers.

**Our Approach**: We provide a unified model zoo spanning classical baselines to large language models, with consistent interfaces and composable configurations. The system is organized into tiers that represent different points in the accuracy-efficiency trade-off space:

- **Tier 1 - Classical Baselines**: Traditional machine learning approaches including Naive Bayes, Support Vector Machines, and Logistic Regression, serving as sanity checks and computational efficiency baselines. Implementations in [experiments/baselines/classical/](./experiments/baselines/classical/).

- **Tier 2 - Standard Transformers**: Full fine-tuning of models like BERT-Base and RoBERTa-Base, establishing the performance ceiling for conventional approaches. Configurations in [configs/models/single/transformers/](./configs/models/single/transformers/).

- **Tier 3 - Large Transformers with PEFT**: Models such as DeBERTa-v3-XLarge and DeBERTa-v2-XXLarge fine-tuned using Low-Rank Adaptation, demonstrating parameter-efficient scaling to larger architectures. Configurations in [configs/models/recommended/tier_1_sota/](./configs/models/recommended/tier_1_sota/).

- **Tier 4 - Large Language Models**: Instruction-tuned models like LLaMA 2 and Mistral fine-tuned with Quantized LoRA, representing the current frontier in transfer learning. Configurations in [configs/models/recommended/tier_2_llm/](./configs/models/recommended/tier_2_llm/).

- **Tier 5 - Ensembles and Distillation**: Multi-model ensembles achieving maximum accuracy, and distilled student models that compress ensemble knowledge into efficient single-model architectures. Configurations in [configs/models/recommended/tier_3_ensemble/](./configs/models/recommended/tier_3_ensemble/) and [configs/models/recommended/tier_4_distilled/](./configs/models/recommended/tier_4_distilled/).

Detailed guidance on selecting appropriate models for different use cases is provided in [SOTA_MODELS_GUIDE.md](./SOTA_MODELS_GUIDE.md), while the system architecture enabling this modularity is documented in [ARCHITECTURE.md](./ARCHITECTURE.md).

### 1.4.3 Platform Dependence and Accessibility Barriers

**Current Practice**: Much academic research in NLP assumes access to substantial computational resources, such as multi-GPU clusters with high-bandwidth interconnects, large amounts of RAM, and fast persistent storage. Code is often optimized for specific environments like institutional SLURM clusters or cloud platforms with particular instance types.

**Limitation**: This creates significant barriers for independent researchers, students, and practitioners in resource-constrained settings. Even when pre-trained models are publicly available, fine-tuning them on custom datasets may be infeasible without access to expensive infrastructure. Furthermore, differences in hardware and software configurations across platforms frequently lead to reproducibility failures, where code that runs successfully in one environment produces errors or different results in another.

**Our Approach**: We adopt a platform-agnostic design that automatically adapts to available computational resources:

1. **Automatic Platform Detection**: The system identifies the execution environment at runtime (Google Colab, Kaggle Notebooks, local CPU, local GPU, etc.) and loads appropriate configuration defaults. Implementation in [src/deployment/platform_detector.py](./src/deployment/platform_detector.py).

2. **Resource-Aware Model Selection**: Based on detected GPU memory, CPU count, and time quotas, the system recommends models and training configurations that will complete within available resources. Decision logic in [src/deployment/smart_selector.py](./src/deployment/smart_selector.py).

3. **Checkpoint Resilience**: Training state is periodically synchronized to persistent storage (Google Drive for Colab, Kaggle Datasets for Kaggle) so that sessions interrupted due to platform time limits can be seamlessly resumed. Implementation in [src/deployment/checkpoint_manager.py](./src/deployment/checkpoint_manager.py).

4. **Quota Management**: For platforms with usage limits (Colab's 12-hour sessions, Kaggle's weekly GPU quotas), the system tracks consumption and optimizes checkpoint intervals to maximize effective training time. Quota tracking in [src/deployment/quota_tracker.py](./src/deployment/quota_tracker.py).

The platform adaptation mechanisms are detailed in [PLATFORM_OPTIMIZATION_GUIDE.md](./PLATFORM_OPTIMIZATION_GUIDE.md), while platform-specific configurations are available in [configs/environments/](./configs/environments/) and [configs/training/platform_adaptive/](./configs/training/platform_adaptive/).

### 1.4.4 Test Set Integrity and Experimental Validity

**Current Practice**: In many machine learning projects, the test set is treated as merely another data split, stored in the same directory structure as training and validation data and accessible to all code components. Researchers manually ensure that test data is not used during development, relying on discipline rather than technical safeguards.

**Limitation**: Human error and the iterative nature of machine learning experimentation make test set leakage a persistent risk. Subtle forms of leakage can occur through:

- **Direct leakage**: Accidentally including test samples in training batches due to indexing errors or incorrect data split logic.

- **Indirect leakage**: Making modeling decisions (feature selection, architecture choices, hyperparameter ranges) based on test set characteristics observed during exploratory analysis.

- **Adaptive leakage**: Trying multiple models or configurations and selecting based on test performance, effectively overfitting to the test set through the model selection process itself.

- **Preprocessing leakage**: Computing normalization statistics, vocabulary mappings, or other preprocessing parameters on the full dataset including test samples, then applying these to create test features.

**Our Approach**: We implement cryptographic test set protection mechanisms:

1. **Hash-Based Integrity**: Upon first loading the test set, a SHA-256 hash is computed over the sorted sample identifiers and stored in a protected file at [data/processed/.test_set_hash](./data/processed/.test_set_hash). Every subsequent test evaluation verifies that the hash matches, detecting any modification or corruption of the test set. Implementation in [src/core/overfitting_prevention/utils/hash_utils.py](./src/core/overfitting_prevention/utils/hash_utils.py).

2. **Access Logging**: All code paths that access test data are instrumented to log the timestamp, calling function, purpose statement, and stack trace to [data/test_access_log.json](./data/test_access_log.json). This creates an auditable record of test set usage. Implementation in [src/core/overfitting_prevention/guards/test_set_guard.py](./src/core/overfitting_prevention/guards/test_set_guard.py).

3. **Access Control**: The test set loader requires explicit authorization through configuration flags. By default, attempting to load test data during training or hyperparameter tuning raises an exception. Guard implementation in [src/core/overfitting_prevention/guards/access_control.py](./src/core/overfitting_prevention/guards/access_control.py).

4. **Budget Enforcement**: A configurable limit on the number of test evaluations prevents adaptive overfitting through repeated model selection based on test performance. Configuration in [configs/overfitting_prevention/validation/test_set_protection.yaml](./configs/overfitting_prevention/validation/test_set_protection.yaml).

These mechanisms, described in detail in [OVERFITTING_PREVENTION.md Â§ Test Set Protection](./OVERFITTING_PREVENTION.md), provide technical enforcement of best practices that would otherwise rely solely on researcher discipline.

## 1.5 Core Contributions

This project makes several specific contributions to the practice of text classification:

### 1. Comprehensive Overfitting Prevention Framework

We provide a multi-layered system for preventing, detecting, and diagnosing overfitting that operates throughout the experimental lifecycle. This includes pre-training configuration validation, real-time monitoring during training, post-training risk assessment, and test set protection mechanisms. The system is designed to be both technically rigorousâ€”implementing ideas from statistical learning theory and adaptive data analysisâ€”and practically usable, with clear error messages and actionable recommendations.

Key components:

- Pre-training validators in [src/core/overfitting_prevention/validators/](./src/core/overfitting_prevention/validators/)
- Real-time monitors in [src/core/overfitting_prevention/monitors/](./src/core/overfitting_prevention/monitors/)
- Constraint enforcers in [src/core/overfitting_prevention/constraints/](./src/core/overfitting_prevention/constraints/)
- Test set guards in [src/core/overfitting_prevention/guards/](./src/core/overfitting_prevention/guards/)
- Automated recommenders in [src/core/overfitting_prevention/recommendations/](./src/core/overfitting_prevention/recommendations/)

Complete documentation in [OVERFITTING_PREVENTION.md](./OVERFITTING_PREVENTION.md).

### 2. Unified Parameter-Efficient Fine-Tuning Infrastructure

We integrate multiple PEFT methods (LoRA, QLoRA, Adapters, Prefix Tuning, Prompt Tuning) within a consistent interface, enabling fair comparisons and hybrid approaches. Extensive hyperparameter search results for LoRA rank selection, target module choices, and regularization strategies are provided to guide users toward configurations that balance accuracy and efficiency for the AG News dataset.

Implementations:

- LoRA: [src/models/efficient/lora/](./src/models/efficient/lora/)
- QLoRA: [src/models/efficient/qlora/](./src/models/efficient/qlora/)
- Adapters: [src/models/efficient/adapters/](./src/models/efficient/adapters/)
- Prefix Tuning: [src/models/efficient/prefix_tuning/](./src/models/efficient/prefix_tuning/)
- Prompt Tuning: [src/models/efficient/prompt_tuning/](./src/models/efficient/prompt_tuning/)

Configuration templates in [configs/training/efficient/](./configs/training/efficient/) and ablation studies in [experiments/ablation_studies/](./experiments/ablation_studies/).

### 3. Multi-Stage SOTA Pipeline

We demonstrate a systematic progression from individual high-capacity models through ensemble aggregation to knowledge distillation, achieving competitive accuracy while maintaining interpretability and deployability. Each stage is fully reproducible with provided configurations and scripts, and ablation studies isolate the contribution of each component.

Pipeline stages:

- Phase 1: XLarge model training with LoRA - [experiments/sota_experiments/phase1_xlarge_lora.py](./experiments/sota_experiments/phase1_xlarge_lora.py)
- Phase 2: LLM fine-tuning with QLoRA - [experiments/sota_experiments/phase2_llm_qlora.py](./experiments/sota_experiments/phase2_llm_qlora.py)
- Phase 3: Knowledge distillation - [experiments/sota_experiments/phase3_llm_distillation.py](./experiments/sota_experiments/phase3_llm_distillation.py)
- Phase 4: Ensemble aggregation - [experiments/sota_experiments/phase4_ensemble_xlarge.py](./experiments/sota_experiments/phase4_ensemble_xlarge.py)
- Phase 5: Ultimate SOTA - [experiments/sota_experiments/phase5_ultimate_sota.py](./experiments/sota_experiments/phase5_ultimate_sota.py)

Complete pipeline guide in [SOTA_MODELS_GUIDE.md](./SOTA_MODELS_GUIDE.md).

### 4. Platform-Agnostic Reproducibility

Through automatic platform detection, resource-aware configuration selection, and comprehensive environment logging, we ensure that experiments can be reproduced across diverse computational environments. This includes consumer laptops, cloud platforms (Google Colab, Kaggle Notebooks), and institutional compute clusters.

Platform support:

- Detection system: [src/deployment/platform_detector.py](./src/deployment/platform_detector.py)
- Smart configuration selection: [src/deployment/smart_selector.py](./src/deployment/smart_selector.py)
- Platform-specific configs: [configs/environments/](./configs/environments/)
- Colab optimization: [configs/training/platform_adaptive/colab_free_training.yaml](./configs/training/platform_adaptive/colab_free_training.yaml)
- Kaggle optimization: [configs/training/platform_adaptive/kaggle_gpu_training.yaml](./configs/training/platform_adaptive/kaggle_gpu_training.yaml)

Platform guide in [PLATFORM_OPTIMIZATION_GUIDE.md](./PLATFORM_OPTIMIZATION_GUIDE.md).

### 5. Extensive Documentation and Educational Resources

Beyond this technical README, we provide detailed guides targeted at different user expertise levels:

- **Beginners**: Step-by-step tutorials covering basic concepts and common workflows in [docs/level_1_beginner/](./docs/level_1_beginner/)
- **Practitioners**: Best practice guides for model selection, hyperparameter tuning, and deployment in [docs/best_practices/](./docs/best_practices/)
- **Researchers**: In-depth theoretical treatments of overfitting prevention, ensemble methods, and distillation in [OVERFITTING_PREVENTION.md](./OVERFITTING_PREVENTION.md) and [ARCHITECTURE.md](./ARCHITECTURE.md)
- **Developers**: API documentation and architecture descriptions for extending the codebase in [docs/developer_guide/](./docs/developer_guide/) and [docs/api_reference/](./docs/api_reference/)

This progressive disclosure approach allows users to engage with the system at a level appropriate to their background and goals. Complete navigation guide in [Section 1.8](#18-organization-of-documentation).

## 1.6 Theoretical Foundations: Overview

This section provides a high-level overview of the theoretical principles underlying our implementation. Detailed mathematical treatments, proofs, and empirical validations are provided in specialized documentation referenced below.

### 1.6.1 Statistical Learning Theory and Capacity Control

The fundamental question in supervised learning is how well a model trained on finite data will perform on new examples. Statistical learning theory, particularly the Vapnik-Chervonenkis framework, provides rigorous bounds on generalization error as a function of model capacity and sample size.

For a hypothesis space with VC dimension $d$, the generalization bound states that with probability at least $1 - \delta$, the true risk $R(f)$ of any hypothesis $f$ is bounded by:

$$R(f) \leq R_{\text{emp}}(f) + \sqrt{\frac{d \log(2N/d) + \log(4/\delta)}{N}}$$

where:

- $R_{\text{emp}}(f)$ is the empirical risk (average loss on training data)
- $N$ is the number of training samples
- $d$ is the VC dimension (a measure of model complexity)
- $\delta$ is the confidence parameter

**Interpretation**: This bound consists of two terms. The first term, empirical risk, can be made arbitrarily small by using sufficiently complex models that fit the training data well. However, the second termâ€”the generalization gapâ€”grows with model capacity ($d$) and shrinks with dataset size ($N$). The optimal model complexity minimizes the sum of these two terms.

More intuitively, the bound tells us that as we increase model complexity $d$, we can fit the training data better (reducing $R_{\text{emp}}(f)$), but the gap between training and true performance grows (the second term increases). Conversely, with more training data $N$, we can safely use more complex models since the generalization gap shrinks proportionally to $1/\sqrt{N}$.

**Practical Implications for This Project**:

1. **Parameter-Efficient Fine-Tuning**: Methods like LoRA reduce the effective VC dimension by constraining the fine-tuning process to low-rank subspaces. For a transformer with $d_{\text{model}}$ hidden dimensions and rank $r \ll d_{\text{model}}$, LoRA updates have far fewer degrees of freedom than full fine-tuning, leading to tighter generalization bounds. Implementation in [src/models/efficient/lora/](./src/models/efficient/lora/).

2. **Early Stopping**: Rather than training until convergence on the training set, we halt training when validation performance plateaus. This implicitly limits effective capacity by restricting the number of gradient updates. Callback implementation in [src/training/callbacks/early_stopping.py](./src/training/callbacks/early_stopping.py).

3. **Ensemble Methods**: While individual models may have high capacity, ensemble averaging acts as a form of regularization. The variance reduction achieved through ensembling can be formalized through bias-variance decomposition as shown in [Section 1.6.4](#164-ensemble-methods-and-diversity).

4. **Validation-Based Model Selection**: By selecting models based on validation rather than test performance, we avoid the adaptive overfitting problem identified by Dwork et al. (2015) in their work on preserving validity in adaptive data analysis. Our validation protocols are detailed in [configs/overfitting_prevention/validation/](./configs/overfitting_prevention/validation/).

Complete theoretical treatments including Rademacher complexity analysis, PAC learning bounds, and empirical process theory perspectives are provided in [OVERFITTING_PREVENTION.md Â§ Theoretical Framework](./OVERFITTING_PREVENTION.md).

### 1.6.2 Transfer Learning and Pre-Training

The remarkable success of transformer-based models on text classification despite limited labeled data is largely attributable to transfer learning through unsupervised pre-training. The pre-training phase learns general linguistic representations from massive unlabeled corpora, while fine-tuning specializes these representations to task-specific patterns.

**Mathematical Formulation**: Let $\theta$ denote the model parameters. Pre-training solves:

$$\theta^* = \arg\min_{\theta} \mathcal{L}_{\text{pretrain}}(\theta; \mathcal{D}_{\text{unlabeled}})$$

where $\mathcal{L}_{\text{pretrain}}$ is an unsupervised objective such as masked language modeling. For masked language modeling, given a sequence of tokens $\mathbf{x} = (x_1, x_2, \ldots, x_T)$, we randomly mask a subset of positions $\mathcal{M}$ and train the model to predict the masked tokens:

$$\mathcal{L}_{\text{MLM}} = -\sum_{i \in \mathcal{M}} \log P(x_i | \mathbf{x}_{\backslash \mathcal{M}}; \theta)$$

where $\mathbf{x}_{\backslash \mathcal{M}}$ denotes the sequence with masked positions replaced by a special [MASK] token.

Fine-tuning then solves:

$$\theta_{\text{task}} = \arg\min_{\theta} \mathcal{L}_{\text{task}}(\theta; \mathcal{D}_{\text{labeled}})$$

initialized at $\theta^*$ rather than random initialization. For classification, the task loss is typically cross-entropy:

$$\mathcal{L}_{\text{task}} = -\sum_{(x,y) \in \mathcal{D}} \log P(y | x; \theta)$$

**Why This Works**: Pre-training on diverse text learns broadly useful featuresâ€”syntactic patterns, semantic relationships, world knowledgeâ€”that transfer across tasks. Fine-tuning requires learning only task-specific decision boundaries, which can be accomplished with far less labeled data than learning both representations and decision boundaries from scratch.

The effectiveness can be understood through a two-stage perspective:
1. In the pre-training stage, the model learns to encode general linguistic knowledge into its parameters $\theta^*$
2. In the fine-tuning stage, only the final classification layer (and optionally, small adjustments to the encoder) needs to be learned from the limited labeled data

**Evidence**: Empirical studies (Devlin et al., 2019; Liu et al., 2019; He et al., 2021) demonstrate that pre-trained transformers achieve competitive performance with hundreds to thousands of labeled examples, whereas comparable architectures trained from scratch require orders of magnitude more data.

**Application in This Project**: All Tier 2 and higher models leverage publicly available pre-trained checkpoints from Hugging Face Hub. We additionally explore domain-adaptive pre-training on news corpora to further specialize representations to the AG News domain. 

Pre-trained model configurations:
- Standard transformers: [configs/models/single/transformers/](./configs/models/single/transformers/)
- Large language models: [configs/models/single/llm/](./configs/models/single/llm/)
- Domain adaptation scripts: [scripts/domain_adaptation/](./scripts/domain_adaptation/)

The transfer learning pipeline is detailed in [ARCHITECTURE.md Â§ Transfer Learning](./ARCHITECTURE.md).

### 1.6.3 Parameter-Efficient Fine-Tuning Theory

Full fine-tuning of large pre-trained models is parameter-inefficient: it requires storing and updating hundreds of millions to billions of parameters, most of which change only slightly from their pre-trained values. Parameter-efficient fine-tuning (PEFT) methods address this by constraining updates to low-dimensional subspaces or small adapter modules.

**Low-Rank Adaptation (LoRA)**: The key insight is that the weight updates during fine-tuning often have low intrinsic dimensionality. For a pre-trained weight matrix $W_0 \in \mathbb{R}^{d \times k}$, LoRA represents updates as a low-rank decomposition:

$$W = W_0 + \Delta W = W_0 + BA$$

where $B \in \mathbb{R}^{d \times r}$, $A \in \mathbb{R}^{r \times k}$, and $r \ll \min(d, k)$ is the rank.

**Detailed Explanation**: 
- $W_0$ is the original pre-trained weight matrix, which remains frozen during training
- $\Delta W = BA$ represents the update to the weights, factorized as a product of two smaller matrices
- Matrix $B$ has dimensions $d \times r$ and matrix $A$ has dimensions $r \times k$
- The rank $r$ controls the capacity of the adaptation; smaller $r$ means fewer trainable parameters and stronger regularization

During forward pass, instead of using $W_0 x$, we compute:
$$y = W_0 x + BAx = W_0 x + \Delta W x$$

**Parameter Count**: The original matrix has $d \times k$ parameters. LoRA introduces only $r(d + k)$ trainable parameters while freezing $W_0$. For typical values ($d = k = 768$, $r = 8$), this represents a reduction from 589,824 to 12,288 trainable parametersâ€”a 48Ã— reduction.

For example, in a standard transformer attention layer:
- Original: Query, Key, Value, Output matrices each have $768 \times 768 = 589,824$ parameters
- With LoRA (rank 8): Each adaptation has only $8 \times (768 + 768) = 12,288$ trainable parameters
- Total reduction: From ~2.4M parameters per attention layer to ~50K trainable parameters

**Theoretical Justification**: Li et al. (2018) demonstrated that the optimization landscape of neural networks lies approximately on low-dimensional manifolds. More recently, Aghajanyan et al. (2021) showed empirically that fine-tuning is intrinsically low-dimensional, with effective rank often much smaller than the explicit parameter count. This means that even though the full parameter space is high-dimensional, the optimization trajectory primarily moves in a low-dimensional subspace.

**Quantized LoRA (QLoRA)**: Building on LoRA, QLoRA applies 4-bit quantization to the frozen base model weights, reducing memory requirements by approximately 4Ã— while maintaining fine-tuning quality through additional techniques:

1. **4-bit NormalFloat Quantization**: Uses a special data type optimized for normally distributed weights
2. **Double Quantization**: Quantizes the quantization constants themselves to save additional memory
3. **Paged Optimizers**: Uses NVIDIA unified memory to handle memory spikes during training

The quantization function maps full-precision weights $W_0$ to 4-bit representation:
$$W_0^{\text{quant}} = \text{Quantize}(W_0, \text{dtype}=\text{NF4})$$

During fine-tuning, only the LoRA adapters $B$ and $A$ are kept in full precision.

**Application in This Project**: We provide extensive configurations for LoRA (ranks 4, 8, 16, 32, 64) and QLoRA (4-bit, 8-bit) across multiple target modules (query, key, value, output projections). 

Configuration files:
- LoRA configs: [configs/training/efficient/lora/](./configs/training/efficient/lora/)
- QLoRA configs: [configs/training/efficient/qlora/](./configs/training/efficient/qlora/)
- Rank ablation: [experiments/ablation_studies/lora_rank_ablation.py](./experiments/ablation_studies/lora_rank_ablation.py)
- Target module ablation: [configs/training/efficient/lora/lora_target_modules_experiments.yaml](./configs/training/efficient/lora/lora_target_modules_experiments.yaml)

Theoretical analysis is provided in [OVERFITTING_PREVENTION.md Â§ Parameter Efficiency](./OVERFITTING_PREVENTION.md).

### 1.6.4 Ensemble Methods and Diversity

Ensemble methods combine predictions from multiple models to achieve better performance than any individual model. The effectiveness of ensembling is well-understood through bias-variance decomposition.

**Bias-Variance-Covariance Decomposition**: For squared loss in regression, the expected error of an ensemble can be decomposed as:

$$E_{\text{ensemble}} = \overline{\text{Bias}^2} + \frac{1}{M}\overline{\text{Var}} + \frac{M-1}{M}\overline{\text{Cov}}$$

where:
- $M$ is the number of models in the ensemble
- $\overline{\text{Bias}^2}$ is the average squared bias of individual models
- $\overline{\text{Var}}$ is the average variance of individual models
- $\overline{\text{Cov}}$ is the average covariance between model predictions

**Detailed Interpretation**: 

This decomposition reveals three key insights:

1. **Bias Term ($\overline{\text{Bias}^2}$)**: Represents systematic errors that all models in the ensemble share. Ensembling does not reduce biasâ€”if all models make the same systematic mistake, averaging them preserves that mistake. The bias term remains constant regardless of ensemble size.

2. **Variance Term ($\frac{1}{M}\overline{\text{Var}}$)**: Represents random errors due to finite training data. This term is reduced by a factor of $M$ through averaging. With $M=5$ models, variance is reduced to 20% of the single-model variance. This is why ensembles are particularly effective when individual models have high variance (overfitting).

3. **Covariance Term ($\frac{M-1}{M}\overline{\text{Cov}}$)**: Represents correlation between model errors. If models make identical errors, $\overline{\text{Cov}} = \overline{\text{Var}}$, and the variance reduction benefit is completely negated. Maximum variance reduction occurs when models are diverseâ€”making errors on different examples, so $\overline{\text{Cov}} \approx 0$.

For classification, while the exact decomposition differs, the same principles apply: ensemble performance improves when individual models are both accurate (low bias) and diverse (low error correlation).

**Diversity Promotion Strategies**: We employ several approaches to create diverse ensemble members:

1. **Different Architectures**: DeBERTa, RoBERTa, ELECTRA, XLNet have different inductive biases:
   - DeBERTa uses disentangled attention mechanisms
   - RoBERTa uses dynamic masking during pre-training
   - ELECTRA uses discriminative pre-training objectives
   - XLNet uses permutation language modeling
   
   Configurations in [configs/models/ensemble/](./configs/models/ensemble/)

2. **Different Initializations**: Multiple random seeds create different optimization trajectories, even with the same architecture. Configuration templates in [configs/experiments/reproducibility/seeds.yaml](./configs/experiments/reproducibility/seeds.yaml).

3. **Different Data Views**: Varied data augmentation strategies (back-translation, paraphrasing, LLM-based generation) expose models to different perturbations of the training data. Augmentation configs in [configs/data/augmentation/](./configs/data/augmentation/).

4. **Different Training Procedures**: Varied learning rates, dropout rates, and regularization strengths create models with different bias-variance trade-offs. Configurations in [configs/training/regularization/](./configs/training/regularization/).

**Aggregation Methods**: We compare multiple ensemble aggregation strategies:

1. **Soft Voting**: Average predicted probabilities across models before taking argmax:
   $$\hat{y} = \arg\max_c \frac{1}{M} \sum_{m=1}^{M} P_m(y=c|x)$$
   
   Implementation in [src/models/ensemble/voting/soft_voting.py](./src/models/ensemble/voting/soft_voting.py)

2. **Weighted Voting**: Learn optimal weights $w_m$ on validation set:
   $$\hat{y} = \arg\max_c \sum_{m=1}^{M} w_m P_m(y=c|x)$$
   
   where $\sum_m w_m = 1$ and $w_m \geq 0$. Weights can be learned using linear regression or more complex meta-learners. Implementation in [src/models/ensemble/voting/weighted_voting.py](./src/models/ensemble/voting/weighted_voting.py).

3. **Stacking**: Train a meta-classifier (logistic regression, gradient boosting) on concatenated predictions from base models:
   $$\hat{y} = f_{\text{meta}}([P_1(y|x), P_2(y|x), \ldots, P_M(y|x)])$$
   
   Implementation in [src/models/ensemble/stacking/](./src/models/ensemble/stacking/)

Implementation details and empirical comparisons are provided in [src/models/ensemble/](./src/models/ensemble/) with selection guidance in [SOTA_MODELS_GUIDE.md Â§ Ensemble Selection](./SOTA_MODELS_GUIDE.md).

### 1.6.5 Knowledge Distillation

Knowledge distillation (Hinton et al., 2015) addresses a key limitation of ensemble methods: while ensembles achieve high accuracy, they are computationally expensive at inference time, requiring multiple forward passes. Distillation trains a single student model to mimic an ensemble teacher, preserving much of the performance gain while drastically reducing inference cost.

**Distillation Loss**: The student is trained on a combination of two objectives:

$$\mathcal{L}_{\text{distill}} = \alpha \cdot \mathcal{L}_{\text{CE}}(y, p_{\text{student}}) + (1-\alpha) \cdot \mathcal{L}_{\text{KL}}(p_{\text{teacher}}, p_{\text{student}})$$

where:
- $\mathcal{L}_{\text{CE}}$ is cross-entropy loss with ground truth labels $y$
- $\mathcal{L}_{\text{KL}}$ is KL divergence between teacher and student probability distributions
- $\alpha \in [0,1]$ balances the two objectives

**Detailed Explanation**:

The cross-entropy term ensures the student learns from the ground truth labels:
$$\mathcal{L}_{\text{CE}}(y, p_{\text{student}}) = -\sum_{c=1}^{C} \mathbb{1}[y=c] \log p_{\text{student}}(c)$$

where $C$ is the number of classes and $\mathbb{1}[y=c]$ is 1 if the true label is $c$, else 0.

The KL divergence term transfers knowledge from the teacher:
$$\mathcal{L}_{\text{KL}}(p_{\text{teacher}}, p_{\text{student}}) = \sum_{c=1}^{C} p_{\text{teacher}}(c) \log \frac{p_{\text{teacher}}(c)}{p_{\text{student}}(c)}$$

The hyperparameter $\alpha$ controls the trade-off:
- $\alpha = 1$: Pure supervised learning (ignores teacher)
- $\alpha = 0$: Pure distillation (ignores ground truth)
- Typical values: $\alpha \in [0.1, 0.5]$ work well in practice

**Temperature Scaling**: To transfer richer information, both teacher and student logits $z$ are divided by temperature $T$ before applying softmax:

$$p_i = \frac{\exp(z_i/T)}{\sum_j \exp(z_j/T)}$$

**Interpretation**: Higher temperatures ($T > 1$) produce softer probability distributions. Consider an example with 4 classes:

- **Hard prediction** ($T=1$): $[0.98, 0.01, 0.01, 0.00]$
  - The model is very confident about class 1
  - Provides almost no information about relationships between other classes
  
- **Soft prediction** ($T=3$): $[0.70, 0.15, 0.12, 0.03]$
  - Still predicts class 1, but with less confidence
  - Reveals that class 2 and 3 are more similar to class 1 than class 4
  - The relative ordering of classes 2 and 3 provides information about semantic similarity

This softer distribution reveals the teacher's uncertainty and relative similarities between classesâ€”information lost when using only hard labels (one-hot vectors). The temperature effectively "smooths" the distribution, making it easier for the student to learn the fine-grained knowledge encoded in the teacher's predictions.

During distillation training:
$$p_{\text{teacher}}(T) = \text{softmax}(z_{\text{teacher}}/T)$$
$$p_{\text{student}}(T) = \text{softmax}(z_{\text{student}}/T)$$

And the KL divergence is computed at temperature $T$, then scaled by $T^2$ to ensure gradient magnitudes match the cross-entropy term:
$$\mathcal{L}_{\text{KL}} = T^2 \cdot \text{KL}(p_{\text{teacher}}(T) \| p_{\text{student}}(T))$$

**Why It Works**: The soft labels from the teacher ensemble contain information about class similarities and ambiguous cases that is not present in the one-hot ground truth labels. By training on this richer supervision signal, the student learns to mimic not just the teacher's final predictions but its confidence calibration and inter-class relationships.

For example, in AG News classification:
- Ground truth might simply say: "This is a Sports article"
- Teacher's soft labels might say: "90% Sports, 7% Business (because it discusses sports contracts), 2% World, 1% Sci/Tech"
- The student learns both the correct class AND the semantic relationships between categories

**Multi-Stage Distillation in This Project**:

1. **Stage 1 (LLM â†’ Transformer)**: Distill knowledge from large language models (LLaMA 2-13B, Mistral-7B) into large transformers (DeBERTa-v3-Large), achieving 40Ã— parameter reduction with minimal accuracy loss. Scripts in [scripts/training/distillation/distill_from_llama.py](./scripts/training/distillation/distill_from_llama.py) and [scripts/training/distillation/distill_from_mistral.py](./scripts/training/distillation/distill_from_mistral.py).

2. **Stage 2 (Ensemble â†’ Single)**: Distill an ensemble of 5-7 diverse DeBERTa-Large models into a single DeBERTa-Large student, capturing ensemble benefits without ensemble inference cost. Configuration in [configs/training/advanced/knowledge_distillation/ensemble_distillation.yaml](./configs/training/advanced/knowledge_distillation/ensemble_distillation.yaml).

3. **Stage 3 (Compression)**: Apply INT8 quantization to the distilled model for 4Ã— size reduction and faster CPU inference. Scripts in [scripts/optimization/quantization_optimization.py](./scripts/optimization/quantization_optimization.py).

Experimental results demonstrating accuracy retention through this pipeline are provided in [experiments/sota_experiments/phase3_llm_distillation.py](./experiments/sota_experiments/phase3_llm_distillation.py). Theoretical analysis and best practices are detailed in [SOTA_MODELS_GUIDE.md Â§ Knowledge Distillation](./SOTA_MODELS_GUIDE.md).

## 1.7 Scope and Limitations

To establish appropriate expectations and clarify the boundaries of this project, we explicitly state what is and is not within scope.

### 1.7.1 Within Scope

This project provides:

- **Complete Text Classification Pipeline**: End-to-end workflow from raw text preprocessing through model training, evaluation, and deployment for supervised classification tasks. Pipeline documentation in [ARCHITECTURE.md](./ARCHITECTURE.md).

- **Rigorous Experimental Protocols**: Infrastructure for conducting statistically valid experiments including proper train-validation-test splits, multiple random seed evaluation, significance testing, and prevention of data leakage. Protocols detailed in [OVERFITTING_PREVENTION.md](./OVERFITTING_PREVENTION.md).

- **Comprehensive Model Coverage**: Implementations spanning classical machine learning baselines (Naive Bayes, SVM) through modern transformers (BERT, RoBERTa, DeBERTa) to large language models (LLaMA, Mistral) with parameter-efficient fine-tuning. Complete model zoo in [configs/models/](./configs/models/).

- **Advanced Training Techniques**: Support for ensemble methods, knowledge distillation, adversarial training, data augmentation, and multi-stage training pipelines. Training strategies in [configs/training/](./configs/training/).

- **Platform Portability**: Configurations and tooling for running experiments on consumer laptops, cloud platforms (Google Colab, Kaggle), and institutional compute clusters with automatic resource adaptation. Platform guide in [PLATFORM_OPTIMIZATION_GUIDE.md](./PLATFORM_OPTIMIZATION_GUIDE.md).

- **Extensive Documentation**: Technical documentation targeted at multiple expertise levels from beginners to advanced researchers, including theoretical treatments, API references, and step-by-step tutorials. Documentation index in [docs/](./docs/).

### 1.7.2 Explicitly Out of Scope

This project does not provide:

- **Novel Architectural Contributions**: We implement and combine existing published techniques rather than proposing new model architectures or training algorithms. Original research contributions are in the domain of systematic evaluation and rigorous experimental methodology.

- **Multilingual Classification**: Focus is on English-language text classification as determined by the AG News dataset. Extensions to multilingual scenarios would require different pre-trained models and evaluation protocols.

- **Streaming or Real-Time Inference**: The system is designed for batch processing and offline evaluation. While inference latency is measured and reported in [benchmarks/efficiency/](./benchmarks/efficiency/), we do not optimize for real-time serving constraints or provide production-grade serving infrastructure.

- **Adversarial Robustness Certification**: While we include adversarial training as an optional technique in [configs/training/advanced/adversarial_training.yaml](./configs/training/advanced/adversarial_training.yaml), we do not provide formally verified robustness guarantees or certified defense mechanisms against adversarial examples.

- **Automatic Data Collection**: We assume users have access to their data. The project provides tools for processing and analyzing data in [src/data/](./src/data/), but does not include web scraping, data purchasing, or crowdsourcing annotation pipelines.

- **Production Deployment Infrastructure**: While we provide basic Docker configurations in [deployment/docker/](./deployment/docker/) and deployment guidelines in [docs/user_guide/local_deployment.md](./docs/user_guide/local_deployment.md), comprehensive production infrastructure (Kubernetes orchestration, auto-scaling, monitoring, A/B testing) is beyond scope.

- **Graphical User Interfaces**: All interfaces are command-line based or notebook-based. We do not provide web dashboards or GUI tools for non-technical users, though Streamlit and Gradio apps are available in [app/](./app/) for demonstration purposes.

### 1.7.3 Assumptions and Prerequisites

**Data Assumptions**:

- **Balanced or Near-Balanced Classes**: Many techniques (ensemble diversity metrics, stratified sampling) assume approximately balanced class distributions. Highly imbalanced datasets may require additional techniques like class weighting or resampling not extensively covered in this framework.

- **Text Length**: Default configurations assume document length of 512 tokens or fewer, matching common transformer limits. Longer documents require alternative architectures (Longformer, BigBird) available in [configs/models/single/transformers/longformer/](./configs/models/single/transformers/longformer/) or truncation strategies.

- **Clean Labels**: We assume labels are accurate and consistent. Label noise handling is not explicitly addressed beyond standard regularization techniques.

- **Single-Label Classification**: The focus is on assigning each document to exactly one category. Multi-label classification (assigning multiple categories per document) requires modifications to loss functions and evaluation metrics.

**Computational Assumptions**:

- **GPU Access**: Training transformer-based models requires GPU acceleration. While CPU-only training is technically possible, it is prohibitively slow for models beyond simple baselines. Access to cloud platforms with GPU quotas or local GPU hardware is assumed. CPU-optimized configs available in [configs/models/recommended/tier_5_free_optimized/cpu_friendly/](./configs/models/recommended/tier_5_free_optimized/cpu_friendly/).

- **Internet Connectivity**: Downloading pre-trained model checkpoints requires stable internet access and sufficient bandwidth. Models range from hundreds of megabytes (BERT-Base) to tens of gigabytes (LLaMA-70B).

- **Storage Capacity**: Training runs generate checkpoints, logs, and cached preprocessed data. We recommend at least 50GB of available disk space for a typical experiment series.

**User Knowledge Assumptions**:

- **Python Programming**: Users should be comfortable with Python syntax, including functions, classes, imports, and common libraries (NumPy, pandas).

- **Command-Line Interfaces**: Basic familiarity with terminal commands, file paths, and environment variables.

- **Machine Learning Fundamentals**: Understanding of core concepts including train-validation-test splits, overfitting, hyperparameters, and evaluation metrics (accuracy, precision, recall, F1).

- **Deep Learning Basics** (for advanced features): Familiarity with neural network architectures, backpropagation, optimization algorithms, and regularization techniques.

Users without these prerequisites are encouraged to consult the beginner-level tutorials in [docs/level_1_beginner/](./docs/level_1_beginner/) which provide gentler introductions with more extensive explanations.

### 1.7.4 Known Limitations

**Limitation 1: Quadratic Complexity of Self-Attention**

Transformer architectures compute pairwise attention between all tokens, resulting in $O(n^2)$ memory and computational complexity where $n$ is sequence length. This limits practical sequence lengths to 512-1024 tokens for standard models.

**Mitigation**: We provide configurations for efficient transformers (Longformer, BigBird) that use sparse attention patterns to achieve $O(n)$ complexity in [configs/models/single/transformers/longformer/](./configs/models/single/transformers/longformer/). However, these are not the primary focus and have received less extensive tuning.

**Future Direction**: Integration of recent linear attention mechanisms (Performers, FNet, Linformer) could enable processing of longer documents without quadratic scaling. Tracked in [ROADMAP.md](./ROADMAP.md).

**Limitation 2: Memory Requirements for Large Models**

Even with parameter-efficient fine-tuning and quantization, the largest models (LLaMA-70B, Mixtral-8x7B) require 40-80GB of GPU memory. This exceeds the capacity of consumer GPUs and requires either model parallelism across multiple devices or cloud instances with high-memory GPUs.

**Mitigation**: QLoRA with 4-bit quantization reduces memory requirements by approximately 4Ã—, making models up to 13B parameters accessible on consumer GPUs with 16-24GB VRAM. Configurations in [configs/training/efficient/qlora/](./configs/training/efficient/qlora/). For larger models, we provide configurations for gradient checkpointing and CPU offloading that trade computation time for memory in [configs/training/efficient/](./configs/training/efficient/).

**Future Direction**: Exploration of more aggressive quantization (INT4, INT2) and structured pruning could further reduce memory footprints. Research directions in [ROADMAP.md](./ROADMAP.md).

**Limitation 3: Ensemble Inference Overhead**

While ensemble methods achieve the highest accuracy in our experiments (results in [benchmarks/accuracy/ensemble_results.json](./benchmarks/accuracy/ensemble_results.json)), they require multiple forward passes at inference time, increasing latency proportionally to ensemble size. A 7-model ensemble is 7Ã— slower than a single model.

**Mitigation**: Knowledge distillation compresses ensemble knowledge into a single student model, retaining typically 90-95% of ensemble improvement while restoring single-model inference speed. Distillation configurations in [configs/training/advanced/knowledge_distillation/](./configs/training/advanced/knowledge_distillation/).

**Future Direction**: Investigation of fast ensemble approximation methods such as dropout ensembles or BatchEnsemble could provide accuracy benefits closer to full ensembles with minimal computational overhead. Tracked in [ROADMAP.md](./ROADMAP.md).

**Limitation 4: Platform-Specific Quota Management**

Our platform detection and quota management systems use heuristics based on typical platform limits (Colab 12-hour sessions, Kaggle 30-hour GPU weekly quotas). These limits may change over time and vary based on account type (free tier versus paid subscriptions).

**Mitigation**: Conservative checkpoint intervals and explicit quota tracking provide safety margins in [src/deployment/quota_tracker.py](./src/deployment/quota_tracker.py). Users can override automatic settings if they have specific information about their quota limits through [configs/quotas/](./configs/quotas/).

**Future Direction**: Integration with platform APIs (when available) could provide real-time quota information rather than relying on hardcoded assumptions. Tracked in [ROADMAP.md](./ROADMAP.md).

**Limitation 5: English-Only Evaluation**

All experiments are conducted on the English-language AG News dataset. While the underlying transformer models (mBERT, XLM-R) support multilingual text, we have not evaluated cross-lingual transfer or performance on non-English datasets.

**Mitigation**: The framework architecture is language-agnostic, and extending to other languages primarily requires different datasets and evaluation protocols rather than code modifications. The modular design in [src/](./src/) supports such extensions.

**Future Direction**: Systematic evaluation on multilingual benchmarks (XNLI, PAWS-X) and investigation of cross-lingual transfer learning techniques. Multilingual support tracked in [ROADMAP.md](./ROADMAP.md).

## 1.8 Organization of Documentation

This project provides extensive documentation organized according to progressive disclosure principles, allowing users to engage at levels appropriate to their expertise and goals.

### 1.8.1 Entry Points by User Type

**New Users Seeking Quick Start**:

- [QUICK_START.md](./QUICK_START.md): Minimal setup to first working model in under 10 minutes
- [quickstart/auto_start.py](./quickstart/auto_start.py): Single-command demo requiring no configuration
- [docs/getting_started/installation.md](./docs/getting_started/installation.md): Comprehensive installation guide for different platforms
- [quickstart/decision_tree.py](./quickstart/decision_tree.py): Interactive CLI for guided model selection

**Practitioners Seeking Best Practices**:

- [SOTA_MODELS_GUIDE.md](./SOTA_MODELS_GUIDE.md): Model selection flowcharts and performance comparisons
- [docs/user_guide/](./docs/user_guide/): Detailed guides on data preparation, training, evaluation, and deployment
- [docs/best_practices/](./docs/best_practices/): Domain-specific recommendations for model selection, hyperparameter tuning, and avoiding common pitfalls
- [notebooks/01_tutorials/](./notebooks/01_tutorials/): Interactive Jupyter tutorials with executable examples

**Researchers Seeking Theoretical Depth**:

- [OVERFITTING_PREVENTION.md](./OVERFITTING_PREVENTION.md): Complete theoretical framework including proofs and statistical guarantees
- [ARCHITECTURE.md](./ARCHITECTURE.md): Detailed system architecture with transformer internals and optimization techniques
- [docs/level_3_advanced/](./docs/level_3_advanced/): Advanced topics including custom model development and research workflows
- [experiments/](./experiments/): Ablation studies, hyperparameter searches, and baseline comparisons with full experimental protocols

**Developers Seeking to Extend the System**:

- [docs/developer_guide/](./docs/developer_guide/): Architecture overview, coding standards, and extension points
- [docs/api_reference/](./docs/api_reference/): Complete API documentation for all modules
- [CONTRIBUTING.md](./CONTRIBUTING.md): Guidelines for contributing code, documentation, and bug reports
- [ARCHITECTURE.md](./ARCHITECTURE.md): Design patterns and architectural decisions

### 1.8.2 Document Hierarchy and Specialization

To avoid duplication and maintain a single source of truth, different documents have clearly defined scopes:

**[README.md](./README.md)** (This Document):
- High-level introduction to the project and its motivation
- Overview of theoretical foundations with links to detailed treatments
- Dataset description and experimental setup (Section 2)
- Quick start instructions and navigation guide

**[OVERFITTING_PREVENTION.md](./OVERFITTING_PREVENTION.md)**:
- Complete mathematical treatment of generalization theory
- Detailed description of overfitting prevention architecture
- Empirical validation of prevention mechanisms
- Decision trees for selecting prevention strategies

**[ARCHITECTURE.md](./ARCHITECTURE.md)**:
- System architecture and component interactions
- Detailed explanations of transformer architectures
- Optimization techniques and efficiency considerations
- Design patterns and extension points

**[SOTA_MODELS_GUIDE.md](./SOTA_MODELS_GUIDE.md)**:
- Model zoo overview and tier descriptions
- Performance benchmarks and accuracy-efficiency trade-offs
- Hyperparameter recommendations for each model family
- Selection flowcharts for different use cases

**[PLATFORM_OPTIMIZATION_GUIDE.md](./PLATFORM_OPTIMIZATION_GUIDE.md)**:
- Platform detection mechanisms
- Resource profiling and quota management
- Checkpoint synchronization strategies
- Platform-specific optimization techniques

**User Guides in [docs/user_guide/](./docs/user_guide/)**:
- Step-by-step instructions for common workflows
- Code examples and configuration templates
- Troubleshooting common issues
- Best practices for specific tasks

**API Reference in [docs/api_reference/](./docs/api_reference/)**:
- Function and class signatures
- Parameter descriptions and types
- Return value specifications
- Usage examples for each API component

This hierarchical organization ensures that:

1. Users can find information at the appropriate level of detail
2. Each piece of information has a single authoritative source
3. Updates to concepts need to be made in only one location
4. Cross-references guide users to related information in other documents

For a visual overview of the documentation structure, see [docs/00_START_HERE.md](./docs/00_START_HERE.md), which provides a guided navigation map based on your learning objectives and experience level.



## Project Structure

The repository is organized as follows:

```plaintext
ag-news-text-classification/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ CITATION.cff
â”œâ”€â”€ CHANGELOG.md
â”œâ”€â”€ ARCHITECTURE.md
â”œâ”€â”€ PERFORMANCE.md
â”œâ”€â”€ SECURITY.md
â”œâ”€â”€ TROUBLESHOOTING.md
â”œâ”€â”€ SOTA_MODELS_GUIDE.md
â”œâ”€â”€ OVERFITTING_PREVENTION.md
â”œâ”€â”€ ROADMAP.md
â”œâ”€â”€ FREE_DEPLOYMENT_GUIDE.md
â”œâ”€â”€ PLATFORM_OPTIMIZATION_GUIDE.md
â”œâ”€â”€ IDE_SETUP_GUIDE.md
â”œâ”€â”€ LOCAL_MONITORING_GUIDE.md
â”œâ”€â”€ QUICK_START.md
â”œâ”€â”€ HEALTH_CHECK.md
â”œâ”€â”€ setup.py
â”œâ”€â”€ setup.cfg
â”œâ”€â”€ MANIFEST.in
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ Makefile
â”œâ”€â”€ install.sh
â”œâ”€â”€ .env.example
â”œâ”€â”€ .env.test
â”œâ”€â”€ .env.local
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .editorconfig
â”œâ”€â”€ .pre-commit-config.yaml
â”œâ”€â”€ .flake8
â”œâ”€â”€ commitlint.config.js
â”‚
â”œâ”€â”€ requirements/
â”‚   â”œâ”€â”€ base.txt
â”‚   â”œâ”€â”€ ml.txt
â”‚   â”œâ”€â”€ llm.txt
â”‚   â”œâ”€â”€ efficient.txt
â”‚   â”œâ”€â”€ local_prod.txt
â”‚   â”œâ”€â”€ dev.txt
â”‚   â”œâ”€â”€ data.txt
â”‚   â”œâ”€â”€ ui.txt
â”‚   â”œâ”€â”€ docs.txt
â”‚   â”œâ”€â”€ minimal.txt
â”‚   â”œâ”€â”€ research.txt
â”‚   â”œâ”€â”€ robustness.txt
â”‚   â”œâ”€â”€ all_local.txt
â”‚   â”œâ”€â”€ colab.txt
â”‚   â”œâ”€â”€ kaggle.txt
â”‚   â”œâ”€â”€ free_tier.txt
â”‚   â”œâ”€â”€ platform_minimal.txt
â”‚   â”œâ”€â”€ local_monitoring.txt
â”‚   â””â”€â”€ lock/
â”‚       â”œâ”€â”€ base.lock
â”‚       â”œâ”€â”€ ml.lock
â”‚       â”œâ”€â”€ llm.lock
â”‚       â”œâ”€â”€ all.lock
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ .devcontainer/
â”‚   â”œâ”€â”€ devcontainer.json
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ .husky/
â”‚   â”œâ”€â”€ pre-commit
â”‚   â””â”€â”€ commit-msg
â”‚
â”œâ”€â”€ .ide/
â”‚   â”œâ”€â”€ SOURCE_OF_TRUTH.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ vscode/
â”‚   â”‚   â”œâ”€â”€ settings.json
â”‚   â”‚   â”œâ”€â”€ launch.json
â”‚   â”‚   â”œâ”€â”€ tasks.json
â”‚   â”‚   â”œâ”€â”€ extensions.json
â”‚   â”‚   â””â”€â”€ snippets/
â”‚   â”‚       â”œâ”€â”€ python.json
â”‚   â”‚       â””â”€â”€ yaml.json
â”‚   â”‚
â”‚   â”œâ”€â”€ pycharm/
â”‚   â”‚   â”œâ”€â”€ .idea/
â”‚   â”‚   â”‚   â”œâ”€â”€ workspace.xml
â”‚   â”‚   â”‚   â”œâ”€â”€ misc.xml
â”‚   â”‚   â”‚   â”œâ”€â”€ modules.xml
â”‚   â”‚   â”‚   â”œâ”€â”€ inspectionProfiles/
â”‚   â”‚   â”‚   â”œâ”€â”€ runConfigurations/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ train_model.xml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ run_tests.xml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ start_api.xml
â”‚   â”‚   â”‚   â””â”€â”€ codeStyles/
â”‚   â”‚   â”‚       â””â”€â”€ Project.xml
â”‚   â”‚   â”œâ”€â”€ README_PYCHARM.md
â”‚   â”‚   â””â”€â”€ settings.zip
â”‚   â”‚
â”‚   â”œâ”€â”€ jupyter/
â”‚   â”‚   â”œâ”€â”€ jupyter_notebook_config.py
â”‚   â”‚   â”œâ”€â”€ jupyter_lab_config.py
â”‚   â”‚   â”œâ”€â”€ custom/
â”‚   â”‚   â”‚   â”œâ”€â”€ custom.css
â”‚   â”‚   â”‚   â””â”€â”€ custom.js
â”‚   â”‚   â”œâ”€â”€ nbextensions_config.json
â”‚   â”‚   â”œâ”€â”€ lab/
â”‚   â”‚   â”‚   â”œâ”€â”€ user-settings/
â”‚   â”‚   â”‚   â””â”€â”€ workspaces/
â”‚   â”‚   â””â”€â”€ kernels/
â”‚   â”‚       â””â”€â”€ ag-news/
â”‚   â”‚           â””â”€â”€ kernel.json
â”‚   â”‚
â”‚   â”œâ”€â”€ vim/
â”‚   â”‚   â”œâ”€â”€ .vimrc
â”‚   â”‚   â”œâ”€â”€ coc-settings.json
â”‚   â”‚   â”œâ”€â”€ ultisnips/
â”‚   â”‚   â”‚   â””â”€â”€ python.snippets
â”‚   â”‚   â””â”€â”€ README_VIM.md
â”‚   â”‚
â”‚   â”œâ”€â”€ neovim/
â”‚   â”‚   â”œâ”€â”€ init.lua
â”‚   â”‚   â”œâ”€â”€ lua/
â”‚   â”‚   â”‚   â”œâ”€â”€ plugins.lua
â”‚   â”‚   â”‚   â”œâ”€â”€ lsp.lua
â”‚   â”‚   â”‚   â”œâ”€â”€ keymaps.lua
â”‚   â”‚   â”‚   â””â”€â”€ ag-news/
â”‚   â”‚   â”‚       â”œâ”€â”€ config.lua
â”‚   â”‚   â”‚       â””â”€â”€ commands.lua
â”‚   â”‚   â”œâ”€â”€ coc-settings.json
â”‚   â”‚   â””â”€â”€ README_NEOVIM.md
â”‚   â”‚
â”‚   â”œâ”€â”€ sublime/
â”‚   â”‚   â”œâ”€â”€ ag-news.sublime-project
â”‚   â”‚   â”œâ”€â”€ ag-news.sublime-workspace
â”‚   â”‚   â”œâ”€â”€ Preferences.sublime-settings
â”‚   â”‚   â”œâ”€â”€ Python.sublime-settings
â”‚   â”‚   â”œâ”€â”€ snippets/
â”‚   â”‚   â”‚   â”œâ”€â”€ pytorch-model.sublime-snippet
â”‚   â”‚   â”‚   â””â”€â”€ lora-config.sublime-snippet
â”‚   â”‚   â”œâ”€â”€ build_systems/
â”‚   â”‚   â”‚   â”œâ”€â”€ Train Model.sublime-build
â”‚   â”‚   â”‚   â””â”€â”€ Run Tests.sublime-build
â”‚   â”‚   â””â”€â”€ README_SUBLIME.md
â”‚   â”‚
â”‚   â””â”€â”€ cloud_ides/
â”‚       â”œâ”€â”€ gitpod/
â”‚       â”‚   â”œâ”€â”€ .gitpod.yml
â”‚       â”‚   â””â”€â”€ .gitpod.Dockerfile
â”‚       â”œâ”€â”€ codespaces/
â”‚       â”‚   â””â”€â”€ .devcontainer.json
â”‚       â”œâ”€â”€ colab/
â”‚       â”‚   â”œâ”€â”€ colab_setup.py
â”‚       â”‚   â””â”€â”€ drive_mount.py
â”‚       â””â”€â”€ kaggle/
â”‚           â””â”€â”€ kaggle_setup.py
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ pipeline.png
â”‚   â”œâ”€â”€ api_architecture.png
â”‚   â”œâ”€â”€ local_deployment_flow.png
â”‚   â”œâ”€â”€ overfitting_prevention_flow.png
â”‚   â”œâ”€â”€ sota_model_architecture.png
â”‚   â”œâ”€â”€ decision_tree.png
â”‚   â”œâ”€â”€ platform_detection_flow.png
â”‚   â”œâ”€â”€ auto_training_workflow.png
â”‚   â”œâ”€â”€ quota_management_diagram.png
â”‚   â””â”€â”€ progressive_disclosure.png
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â”œâ”€â”€ config_validator.py
â”‚   â”œâ”€â”€ config_schema.py
â”‚   â”œâ”€â”€ constants.py
â”‚   â”œâ”€â”€ compatibility_matrix.yaml
â”‚   â”œâ”€â”€ smart_defaults.py
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ rest_config.yaml
â”‚   â”‚   â”œâ”€â”€ auth_config.yaml
â”‚   â”‚   â””â”€â”€ rate_limit_config.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ prediction_service.yaml
â”‚   â”‚   â”œâ”€â”€ training_service.yaml
â”‚   â”‚   â”œâ”€â”€ data_service.yaml
â”‚   â”‚   â”œâ”€â”€ model_service.yaml
â”‚   â”‚   â””â”€â”€ local_monitoring.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ environments/
â”‚   â”‚   â”œâ”€â”€ dev.yaml
â”‚   â”‚   â”œâ”€â”€ local_prod.yaml
â”‚   â”‚   â”œâ”€â”€ colab.yaml
â”‚   â”‚   â””â”€â”€ kaggle.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ feature_flags.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ secrets/
â”‚   â”‚   â”œâ”€â”€ secrets.template.yaml
â”‚   â”‚   â””â”€â”€ local_secrets.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ deberta_template.yaml.j2
â”‚   â”‚   â”œâ”€â”€ roberta_template.yaml.j2
â”‚   â”‚   â”œâ”€â”€ llm_template.yaml.j2
â”‚   â”‚   â”œâ”€â”€ ensemble_template.yaml.j2
â”‚   â”‚   â””â”€â”€ training_template.yaml.j2
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/
â”‚   â”‚   â”œâ”€â”€ model_specs.yaml
â”‚   â”‚   â”œâ”€â”€ training_specs.yaml
â”‚   â”‚   â””â”€â”€ ensemble_specs.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ SELECTION_GUIDE.md
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ recommended/
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â”œâ”€â”€ ag_news_best_practices.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ quick_start.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ balanced.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ sota_accuracy.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ tier_1_sota/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v3_xlarge_lora.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v2_xxlarge_qlora.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ roberta_large_lora.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ electra_large_lora.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ xlnet_large_lora.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ tier_2_llm/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama2_7b_qlora.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama2_13b_qlora.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama3_8b_qlora.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mistral_7b_qlora.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mixtral_8x7b_qlora.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ falcon_7b_qlora.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ phi_3_qlora.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mpt_7b_qlora.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ tier_3_ensemble/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ xlarge_ensemble.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm_ensemble.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ hybrid_ensemble.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ open_source_llm_ensemble.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ tier_4_distilled/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama_distilled_deberta.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mistral_distilled_roberta.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ensemble_distilled.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ tier_5_free_optimized/
â”‚   â”‚   â”‚       â”œâ”€â”€ auto_selected/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ colab_free_auto.yaml
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ colab_pro_auto.yaml
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ kaggle_auto.yaml
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ local_auto.yaml
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ platform_matrix.yaml
â”‚   â”‚   â”‚       â”‚
â”‚   â”‚   â”‚       â”œâ”€â”€ platform_specific/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ colab_optimized.yaml
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ kaggle_tpu_optimized.yaml
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ local_cpu_optimized.yaml
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ local_gpu_optimized.yaml
â”‚   â”‚   â”‚       â”‚
â”‚   â”‚   â”‚       â”œâ”€â”€ colab_friendly/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ deberta_large_lora_colab.yaml
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ distilroberta_efficient.yaml
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ ensemble_lightweight.yaml
â”‚   â”‚   â”‚       â”‚
â”‚   â”‚   â”‚       â””â”€â”€ cpu_friendly/
â”‚   â”‚   â”‚           â”œâ”€â”€ distilled_cpu_optimized.yaml
â”‚   â”‚   â”‚           â””â”€â”€ quantized_int8.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ single/
â”‚   â”‚   â”‚   â”œâ”€â”€ transformers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v3_base.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v3_large.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v3_xlarge.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v2_xlarge.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v2_xxlarge.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ deberta_sliding_window.yaml
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ roberta/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ roberta_base.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ roberta_large.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ roberta_large_mnli.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ xlm_roberta_large.yaml
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ electra/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ electra_base.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ electra_large.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ electra_discriminator.yaml
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ xlnet/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ xlnet_base.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ xlnet_large.yaml
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ longformer/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ longformer_base.yaml
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ longformer_large.yaml
â”‚   â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ t5/
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ t5_base.yaml
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ t5_large.yaml
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ t5_3b.yaml
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ flan_t5_xl.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ llm/
â”‚   â”‚   â”‚       â”œâ”€â”€ llama/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ llama2_7b.yaml
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ llama2_13b.yaml
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ llama2_70b.yaml
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ llama3_8b.yaml
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ llama3_70b.yaml
â”‚   â”‚   â”‚       â”‚
â”‚   â”‚   â”‚       â”œâ”€â”€ mistral/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ mistral_7b.yaml
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ mistral_7b_instruct.yaml
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ mixtral_8x7b.yaml
â”‚   â”‚   â”‚       â”‚
â”‚   â”‚   â”‚       â”œâ”€â”€ falcon/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ falcon_7b.yaml
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ falcon_40b.yaml
â”‚   â”‚   â”‚       â”‚
â”‚   â”‚   â”‚       â”œâ”€â”€ mpt/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ mpt_7b.yaml
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ mpt_30b.yaml
â”‚   â”‚   â”‚       â”‚
â”‚   â”‚   â”‚       â””â”€â”€ phi/
â”‚   â”‚   â”‚           â”œâ”€â”€ phi_2.yaml
â”‚   â”‚   â”‚           â””â”€â”€ phi_3.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ensemble/
â”‚   â”‚       â”œâ”€â”€ ENSEMBLE_SELECTION_GUIDE.yaml
â”‚   â”‚       â”œâ”€â”€ presets/
â”‚   â”‚       â”‚   â”œâ”€â”€ quick_start.yaml
â”‚   â”‚       â”‚   â”œâ”€â”€ sota_accuracy.yaml
â”‚   â”‚       â”‚   â””â”€â”€ balanced.yaml
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ voting/
â”‚   â”‚       â”‚   â”œâ”€â”€ soft_voting_xlarge.yaml
â”‚   â”‚       â”‚   â”œâ”€â”€ weighted_voting_llm.yaml
â”‚   â”‚       â”‚   â””â”€â”€ rank_voting_hybrid.yaml
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ stacking/
â”‚   â”‚       â”‚   â”œâ”€â”€ stacking_xlarge_xgboost.yaml
â”‚   â”‚       â”‚   â”œâ”€â”€ stacking_llm_lightgbm.yaml
â”‚   â”‚       â”‚   â””â”€â”€ stacking_hybrid_catboost.yaml
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ blending/
â”‚   â”‚       â”‚   â”œâ”€â”€ blending_xlarge.yaml
â”‚   â”‚       â”‚   â””â”€â”€ dynamic_blending_llm.yaml
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ advanced/
â”‚   â”‚           â”œâ”€â”€ bayesian_ensemble_xlarge.yaml
â”‚   â”‚           â”œâ”€â”€ snapshot_ensemble_llm.yaml
â”‚   â”‚           â””â”€â”€ multi_level_ensemble.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ standard/
â”‚   â”‚   â”‚   â”œâ”€â”€ base_training.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ mixed_precision.yaml
â”‚   â”‚   â”‚   â””â”€â”€ distributed.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ platform_adaptive/
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â”œâ”€â”€ colab_free_training.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ colab_pro_training.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ kaggle_gpu_training.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ kaggle_tpu_training.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ local_gpu_training.yaml
â”‚   â”‚   â”‚   â””â”€â”€ local_cpu_training.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ efficient/
â”‚   â”‚   â”‚   â”œâ”€â”€ lora/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lora_config.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lora_xlarge.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lora_llm.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lora_rank_experiments.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ lora_target_modules_experiments.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ qlora/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ qlora_4bit.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ qlora_8bit.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ qlora_nf4.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ qlora_llm.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_houlsby.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_pfeiffer.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_parallel.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_fusion.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ adapter_stacking.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ prefix_tuning/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prefix_tuning.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prefix_tuning_llm.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ prefix_length_experiments.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_tuning/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ soft_prompt_tuning.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ p_tuning_v2.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ prompt_length_experiments.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ia3/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ia3_config.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ combined/
â”‚   â”‚   â”‚       â”œâ”€â”€ lora_plus_adapters.yaml
â”‚   â”‚   â”‚       â”œâ”€â”€ qlora_plus_prompt.yaml
â”‚   â”‚   â”‚       â””â”€â”€ multi_method_fusion.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ tpu/
â”‚   â”‚   â”‚   â”œâ”€â”€ kaggle_tpu_v3.yaml
â”‚   â”‚   â”‚   â””â”€â”€ tpu_optimization.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ advanced/
â”‚   â”‚   â”‚   â”œâ”€â”€ curriculum_learning.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ adversarial_training.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ multitask_learning.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ contrastive_learning.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ knowledge_distillation/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ standard_distillation.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama_distillation.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mistral_distillation.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm_to_xlarge_distillation.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ xlarge_to_large_distillation.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ensemble_distillation.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ self_distillation.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ meta_learning.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_tuning/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ alpaca_style.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ dolly_style.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ vicuna_style.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ custom_instructions.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ multi_stage/
â”‚   â”‚   â”‚       â”œâ”€â”€ stage_manager.yaml
â”‚   â”‚   â”‚       â”œâ”€â”€ progressive_training.yaml
â”‚   â”‚   â”‚       â”œâ”€â”€ iterative_refinement.yaml
â”‚   â”‚   â”‚       â””â”€â”€ base_to_xlarge_progressive.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ regularization/
â”‚   â”‚   â”‚   â”œâ”€â”€ dropout_strategies/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ standard_dropout.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ variational_dropout.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ dropconnect.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adaptive_dropout.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ monte_carlo_dropout.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ scheduled_dropout.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ advanced_regularization/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ r_drop.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mixout.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ spectral_normalization.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ gradient_penalty.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ weight_decay_schedule.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ elastic_weight_consolidation.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ data_regularization/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mixup.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cutmix.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cutout.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ manifold_mixup.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ augmax.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ combined/
â”‚   â”‚   â”‚       â”œâ”€â”€ heavy_regularization.yaml
â”‚   â”‚   â”‚       â”œâ”€â”€ xlarge_safe_config.yaml
â”‚   â”‚   â”‚       â””â”€â”€ llm_safe_config.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ safe/
â”‚   â”‚       â”œâ”€â”€ xlarge_safe_training.yaml
â”‚   â”‚       â”œâ”€â”€ llm_safe_training.yaml
â”‚   â”‚       â”œâ”€â”€ ensemble_safe_training.yaml
â”‚   â”‚       â””â”€â”€ ultra_safe_training.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ overfitting_prevention/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ constraints/
â”‚   â”‚   â”‚   â”œâ”€â”€ model_size_constraints.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ xlarge_constraints.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_constraints.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ ensemble_constraints.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ training_constraints.yaml
â”‚   â”‚   â”‚   â””â”€â”€ parameter_efficiency_requirements.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”‚   â”œâ”€â”€ realtime_monitoring.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ thresholds.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics_to_track.yaml
â”‚   â”‚   â”‚   â””â”€â”€ reporting_schedule.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”‚   â”œâ”€â”€ cross_validation_strategy.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ holdout_validation.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ test_set_protection.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ data_split_rules.yaml
â”‚   â”‚   â”‚   â””â”€â”€ hyperparameter_tuning_rules.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ recommendations/
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset_specific/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ag_news_recommendations.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ small_dataset.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ medium_dataset.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ large_dataset.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ model_recommendations/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ xlarge_models.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm_models.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ model_selection_guide.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ technique_recommendations/
â”‚   â”‚   â”‚       â”œâ”€â”€ lora_recommendations.yaml
â”‚   â”‚   â”‚       â”œâ”€â”€ qlora_recommendations.yaml
â”‚   â”‚   â”‚       â”œâ”€â”€ distillation_recommendations.yaml
â”‚   â”‚   â”‚       â””â”€â”€ ensemble_recommendations.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ safe_defaults/
â”‚   â”‚       â”œâ”€â”€ xlarge_safe_defaults.yaml
â”‚   â”‚       â”œâ”€â”€ llm_safe_defaults.yaml
â”‚   â”‚       â””â”€â”€ beginner_safe_defaults.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”‚   â”œâ”€â”€ standard.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ advanced.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_preprocessing.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_formatting.yaml
â”‚   â”‚   â”‚   â””â”€â”€ domain_specific.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ augmentation/
â”‚   â”‚   â”‚   â”œâ”€â”€ safe_augmentation.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ basic_augmentation.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ back_translation.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ paraphrase_generation.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_augmentation/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama_augmentation.yaml
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mistral_augmentation.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ controlled_generation.yaml
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ mixup_strategies.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ adversarial_augmentation.yaml
â”‚   â”‚   â”‚   â””â”€â”€ contrast_sets.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ selection/
â”‚   â”‚   â”‚   â”œâ”€â”€ coreset_selection.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ influence_functions.yaml
â”‚   â”‚   â”‚   â””â”€â”€ active_selection.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”‚   â”œâ”€â”€ stratified_split.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ k_fold_cv.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ nested_cv.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ time_based_split.yaml
â”‚   â”‚   â”‚   â””â”€â”€ holdout_validation.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ external/
â”‚   â”‚       â”œâ”€â”€ news_corpus.yaml
â”‚   â”‚       â”œâ”€â”€ wikipedia.yaml
â”‚   â”‚       â”œâ”€â”€ domain_adaptive_pretraining.yaml
â”‚   â”‚       â””â”€â”€ synthetic_data/
â”‚   â”‚           â”œâ”€â”€ llm_generated.yaml
â”‚   â”‚           â””â”€â”€ quality_filtering.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ deployment/
â”‚   â”‚   â”œâ”€â”€ local/
â”‚   â”‚   â”‚   â”œâ”€â”€ docker_local.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ api_local.yaml
â”‚   â”‚   â”‚   â””â”€â”€ inference_local.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ free_tier/
â”‚   â”‚   â”‚   â”œâ”€â”€ colab_deployment.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ kaggle_deployment.yaml
â”‚   â”‚   â”‚   â””â”€â”€ huggingface_spaces.yaml
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ platform_profiles/
â”‚   â”‚       â”œâ”€â”€ colab_profile.yaml
â”‚   â”‚       â”œâ”€â”€ kaggle_profile.yaml
â”‚   â”‚       â”œâ”€â”€ gitpod_profile.yaml
â”‚   â”‚       â”œâ”€â”€ codespaces_profile.yaml
â”‚   â”‚       â””â”€â”€ hf_spaces_profile.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ quotas/
â”‚   â”‚   â”œâ”€â”€ quota_limits.yaml
â”‚   â”‚   â”œâ”€â”€ quota_tracking.yaml
â”‚   â”‚   â””â”€â”€ platform_quotas.yaml
â”‚   â”‚
â”‚   â””â”€â”€ experiments/
â”‚       â”œâ”€â”€ baselines/
â”‚       â”‚   â”œâ”€â”€ classical_ml.yaml
â”‚       â”‚   â””â”€â”€ transformer_baseline.yaml
â”‚       â”‚
â”‚       â”œâ”€â”€ ablations/
â”‚       â”‚   â”œâ”€â”€ model_size_ablation.yaml
â”‚       â”‚   â”œâ”€â”€ data_amount.yaml
â”‚       â”‚   â”œâ”€â”€ lora_rank_ablation.yaml
â”‚       â”‚   â”œâ”€â”€ qlora_bits_ablation.yaml
â”‚       â”‚   â”œâ”€â”€ regularization_ablation.yaml
â”‚       â”‚   â”œâ”€â”€ augmentation_impact.yaml
â”‚       â”‚   â”œâ”€â”€ ensemble_size_ablation.yaml
â”‚       â”‚   â”œâ”€â”€ ensemble_components.yaml
â”‚       â”‚   â”œâ”€â”€ prompt_ablation.yaml
â”‚       â”‚   â””â”€â”€ distillation_temperature_ablation.yaml
â”‚       â”‚
â”‚       â”œâ”€â”€ hyperparameter_search/
â”‚       â”‚   â”œâ”€â”€ lora_search.yaml
â”‚       â”‚   â”œâ”€â”€ qlora_search.yaml
â”‚       â”‚   â”œâ”€â”€ regularization_search.yaml
â”‚       â”‚   â””â”€â”€ ensemble_weights_search.yaml
â”‚       â”‚
â”‚       â”œâ”€â”€ sota_experiments/
â”‚       â”‚   â”œâ”€â”€ phase1_xlarge_models.yaml
â”‚       â”‚   â”œâ”€â”€ phase2_llm_models.yaml
â”‚       â”‚   â”œâ”€â”€ phase3_llm_distillation.yaml
â”‚       â”‚   â”œâ”€â”€ phase4_ensemble_sota.yaml
â”‚       â”‚   â”œâ”€â”€ phase5_ultimate_sota.yaml
â”‚       â”‚   â””â”€â”€ phase6_production_sota.yaml
â”‚       â”‚
â”‚       â””â”€â”€ reproducibility/
â”‚           â”œâ”€â”€ seeds.yaml
â”‚           â””â”€â”€ hardware_specs.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ ag_news/
â”‚   â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ stratified_folds/
â”‚   â”‚   â”œâ”€â”€ instruction_formatted/
â”‚   â”‚   â””â”€â”€ .test_set_hash
â”‚   â”‚
â”‚   â”œâ”€â”€ augmented/
â”‚   â”‚   â”œâ”€â”€ back_translated/
â”‚   â”‚   â”œâ”€â”€ paraphrased/
â”‚   â”‚   â”œâ”€â”€ synthetic/
â”‚   â”‚   â”œâ”€â”€ llm_generated/
â”‚   â”‚   â”‚   â”œâ”€â”€ llama2/
â”‚   â”‚   â”‚   â”œâ”€â”€ mistral/
â”‚   â”‚   â”‚   â””â”€â”€ mixtral/
â”‚   â”‚   â”œâ”€â”€ mixup/
â”‚   â”‚   â””â”€â”€ contrast_sets/
â”‚   â”‚
â”‚   â”œâ”€â”€ external/
â”‚   â”‚   â”œâ”€â”€ news_corpus/
â”‚   â”‚   â”œâ”€â”€ pretrain_data/
â”‚   â”‚   â””â”€â”€ distillation_data/
â”‚   â”‚       â”œâ”€â”€ llama_outputs/
â”‚   â”‚       â”œâ”€â”€ mistral_outputs/
â”‚   â”‚       â””â”€â”€ teacher_ensemble_outputs/
â”‚   â”‚
â”‚   â”œâ”€â”€ pseudo_labeled/
â”‚   â”œâ”€â”€ selected_subsets/
â”‚   â”‚
â”‚   â”œâ”€â”€ test_samples/
â”‚   â”‚   â”œâ”€â”€ api_test_cases.json
â”‚   â”‚   â””â”€â”€ mock_responses.json
â”‚   â”‚
â”‚   â”œâ”€â”€ metadata/
â”‚   â”‚   â”œâ”€â”€ split_info.json
â”‚   â”‚   â”œâ”€â”€ statistics.json
â”‚   â”‚   â”œâ”€â”€ leakage_check.json
â”‚   â”‚   â””â”€â”€ model_predictions/
â”‚   â”‚       â”œâ”€â”€ xlarge_predictions.json
â”‚   â”‚       â”œâ”€â”€ llm_predictions.json
â”‚   â”‚       â””â”€â”€ ensemble_predictions.json
â”‚   â”‚
â”‚   â”œâ”€â”€ test_access_log.json
â”‚   â”‚
â”‚   â”œâ”€â”€ platform_cache/
â”‚   â”‚   â”œâ”€â”€ colab_cache/
â”‚   â”‚   â”œâ”€â”€ kaggle_cache/
â”‚   â”‚   â””â”€â”€ local_cache/
â”‚   â”‚
â”‚   â”œâ”€â”€ quota_tracking/
â”‚   â”‚   â”œâ”€â”€ quota_history.json
â”‚   â”‚   â”œâ”€â”€ session_logs.json
â”‚   â”‚   â””â”€â”€ platform_usage.db
â”‚   â”‚
â”‚   â””â”€â”€ cache/
â”‚       â”œâ”€â”€ local_cache/
â”‚       â”œâ”€â”€ model_cache/
â”‚       â””â”€â”€ huggingface_cache/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __version__.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â”‚
â”‚   â”œâ”€â”€ cli_commands/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auto_train.py
â”‚   â”‚   â”œâ”€â”€ choose_platform.py
â”‚   â”‚   â”œâ”€â”€ check_quota.py
â”‚   â”‚   â””â”€â”€ platform_info.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ registry.py
â”‚   â”‚   â”œâ”€â”€ factory.py
â”‚   â”‚   â”œâ”€â”€ types.py
â”‚   â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”‚   â”œâ”€â”€ interfaces.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ health/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ health_checker.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency_checker.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gpu_checker.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config_checker.py
â”‚   â”‚   â”‚   â””â”€â”€ data_checker.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ auto_fix/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config_fixer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dependency_fixer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ cache_cleaner.py
â”‚   â”‚   â”‚   â””â”€â”€ ide_sync_fixer.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ overfitting_prevention/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ validators/
â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚       â”‚   â”œâ”€â”€ test_set_validator.py
â”‚   â”‚       â”‚   â”œâ”€â”€ config_validator.py
â”‚   â”‚       â”‚   â”œâ”€â”€ data_leakage_detector.py
â”‚   â”‚       â”‚   â”œâ”€â”€ hyperparameter_validator.py
â”‚   â”‚       â”‚   â”œâ”€â”€ split_validator.py
â”‚   â”‚       â”‚   â”œâ”€â”€ model_size_validator.py
â”‚   â”‚       â”‚   â”œâ”€â”€ lora_config_validator.py
â”‚   â”‚       â”‚   â””â”€â”€ ensemble_validator.py
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ monitors/
â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚       â”‚   â”œâ”€â”€ training_monitor.py
â”‚   â”‚       â”‚   â”œâ”€â”€ overfitting_detector.py
â”‚   â”‚       â”‚   â”œâ”€â”€ complexity_monitor.py
â”‚   â”‚       â”‚   â”œâ”€â”€ benchmark_comparator.py
â”‚   â”‚       â”‚   â”œâ”€â”€ metrics_tracker.py
â”‚   â”‚       â”‚   â”œâ”€â”€ gradient_monitor.py
â”‚   â”‚       â”‚   â””â”€â”€ lora_rank_monitor.py
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ constraints/
â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚       â”‚   â”œâ”€â”€ model_constraints.py
â”‚   â”‚       â”‚   â”œâ”€â”€ ensemble_constraints.py
â”‚   â”‚       â”‚   â”œâ”€â”€ augmentation_constraints.py
â”‚   â”‚       â”‚   â”œâ”€â”€ training_constraints.py
â”‚   â”‚       â”‚   â”œâ”€â”€ constraint_enforcer.py
â”‚   â”‚       â”‚   â””â”€â”€ parameter_efficiency_enforcer.py
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ guards/
â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚       â”‚   â”œâ”€â”€ test_set_guard.py
â”‚   â”‚       â”‚   â”œâ”€â”€ validation_guard.py
â”‚   â”‚       â”‚   â”œâ”€â”€ experiment_guard.py
â”‚   â”‚       â”‚   â”œâ”€â”€ access_control.py
â”‚   â”‚       â”‚   â””â”€â”€ parameter_freeze_guard.py
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ recommendations/
â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚       â”‚   â”œâ”€â”€ model_recommender.py
â”‚   â”‚       â”‚   â”œâ”€â”€ config_recommender.py
â”‚   â”‚       â”‚   â”œâ”€â”€ prevention_recommender.py
â”‚   â”‚       â”‚   â”œâ”€â”€ ensemble_recommender.py
â”‚   â”‚       â”‚   â”œâ”€â”€ lora_recommender.py
â”‚   â”‚       â”‚   â”œâ”€â”€ distillation_recommender.py
â”‚   â”‚       â”‚   â””â”€â”€ parameter_efficiency_recommender.py
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ reporting/
â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚       â”‚   â”œâ”€â”€ overfitting_reporter.py
â”‚   â”‚       â”‚   â”œâ”€â”€ risk_scorer.py
â”‚   â”‚       â”‚   â”œâ”€â”€ comparison_reporter.py
â”‚   â”‚       â”‚   â”œâ”€â”€ html_report_generator.py
â”‚   â”‚       â”‚   â””â”€â”€ parameter_efficiency_reporter.py
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ utils/
â”‚   â”‚           â”œâ”€â”€ __init__.py
â”‚   â”‚           â”œâ”€â”€ hash_utils.py
â”‚   â”‚           â”œâ”€â”€ statistical_tests.py
â”‚   â”‚           â””â”€â”€ visualization_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ deployment/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ platform_detector.py
â”‚   â”‚   â”œâ”€â”€ smart_selector.py
â”‚   â”‚   â”œâ”€â”€ cache_manager.py
â”‚   â”‚   â”œâ”€â”€ checkpoint_manager.py
â”‚   â”‚   â”œâ”€â”€ quota_tracker.py
â”‚   â”‚   â”œâ”€â”€ storage_sync.py
â”‚   â”‚   â”œâ”€â”€ session_manager.py
â”‚   â”‚   â””â”€â”€ resource_monitor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base_handler.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ rate_limiter.py
â”‚   â”‚   â”‚   â”œâ”€â”€ error_handler.py
â”‚   â”‚   â”‚   â”œâ”€â”€ cors_handler.py
â”‚   â”‚   â”‚   â””â”€â”€ request_validator.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ rest/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ classification.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ training.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ data.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ health.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ overfitting.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ platform.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ admin.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ request_schemas.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ response_schemas.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ error_schemas.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ common_schemas.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ logging_middleware.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics_middleware.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ security_middleware.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”‚   â”‚   â”œâ”€â”€ validators.py
â”‚   â”‚   â”‚   â””â”€â”€ websocket_handler.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ local/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ simple_api.py
â”‚   â”‚       â”œâ”€â”€ batch_api.py
â”‚   â”‚       â””â”€â”€ streaming_api.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_service.py
â”‚   â”‚   â”œâ”€â”€ service_registry.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prediction_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ training_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model_management_service.py
â”‚   â”‚   â”‚   â””â”€â”€ llm_service.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ local/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ local_cache_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ local_queue_service.py
â”‚   â”‚   â”‚   â””â”€â”€ file_storage_service.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ monitoring/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ monitoring_router.py
â”‚   â”‚       â”œâ”€â”€ tensorboard_service.py
â”‚   â”‚       â”œâ”€â”€ mlflow_service.py
â”‚   â”‚       â”œâ”€â”€ wandb_service.py
â”‚   â”‚       â”œâ”€â”€ local_metrics_service.py
â”‚   â”‚       â””â”€â”€ logging_service.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ag_news.py
â”‚   â”‚   â”‚   â”œâ”€â”€ external_news.py
â”‚   â”‚   â”‚   â”œâ”€â”€ combined_dataset.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prompted_dataset.py
â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_dataset.py
â”‚   â”‚   â”‚   â””â”€â”€ distillation_dataset.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ text_cleaner.py
â”‚   â”‚   â”‚   â”œâ”€â”€ tokenization.py
â”‚   â”‚   â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”‚   â”‚   â”œâ”€â”€ sliding_window.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_formatter.py
â”‚   â”‚   â”‚   â””â”€â”€ instruction_formatter.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ augmentation/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base_augmenter.py
â”‚   â”‚   â”‚   â”œâ”€â”€ back_translation.py
â”‚   â”‚   â”‚   â”œâ”€â”€ paraphrase.py
â”‚   â”‚   â”‚   â”œâ”€â”€ token_replacement.py
â”‚   â”‚   â”‚   â”œâ”€â”€ mixup.py
â”‚   â”‚   â”‚   â”œâ”€â”€ cutmix.py
â”‚   â”‚   â”‚   â”œâ”€â”€ adversarial.py
â”‚   â”‚   â”‚   â”œâ”€â”€ contrast_set_generator.py
â”‚   â”‚   â”‚   â””â”€â”€ llm_augmenter/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ llama_augmenter.py
â”‚   â”‚   â”‚       â”œâ”€â”€ mistral_augmenter.py
â”‚   â”‚   â”‚       â””â”€â”€ controlled_generation.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ sampling/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ balanced_sampler.py
â”‚   â”‚   â”‚   â”œâ”€â”€ curriculum_sampler.py
â”‚   â”‚   â”‚   â”œâ”€â”€ active_learning.py
â”‚   â”‚   â”‚   â”œâ”€â”€ uncertainty_sampling.py
â”‚   â”‚   â”‚   â””â”€â”€ coreset_sampler.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ selection/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ influence_function.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gradient_matching.py
â”‚   â”‚   â”‚   â”œâ”€â”€ diversity_selection.py
â”‚   â”‚   â”‚   â””â”€â”€ quality_filtering.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ split_strategies.py
â”‚   â”‚   â”‚   â”œâ”€â”€ cross_validator.py
â”‚   â”‚   â”‚   â”œâ”€â”€ nested_cross_validator.py
â”‚   â”‚   â”‚   â””â”€â”€ holdout_manager.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ loaders/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ dataloader.py
â”‚   â”‚       â”œâ”€â”€ dynamic_batching.py
â”‚   â”‚       â””â”€â”€ prefetch_loader.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”‚   â”œâ”€â”€ base_model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model_wrapper.py
â”‚   â”‚   â”‚   â”œâ”€â”€ complexity_tracker.py
â”‚   â”‚   â”‚   â””â”€â”€ pooling_strategies.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ transformers/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ deberta/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v3_base.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v3_large.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v3_xlarge.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v2_xlarge.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_v2_xxlarge.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deberta_sliding_window.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ deberta_hierarchical.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ roberta/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ roberta_base.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ roberta_large.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ roberta_large_mnli.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ roberta_enhanced.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ roberta_domain.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ xlm_roberta_large.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ electra/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ electra_base.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ electra_large.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ electra_discriminator.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ xlnet/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ xlnet_base.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ xlnet_large.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ xlnet_classifier.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ longformer/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ longformer_large.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ longformer_global.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ t5/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ t5_base.py
â”‚   â”‚   â”‚       â”œâ”€â”€ t5_large.py
â”‚   â”‚   â”‚       â”œâ”€â”€ t5_3b.py
â”‚   â”‚   â”‚       â”œâ”€â”€ flan_t5_xl.py
â”‚   â”‚   â”‚       â””â”€â”€ t5_classifier.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ llama/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama2_7b.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama2_13b.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama2_70b.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama3_8b.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama3_70b.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ llama_for_classification.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ mistral/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mistral_7b.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mistral_7b_instruct.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mixtral_8x7b.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mistral_for_classification.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ falcon/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ falcon_7b.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ falcon_40b.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ falcon_for_classification.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ mpt/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mpt_7b.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mpt_30b.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mpt_for_classification.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ phi/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ phi_2.py
â”‚   â”‚   â”‚       â”œâ”€â”€ phi_3.py
â”‚   â”‚   â”‚       â””â”€â”€ phi_for_classification.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ prompt_based/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ soft_prompt.py
â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_model.py
â”‚   â”‚   â”‚   â””â”€â”€ template_manager.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ efficient/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ lora/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lora_model.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lora_config.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lora_layers.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lora_utils.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ rank_selection.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ target_modules_selector.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ qlora/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ qlora_model.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ qlora_config.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ quantization.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ dequantization.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_model.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_config.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ houlsby_adapter.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pfeiffer_adapter.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ parallel_adapter.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_fusion.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ adapter_stacking.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ prefix_tuning/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prefix_tuning_model.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prefix_encoder.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ prefix_length_selector.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_tuning/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ soft_prompt_model.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_encoder.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ p_tuning_v2.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ prompt_initialization.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ia3/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ia3_model.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ quantization/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ int8_quantization.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ dynamic_quantization.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ pruning/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ magnitude_pruning.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ combined/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ lora_plus_adapter.py
â”‚   â”‚   â”‚       â””â”€â”€ multi_method_model.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ensemble/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base_ensemble.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ensemble_selector.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ voting/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ soft_voting.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ hard_voting.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ weighted_voting.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ rank_averaging.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ confidence_weighted_voting.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ stacking/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ stacking_classifier.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ meta_learners.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cross_validation_stacking.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ neural_stacking.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ blending/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ blending_ensemble.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ dynamic_blending.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ advanced/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ bayesian_ensemble.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ snapshot_ensemble.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ multi_level_ensemble.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mixture_of_experts.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ diversity/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ diversity_calculator.py
â”‚   â”‚   â”‚       â”œâ”€â”€ diversity_optimizer.py
â”‚   â”‚   â”‚       â””â”€â”€ ensemble_pruning.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ heads/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ classification_head.py
â”‚   â”‚       â”œâ”€â”€ multitask_head.py
â”‚   â”‚       â”œâ”€â”€ hierarchical_head.py
â”‚   â”‚       â”œâ”€â”€ attention_head.py
â”‚   â”‚       â”œâ”€â”€ prompt_head.py
â”‚   â”‚       â””â”€â”€ adaptive_head.py
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ trainers/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ standard_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ distributed_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ apex_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ safe_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auto_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ lora_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ qlora_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_trainer.py
â”‚   â”‚   â”‚   â””â”€â”€ multi_stage_trainer.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ strategies/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ curriculum/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ curriculum_learning.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self_paced.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ competence_based.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ adversarial/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ fgm.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pgd.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ freelb.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ smart.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ regularization/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ r_drop.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mixout.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ spectral_norm.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adaptive_dropout.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ gradient_penalty.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ elastic_weight_consolidation.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ sharpness_aware_minimization.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ distillation/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ knowledge_distillation.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ feature_distillation.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ self_distillation.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama_distillation.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mistral_distillation.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ensemble_distillation.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ progressive_distillation.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ meta/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ maml.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ reptile.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_based/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_tuning.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prefix_tuning.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ p_tuning.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ soft_prompt_tuning.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ tpu_training.py
â”‚   â”‚   â”‚   â”œâ”€â”€ adaptive_training.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ multi_stage/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ stage_manager.py
â”‚   â”‚   â”‚       â”œâ”€â”€ progressive_training.py
â”‚   â”‚   â”‚       â”œâ”€â”€ iterative_refinement.py
â”‚   â”‚   â”‚       â””â”€â”€ base_to_xlarge_progression.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ objectives/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ losses/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ focal_loss.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ label_smoothing.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ contrastive_loss.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ triplet_loss.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ custom_ce_loss.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_loss.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ distillation_loss.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ regularizers/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ l2_regularizer.py
â”‚   â”‚   â”‚       â”œâ”€â”€ gradient_penalty.py
â”‚   â”‚   â”‚       â”œâ”€â”€ complexity_regularizer.py
â”‚   â”‚   â”‚       â””â”€â”€ parameter_norm_regularizer.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ optimization/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ optimizers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ adamw_custom.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lamb.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lookahead.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ sam.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ adafactor.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ schedulers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cosine_warmup.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ polynomial_decay.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cyclic_scheduler.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ inverse_sqrt_scheduler.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ gradient/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ gradient_accumulation.py
â”‚   â”‚   â”‚       â”œâ”€â”€ gradient_clipping.py
â”‚   â”‚   â”‚       â””â”€â”€ gradient_checkpointing.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ callbacks/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ early_stopping.py
â”‚   â”‚       â”œâ”€â”€ model_checkpoint.py
â”‚   â”‚       â”œâ”€â”€ tensorboard_logger.py
â”‚   â”‚       â”œâ”€â”€ wandb_logger.py
â”‚   â”‚       â”œâ”€â”€ mlflow_logger.py
â”‚   â”‚       â”œâ”€â”€ learning_rate_monitor.py
â”‚   â”‚       â”œâ”€â”€ overfitting_monitor.py
â”‚   â”‚       â”œâ”€â”€ complexity_regularizer_callback.py
â”‚   â”‚       â”œâ”€â”€ test_protection_callback.py
â”‚   â”‚       â”œâ”€â”€ lora_rank_callback.py
â”‚   â”‚       â”œâ”€â”€ memory_monitor_callback.py
â”‚   â”‚       â”œâ”€â”€ colab_callback.py
â”‚   â”‚       â”œâ”€â”€ kaggle_callback.py
â”‚   â”‚       â”œâ”€â”€ platform_callback.py
â”‚   â”‚       â”œâ”€â”€ quota_callback.py
â”‚   â”‚       â””â”€â”€ session_callback.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ classification_metrics.py
â”‚   â”‚   â”‚   â”œâ”€â”€ overfitting_metrics.py
â”‚   â”‚   â”‚   â”œâ”€â”€ diversity_metrics.py
â”‚   â”‚   â”‚   â””â”€â”€ efficiency_metrics.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ error_analysis.py
â”‚   â”‚   â”‚   â”œâ”€â”€ overfitting_analysis.py
â”‚   â”‚   â”‚   â”œâ”€â”€ train_val_test_comparison.py
â”‚   â”‚   â”‚   â”œâ”€â”€ lora_rank_analysis.py
â”‚   â”‚   â”‚   â””â”€â”€ ensemble_analysis.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ visualizations/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ training_curves.py
â”‚   â”‚       â”œâ”€â”€ confusion_matrix.py
â”‚   â”‚       â”œâ”€â”€ attention_visualization.py
â”‚   â”‚       â””â”€â”€ lora_weight_visualization.py
â”‚   â”‚
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ predictors/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ single_predictor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ensemble_predictor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ lora_predictor.py
â”‚   â”‚   â”‚   â””â”€â”€ qlora_predictor.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ optimization/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model_quantization.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model_pruning.py
â”‚   â”‚   â”‚   â”œâ”€â”€ onnx_export.py
â”‚   â”‚   â”‚   â””â”€â”€ openvino_optimization.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ serving/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ local_server.py
â”‚   â”‚       â”œâ”€â”€ batch_predictor.py
â”‚   â”‚       â””â”€â”€ streaming_predictor.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ io_utils.py
â”‚       â”œâ”€â”€ logging_config.py
â”‚       â”œâ”€â”€ reproducibility.py
â”‚       â”œâ”€â”€ distributed_utils.py
â”‚       â”œâ”€â”€ memory_utils.py
â”‚       â”œâ”€â”€ profiling_utils.py
â”‚       â”œâ”€â”€ experiment_tracking.py
â”‚       â”œâ”€â”€ prompt_utils.py
â”‚       â”œâ”€â”€ api_utils.py
â”‚       â”œâ”€â”€ local_utils.py
â”‚       â”œâ”€â”€ platform_utils.py
â”‚       â”œâ”€â”€ resource_utils.py
â”‚       â””â”€â”€ quota_utils.py
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ experiment_runner.py
â”‚   â”œâ”€â”€ experiment_tagger.py
â”‚   â”‚
â”‚   â”œâ”€â”€ hyperparameter_search/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ optuna_search.py
â”‚   â”‚   â”œâ”€â”€ ray_tune_search.py
â”‚   â”‚   â”œâ”€â”€ hyperband.py
â”‚   â”‚   â”œâ”€â”€ bayesian_optimization.py
â”‚   â”‚   â”œâ”€â”€ lora_rank_search.py
â”‚   â”‚   â””â”€â”€ ensemble_weight_search.py
â”‚   â”‚
â”‚   â”œâ”€â”€ benchmarks/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ speed_benchmark.py
â”‚   â”‚   â”œâ”€â”€ memory_benchmark.py
â”‚   â”‚   â”œâ”€â”€ accuracy_benchmark.py
â”‚   â”‚   â”œâ”€â”€ robustness_benchmark.py
â”‚   â”‚   â”œâ”€â”€ sota_comparison.py
â”‚   â”‚   â”œâ”€â”€ overfitting_benchmark.py
â”‚   â”‚   â””â”€â”€ parameter_efficiency_benchmark.py
â”‚   â”‚
â”‚   â”œâ”€â”€ baselines/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ classical/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ naive_bayes.py
â”‚   â”‚   â”‚   â”œâ”€â”€ svm_baseline.py
â”‚   â”‚   â”‚   â”œâ”€â”€ random_forest.py
â”‚   â”‚   â”‚   â””â”€â”€ logistic_regression.py
â”‚   â”‚   â””â”€â”€ neural/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ lstm_baseline.py
â”‚   â”‚       â”œâ”€â”€ cnn_baseline.py
â”‚   â”‚       â””â”€â”€ bert_vanilla.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ablation_studies/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ component_ablation.py
â”‚   â”‚   â”œâ”€â”€ data_ablation.py
â”‚   â”‚   â”œâ”€â”€ model_size_ablation.py
â”‚   â”‚   â”œâ”€â”€ feature_ablation.py
â”‚   â”‚   â”œâ”€â”€ lora_rank_ablation.py
â”‚   â”‚   â”œâ”€â”€ qlora_bits_ablation.py
â”‚   â”‚   â”œâ”€â”€ regularization_ablation.py
â”‚   â”‚   â”œâ”€â”€ prompt_ablation.py
â”‚   â”‚   â””â”€â”€ distillation_temperature_ablation.py
â”‚   â”‚
â”‚   â”œâ”€â”€ sota_experiments/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ phase1_xlarge_lora.py
â”‚   â”‚   â”œâ”€â”€ phase2_llm_qlora.py
â”‚   â”‚   â”œâ”€â”€ phase3_llm_distillation.py
â”‚   â”‚   â”œâ”€â”€ phase4_ensemble_xlarge.py
â”‚   â”‚   â”œâ”€â”€ phase5_ultimate_sota.py
â”‚   â”‚   â”œâ”€â”€ single_model_sota.py
â”‚   â”‚   â”œâ”€â”€ ensemble_sota.py
â”‚   â”‚   â”œâ”€â”€ full_pipeline_sota.py
â”‚   â”‚   â”œâ”€â”€ production_sota.py
â”‚   â”‚   â”œâ”€â”€ prompt_based_sota.py
â”‚   â”‚   â””â”€â”€ compare_all_approaches.py
â”‚   â”‚
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ experiment_tracker.py
â”‚       â”œâ”€â”€ result_aggregator.py
â”‚       â””â”€â”€ leaderboard_generator.py
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ local/
â”‚   â”‚   â”œâ”€â”€ docker-compose.local.yml
â”‚   â”‚   â”œâ”€â”€ tensorboard_config.yaml
â”‚   â”‚   â”œâ”€â”€ mlflow_config.yaml
â”‚   â”‚   â””â”€â”€ setup_local_monitoring.sh
â”‚   â”‚
â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”œâ”€â”€ tensorboard/
â”‚   â”‚   â”‚   â”œâ”€â”€ scalar_config.json
â”‚   â”‚   â”‚   â”œâ”€â”€ image_config.json
â”‚   â”‚   â”‚   â””â”€â”€ custom_scalars.json
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ mlflow/
â”‚   â”‚   â”‚   â”œâ”€â”€ experiment_dashboard.py
â”‚   â”‚   â”‚   â””â”€â”€ model_registry.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ wandb/
â”‚   â”‚   â”‚   â”œâ”€â”€ training_dashboard.json
â”‚   â”‚   â”‚   â”œâ”€â”€ overfitting_dashboard.json
â”‚   â”‚   â”‚   â””â”€â”€ parameter_efficiency_dashboard.json
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ platform_dashboard.json
â”‚   â”‚   â””â”€â”€ quota_dashboard.json
â”‚   â”‚
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ custom_metrics.py
â”‚   â”‚   â”œâ”€â”€ metric_collectors.py
â”‚   â”‚   â”œâ”€â”€ local_metrics.py
â”‚   â”‚   â”œâ”€â”€ model_metrics.py
â”‚   â”‚   â”œâ”€â”€ training_metrics.py
â”‚   â”‚   â”œâ”€â”€ overfitting_metrics.py
â”‚   â”‚   â”œâ”€â”€ platform_metrics.py
â”‚   â”‚   â””â”€â”€ quota_metrics.py
â”‚   â”‚
â”‚   â”œâ”€â”€ logs_analysis/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ log_parser.py
â”‚   â”‚   â”œâ”€â”€ anomaly_detector.py
â”‚   â”‚   â””â”€â”€ log_aggregator.py
â”‚   â”‚
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ start_tensorboard.sh
â”‚       â”œâ”€â”€ start_mlflow.sh
â”‚       â”œâ”€â”€ start_wandb.sh
â”‚       â”œâ”€â”€ monitor_platform.sh
â”‚       â”œâ”€â”€ export_metrics.py
â”‚       â”œâ”€â”€ export_quota_metrics.py
â”‚       â””â”€â”€ generate_report.py
â”‚
â”œâ”€â”€ security/
â”‚   â”œâ”€â”€ local_auth/
â”‚   â”‚   â”œâ”€â”€ simple_token.py
â”‚   â”‚   â””â”€â”€ local_rbac.py
â”‚   â”œâ”€â”€ data_privacy/
â”‚   â”‚   â”œâ”€â”€ pii_detector.py
â”‚   â”‚   â””â”€â”€ data_masking.py
â”‚   â””â”€â”€ model_security/
â”‚       â”œâ”€â”€ adversarial_defense.py
â”‚       â””â”€â”€ model_checksum.py
â”‚
â”œâ”€â”€ plugins/
â”‚   â”œâ”€â”€ custom_models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ plugin_interface.py
â”‚   â”œâ”€â”€ data_sources/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ custom_loaders/
â”‚   â”œâ”€â”€ evaluators/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ custom_metrics/
â”‚   â””â”€â”€ processors/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ custom_preprocessors/
â”‚
â”œâ”€â”€ migrations/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ 001_initial_schema.py
â”‚   â”‚   â””â”€â”€ migration_runner.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ version_converter.py
â”‚   â”‚   â””â”€â”€ compatibility_layer.py
â”‚   â””â”€â”€ configs/
â”‚       â””â”€â”€ config_migrator.py
â”‚
â”œâ”€â”€ cache/
â”‚   â”œâ”€â”€ local/
â”‚   â”‚   â”œâ”€â”€ disk_cache.py
â”‚   â”‚   â”œâ”€â”€ memory_cache.py
â”‚   â”‚   â””â”€â”€ lru_cache.py
â”‚   â”‚
â”‚   â””â”€â”€ sqlite/
â”‚       â””â”€â”€ cache_db_schema.sql
â”‚
â”œâ”€â”€ backup/
â”‚   â”œâ”€â”€ strategies/
â”‚   â”‚   â”œâ”€â”€ incremental_backup.yaml
â”‚   â”‚   â””â”€â”€ local_backup.yaml
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ backup_local.sh
â”‚   â”‚   â””â”€â”€ restore_local.sh
â”‚   â””â”€â”€ recovery/
â”‚       â””â”€â”€ local_recovery_plan.md
â”‚
â”œâ”€â”€ quickstart/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ SIMPLE_START.md
â”‚   â”œâ”€â”€ setup_wizard.py
â”‚   â”œâ”€â”€ interactive_cli.py
â”‚   â”œâ”€â”€ decision_tree.py
â”‚   â”œâ”€â”€ minimal_example.py
â”‚   â”œâ”€â”€ train_simple.py
â”‚   â”œâ”€â”€ evaluate_simple.py
â”‚   â”œâ”€â”€ demo_app.py
â”‚   â”œâ”€â”€ local_api_quickstart.py
â”‚   â”œâ”€â”€ auto_start.py
â”‚   â”œâ”€â”€ auto_train_demo.py
â”‚   â”œâ”€â”€ colab_notebook.ipynb
â”‚   â”œâ”€â”€ kaggle_notebook.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ use_cases/
â”‚   â”‚   â”œâ”€â”€ quick_demo_5min.py
â”‚   â”‚   â”œâ”€â”€ auto_demo_2min.py
â”‚   â”‚   â”œâ”€â”€ research_experiment_30min.py
â”‚   â”‚   â”œâ”€â”€ production_deployment_1hr.py
â”‚   â”‚   â”œâ”€â”€ learning_exploration.py
â”‚   â”‚   â””â”€â”€ platform_comparison_demo.py
â”‚   â”‚
â”‚   â””â”€â”€ docker_quickstart/
â”‚       â”œâ”€â”€ Dockerfile.local
â”‚       â””â”€â”€ docker-compose.local.yml
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ experiment/
â”‚   â”‚   â”œâ”€â”€ experiment_template.py
â”‚   â”‚   â””â”€â”€ config_template.yaml
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ model_template.py
â”‚   â”‚   â””â”€â”€ README_template.md
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â””â”€â”€ dataset_template.py
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â””â”€â”€ metric_template.py
â”‚   â””â”€â”€ ide/
â”‚       â”œâ”€â”€ pycharm_run_config.xml
â”‚       â”œâ”€â”€ vscode_task.json
â”‚       â””â”€â”€ jupyter_template.ipynb
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup/
â”‚   â”‚   â”œâ”€â”€ download_all_data.py
â”‚   â”‚   â”œâ”€â”€ setup_local_environment.sh
â”‚   â”‚   â”œâ”€â”€ setup_platform.py
â”‚   â”‚   â”œâ”€â”€ setup_colab.sh
â”‚   â”‚   â”œâ”€â”€ setup_kaggle.sh
â”‚   â”‚   â”œâ”€â”€ verify_installation.py
â”‚   â”‚   â”œâ”€â”€ verify_dependencies.py
â”‚   â”‚   â”œâ”€â”€ verify_platform.py
â”‚   â”‚   â”œâ”€â”€ optimize_for_platform.sh
â”‚   â”‚   â””â”€â”€ download_pretrained_models.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_preparation/
â”‚   â”‚   â”œâ”€â”€ prepare_ag_news.py
â”‚   â”‚   â”œâ”€â”€ prepare_external_data.py
â”‚   â”‚   â”œâ”€â”€ create_augmented_data.py
â”‚   â”‚   â”œâ”€â”€ create_instruction_data.py
â”‚   â”‚   â”œâ”€â”€ generate_with_llama.py
â”‚   â”‚   â”œâ”€â”€ generate_with_mistral.py
â”‚   â”‚   â”œâ”€â”€ generate_pseudo_labels.py
â”‚   â”‚   â”œâ”€â”€ create_data_splits.py
â”‚   â”‚   â”œâ”€â”€ generate_contrast_sets.py
â”‚   â”‚   â”œâ”€â”€ select_quality_data.py
â”‚   â”‚   â”œâ”€â”€ verify_data_splits.py
â”‚   â”‚   â””â”€â”€ register_test_set.py
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ single_model/
â”‚   â”‚   â”‚   â”œâ”€â”€ train_xlarge_lora.py
â”‚   â”‚   â”‚   â”œâ”€â”€ train_xxlarge_qlora.py
â”‚   â”‚   â”‚   â”œâ”€â”€ train_llm_qlora.py
â”‚   â”‚   â”‚   â””â”€â”€ train_with_adapters.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ensemble/
â”‚   â”‚   â”‚   â”œâ”€â”€ train_xlarge_ensemble.py
â”‚   â”‚   â”‚   â”œâ”€â”€ train_llm_ensemble.py
â”‚   â”‚   â”‚   â””â”€â”€ train_hybrid_ensemble.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ distillation/
â”‚   â”‚   â”‚   â”œâ”€â”€ distill_from_llama.py
â”‚   â”‚   â”‚   â”œâ”€â”€ distill_from_mistral.py
â”‚   â”‚   â”‚   â”œâ”€â”€ distill_from_ensemble.py
â”‚   â”‚   â”‚   â””â”€â”€ progressive_distillation.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ instruction_tuning/
â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_tuning_llama.py
â”‚   â”‚   â”‚   â””â”€â”€ instruction_tuning_mistral.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ multi_stage/
â”‚   â”‚   â”‚   â”œâ”€â”€ base_to_xlarge.py
â”‚   â”‚   â”‚   â””â”€â”€ pretrain_finetune_distill.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ auto_train.sh
â”‚   â”‚   â”œâ”€â”€ train_all_models.sh
â”‚   â”‚   â”œâ”€â”€ train_single_model.py
â”‚   â”‚   â”œâ”€â”€ train_ensemble.py
â”‚   â”‚   â”œâ”€â”€ train_local.py
â”‚   â”‚   â”œâ”€â”€ resume_training.py
â”‚   â”‚   â””â”€â”€ train_with_prompts.py
â”‚   â”‚
â”‚   â”œâ”€â”€ domain_adaptation/
â”‚   â”‚   â”œâ”€â”€ pretrain_on_news.py
â”‚   â”‚   â”œâ”€â”€ download_news_corpus.py
â”‚   â”‚   â””â”€â”€ run_dapt.sh
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ evaluate_all_models.py
â”‚   â”‚   â”œâ”€â”€ evaluate_with_guard.py
â”‚   â”‚   â”œâ”€â”€ final_evaluation.py
â”‚   â”‚   â”œâ”€â”€ generate_reports.py
â”‚   â”‚   â”œâ”€â”€ create_leaderboard.py
â”‚   â”‚   â”œâ”€â”€ check_overfitting.py
â”‚   â”‚   â”œâ”€â”€ evaluate_parameter_efficiency.py
â”‚   â”‚   â”œâ”€â”€ statistical_analysis.py
â”‚   â”‚   â””â”€â”€ evaluate_contrast_sets.py
â”‚   â”‚
â”‚   â”œâ”€â”€ optimization/
â”‚   â”‚   â”œâ”€â”€ hyperparameter_search.py
â”‚   â”‚   â”œâ”€â”€ lora_rank_search.py
â”‚   â”‚   â”œâ”€â”€ ensemble_optimization.py
â”‚   â”‚   â”œâ”€â”€ quantization_optimization.py
â”‚   â”‚   â”œâ”€â”€ architecture_search.py
â”‚   â”‚   â””â”€â”€ prompt_optimization.py
â”‚   â”‚
â”‚   â”œâ”€â”€ deployment/
â”‚   â”‚   â”œâ”€â”€ export_models.py
â”‚   â”‚   â”œâ”€â”€ optimize_for_inference.py
â”‚   â”‚   â”œâ”€â”€ create_docker_local.sh
â”‚   â”‚   â”œâ”€â”€ deploy_to_local.py
â”‚   â”‚   â”œâ”€â”€ deploy_auto.py
â”‚   â”‚   â””â”€â”€ deploy_to_hf_spaces.py
â”‚   â”‚
â”‚   â”œâ”€â”€ overfitting_prevention/
â”‚   â”‚   â”œâ”€â”€ get_model_recommendations.py
â”‚   â”‚   â”œâ”€â”€ validate_experiment_config.py
â”‚   â”‚   â”œâ”€â”€ check_data_leakage.py
â”‚   â”‚   â”œâ”€â”€ monitor_training_live.py
â”‚   â”‚   â””â”€â”€ generate_overfitting_report.py
â”‚   â”‚
â”‚   â”œâ”€â”€ platform/
â”‚   â”‚   â”œâ”€â”€ colab/
â”‚   â”‚   â”‚   â”œâ”€â”€ mount_drive.py
â”‚   â”‚   â”‚   â”œâ”€â”€ setup_colab.py
â”‚   â”‚   â”‚   â””â”€â”€ keep_alive.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ kaggle/
â”‚   â”‚   â”‚   â”œâ”€â”€ setup_kaggle.py
â”‚   â”‚   â”‚   â”œâ”€â”€ setup_tpu.py
â”‚   â”‚   â”‚   â””â”€â”€ create_dataset.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ local/
â”‚   â”‚       â”œâ”€â”€ detect_gpu.py
â”‚   â”‚       â””â”€â”€ optimize_local.py
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ monitor_quota.py
â”‚   â”‚   â””â”€â”€ monitor_session.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ide/
â”‚   â”‚   â”œâ”€â”€ setup_pycharm.py
â”‚   â”‚   â”œâ”€â”€ setup_vscode.py
â”‚   â”‚   â”œâ”€â”€ setup_jupyter.py
â”‚   â”‚   â”œâ”€â”€ setup_vim.py
â”‚   â”‚   â””â”€â”€ setup_all_ides.sh
â”‚   â”‚
â”‚   â”œâ”€â”€ local/
â”‚   â”‚   â”œâ”€â”€ start_local_api.sh
â”‚   â”‚   â”œâ”€â”€ start_monitoring.sh
â”‚   â”‚   â”œâ”€â”€ cleanup_cache.sh
â”‚   â”‚   â””â”€â”€ backup_experiments.sh
â”‚   â”‚
â”‚   â””â”€â”€ ci/
â”‚       â”œâ”€â”€ run_tests.sh
â”‚       â”œâ”€â”€ run_benchmarks.sh
â”‚       â”œâ”€â”€ build_docker_local.sh
â”‚       â”œâ”€â”€ test_local_deployment.sh
â”‚       â”œâ”€â”€ check_docs_sync.py
â”‚       â””â”€â”€ verify_all.sh
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ classification/
â”‚   â”‚   â”œâ”€â”€ zero_shot.txt
â”‚   â”‚   â”œâ”€â”€ few_shot.txt
â”‚   â”‚   â””â”€â”€ chain_of_thought.txt
â”‚   â”œâ”€â”€ instruction/
â”‚   â”‚   â”œâ”€â”€ base_instruction.txt
â”‚   â”‚   â”œâ”€â”€ detailed_instruction.txt
â”‚   â”‚   â””â”€â”€ task_specific.txt
â”‚   â””â”€â”€ distillation/
â”‚       â”œâ”€â”€ llm_prompts.txt
â”‚       â””â”€â”€ explanation_prompts.txt
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ 00_setup/
â”‚   â”‚   â”œâ”€â”€ 00_auto_setup.ipynb
â”‚   â”‚   â”œâ”€â”€ 00_local_setup.ipynb
â”‚   â”‚   â”œâ”€â”€ 01_colab_setup.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_kaggle_setup.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_vscode_setup.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_pycharm_setup.ipynb
â”‚   â”‚   â””â”€â”€ 05_jupyterlab_setup.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ 01_tutorials/
â”‚   â”‚   â”œâ”€â”€ 00_auto_training_tutorial.ipynb
â”‚   â”‚   â”œâ”€â”€ 00_environment_setup.ipynb
â”‚   â”‚   â”œâ”€â”€ 01_data_loading_basics.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_preprocessing_tutorial.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_model_training_basics.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_lora_tutorial.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_qlora_tutorial.ipynb
â”‚   â”‚   â”œâ”€â”€ 06_distillation_tutorial.ipynb
â”‚   â”‚   â”œâ”€â”€ 07_ensemble_tutorial.ipynb
â”‚   â”‚   â”œâ”€â”€ 08_overfitting_prevention.ipynb
â”‚   â”‚   â”œâ”€â”€ 09_safe_training_workflow.ipynb
â”‚   â”‚   â”œâ”€â”€ 10_evaluation_tutorial.ipynb
â”‚   â”‚   â”œâ”€â”€ 11_prompt_engineering.ipynb
â”‚   â”‚   â”œâ”€â”€ 12_instruction_tuning.ipynb
â”‚   â”‚   â”œâ”€â”€ 13_local_api_usage.ipynb
â”‚   â”‚   â”œâ”€â”€ 14_monitoring_setup.ipynb
â”‚   â”‚   â”œâ”€â”€ 15_platform_optimization.ipynb
â”‚   â”‚   â””â”€â”€ 16_quota_management.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ 02_exploratory/
â”‚   â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_model_size_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_parameter_efficiency_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_data_statistics.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_label_distribution.ipynb
â”‚   â”‚   â”œâ”€â”€ 06_text_length_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ 07_vocabulary_analysis.ipynb
â”‚   â”‚   â””â”€â”€ 08_contrast_set_exploration.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ 03_experiments/
â”‚   â”‚   â”œâ”€â”€ 01_baseline_experiments.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_xlarge_lora_experiments.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_llm_qlora_experiments.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_ensemble_experiments.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_distillation_experiments.ipynb
â”‚   â”‚   â”œâ”€â”€ 06_sota_experiments.ipynb
â”‚   â”‚   â”œâ”€â”€ 07_ablation_studies.ipynb
â”‚   â”‚   â”œâ”€â”€ 08_sota_reproduction.ipynb
â”‚   â”‚   â”œâ”€â”€ 09_prompt_experiments.ipynb
â”‚   â”‚   â””â”€â”€ 10_single_model_experiments.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ 04_analysis/
â”‚   â”‚   â”œâ”€â”€ 01_error_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_overfitting_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_lora_rank_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_ensemble_diversity_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_parameter_efficiency_comparison.ipynb
â”‚   â”‚   â”œâ”€â”€ 06_model_interpretability.ipynb
â”‚   â”‚   â”œâ”€â”€ 07_attention_visualization.ipynb
â”‚   â”‚   â”œâ”€â”€ 08_embedding_analysis.ipynb
â”‚   â”‚   â””â”€â”€ 09_failure_cases.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ 05_deployment/
â”‚   â”‚   â”œâ”€â”€ 01_model_export.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_quantization.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_local_serving.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_model_optimization.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_inference_pipeline.ipynb
â”‚   â”‚   â”œâ”€â”€ 06_api_demo.ipynb
â”‚   â”‚   â””â”€â”€ 07_hf_spaces_deploy.ipynb
â”‚   â”‚
â”‚   â””â”€â”€ 06_platform_specific/
â”‚       â”œâ”€â”€ local/
â”‚       â”‚   â”œâ”€â”€ auto_training_local.ipynb
â”‚       â”‚   â”œâ”€â”€ cpu_training.ipynb
â”‚       â”‚   â”œâ”€â”€ gpu_training.ipynb
â”‚       â”‚   â”œâ”€â”€ multi_gpu_local.ipynb
â”‚       â”‚   â””â”€â”€ inference_demo.ipynb
â”‚       â”‚
â”‚       â”œâ”€â”€ colab/
â”‚       â”‚   â”œâ”€â”€ auto_training_colab.ipynb
â”‚       â”‚   â”œâ”€â”€ quick_start_colab.ipynb
â”‚       â”‚   â”œâ”€â”€ full_training_colab.ipynb
â”‚       â”‚   â”œâ”€â”€ drive_optimization.ipynb
â”‚       â”‚   â”œâ”€â”€ keep_alive_demo.ipynb
â”‚       â”‚   â””â”€â”€ inference_demo_colab.ipynb
â”‚       â”‚
â”‚       â”œâ”€â”€ kaggle/
â”‚       â”‚   â”œâ”€â”€ auto_training_kaggle.ipynb
â”‚       â”‚   â”œâ”€â”€ kaggle_submission.ipynb
â”‚       â”‚   â”œâ”€â”€ kaggle_training.ipynb
â”‚       â”‚   â”œâ”€â”€ tpu_training.ipynb
â”‚       â”‚   â””â”€â”€ dataset_caching.ipynb
â”‚       â”‚
â”‚       â””â”€â”€ huggingface/
â”‚           â””â”€â”€ spaces_demo.ipynb
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â”œâ”€â”€ gradio_app.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ 01_Home.py
â”‚   â”‚   â”œâ”€â”€ 02_Single_Prediction.py
â”‚   â”‚   â”œâ”€â”€ 03_Batch_Analysis.py
â”‚   â”‚   â”œâ”€â”€ 04_Model_Comparison.py
â”‚   â”‚   â”œâ”€â”€ 05_Overfitting_Dashboard.py
â”‚   â”‚   â”œâ”€â”€ 06_Model_Recommender.py
â”‚   â”‚   â”œâ”€â”€ 07_Parameter_Efficiency_Dashboard.py
â”‚   â”‚   â”œâ”€â”€ 08_Interpretability.py
â”‚   â”‚   â”œâ”€â”€ 09_Performance_Dashboard.py
â”‚   â”‚   â”œâ”€â”€ 10_Real_Time_Demo.py
â”‚   â”‚   â”œâ”€â”€ 11_Model_Selection.py
â”‚   â”‚   â”œâ”€â”€ 12_Documentation.py
â”‚   â”‚   â”œâ”€â”€ 13_Prompt_Testing.py
â”‚   â”‚   â”œâ”€â”€ 14_Local_Monitoring.py
â”‚   â”‚   â”œâ”€â”€ 15_IDE_Setup_Guide.py
â”‚   â”‚   â”œâ”€â”€ 16_Experiment_Tracker.py
â”‚   â”‚   â”œâ”€â”€ 17_Platform_Info.py
â”‚   â”‚   â”œâ”€â”€ 18_Quota_Dashboard.py
â”‚   â”‚   â”œâ”€â”€ 19_Platform_Selector.py
â”‚   â”‚   â””â”€â”€ 20_Auto_Train_UI.py
â”‚   â”‚
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prediction_component.py
â”‚   â”‚   â”œâ”€â”€ overfitting_monitor.py
â”‚   â”‚   â”œâ”€â”€ lora_config_selector.py
â”‚   â”‚   â”œâ”€â”€ ensemble_builder.py
â”‚   â”‚   â”œâ”€â”€ visualization_component.py
â”‚   â”‚   â”œâ”€â”€ model_selector.py
â”‚   â”‚   â”œâ”€â”€ file_uploader.py
â”‚   â”‚   â”œâ”€â”€ result_display.py
â”‚   â”‚   â”œâ”€â”€ performance_monitor.py
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py
â”‚   â”‚   â”œâ”€â”€ ide_configurator.py
â”‚   â”‚   â”œâ”€â”€ platform_info_component.py
â”‚   â”‚   â”œâ”€â”€ quota_monitor_component.py
â”‚   â”‚   â””â”€â”€ resource_gauge.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ session_manager.py
â”‚   â”‚   â”œâ”€â”€ caching.py
â”‚   â”‚   â”œâ”€â”€ theming.py
â”‚   â”‚   â””â”€â”€ helpers.py
â”‚   â”‚
â”‚   â””â”€â”€ assets/
â”‚       â”œâ”€â”€ css/
â”‚       â”‚   â””â”€â”€ custom.css
â”‚       â”œâ”€â”€ js/
â”‚       â”‚   â””â”€â”€ custom.js
â”‚       â””â”€â”€ images/
â”‚           â”œâ”€â”€ logo.png
â”‚           â””â”€â”€ banner.png
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”œâ”€â”€ pretrained/
â”‚   â”‚   â”œâ”€â”€ fine_tuned/
â”‚   â”‚   â”œâ”€â”€ lora_adapters/
â”‚   â”‚   â”œâ”€â”€ qlora_adapters/
â”‚   â”‚   â”œâ”€â”€ ensembles/
â”‚   â”‚   â”œâ”€â”€ distilled/
â”‚   â”‚   â”œâ”€â”€ optimized/
â”‚   â”‚   â”œâ”€â”€ exported/
â”‚   â”‚   â””â”€â”€ prompted/
â”‚   â”‚
â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”œâ”€â”€ experiments/
â”‚   â”‚   â”œâ”€â”€ benchmarks/
â”‚   â”‚   â”œâ”€â”€ overfitting_reports/
â”‚   â”‚   â”œâ”€â”€ parameter_efficiency_reports/
â”‚   â”‚   â”œâ”€â”€ ablations/
â”‚   â”‚   â””â”€â”€ reports/
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ error_analysis/
â”‚   â”‚   â”œâ”€â”€ interpretability/
â”‚   â”‚   â””â”€â”€ statistical/
â”‚   â”‚
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ tensorboard/
â”‚   â”‚   â”œâ”€â”€ mlflow/
â”‚   â”‚   â”œâ”€â”€ wandb/
â”‚   â”‚   â””â”€â”€ local/
â”‚   â”‚
â”‚   â”œâ”€â”€ profiling/
â”‚   â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ speed/
â”‚   â”‚   â””â”€â”€ traces/
â”‚   â”‚
â”‚   â””â”€â”€ artifacts/
â”‚       â”œâ”€â”€ figures/
â”‚       â”œâ”€â”€ tables/
â”‚       â”œâ”€â”€ lora_visualizations/
â”‚       â””â”€â”€ presentations/
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ index.md
â”‚   â”œâ”€â”€ 00_START_HERE.md
â”‚   â”œâ”€â”€ limitations.md
â”‚   â”œâ”€â”€ ethical_considerations.md
â”‚   â”‚
â”‚   â”œâ”€â”€ getting_started/
â”‚   â”‚   â”œâ”€â”€ installation.md
â”‚   â”‚   â”œâ”€â”€ local_setup.md
â”‚   â”‚   â”œâ”€â”€ ide_setup.md
â”‚   â”‚   â”œâ”€â”€ quickstart.md
â”‚   â”‚   â”œâ”€â”€ auto_mode.md
â”‚   â”‚   â”œâ”€â”€ platform_detection.md
â”‚   â”‚   â”œâ”€â”€ overfitting_prevention_quickstart.md
â”‚   â”‚   â”œâ”€â”€ choosing_model.md
â”‚   â”‚   â”œâ”€â”€ choosing_platform.md
â”‚   â”‚   â”œâ”€â”€ free_deployment.md
â”‚   â”‚   â””â”€â”€ troubleshooting.md
â”‚   â”‚
â”‚   â”œâ”€â”€ level_1_beginner/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ 01_installation.md
â”‚   â”‚   â”œâ”€â”€ 02_first_model.md
â”‚   â”‚   â”œâ”€â”€ 03_evaluation.md
â”‚   â”‚   â”œâ”€â”€ 04_deployment.md
â”‚   â”‚   â””â”€â”€ quick_demo.md
â”‚   â”‚
â”‚   â”œâ”€â”€ level_2_intermediate/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ 01_lora_qlora.md
â”‚   â”‚   â”œâ”€â”€ 02_ensemble.md
â”‚   â”‚   â”œâ”€â”€ 03_distillation.md
â”‚   â”‚   â””â”€â”€ 04_optimization.md
â”‚   â”‚
â”‚   â”œâ”€â”€ level_3_advanced/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ 01_sota_pipeline.md
â”‚   â”‚   â”œâ”€â”€ 02_custom_models.md
â”‚   â”‚   â””â”€â”€ 03_research_workflow.md
â”‚   â”‚
â”‚   â”œâ”€â”€ platform_guides/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ colab_guide.md
â”‚   â”‚   â”œâ”€â”€ colab_advanced.md
â”‚   â”‚   â”œâ”€â”€ kaggle_guide.md
â”‚   â”‚   â”œâ”€â”€ kaggle_tpu.md
â”‚   â”‚   â”œâ”€â”€ local_guide.md
â”‚   â”‚   â”œâ”€â”€ gitpod_guide.md
â”‚   â”‚   â””â”€â”€ platform_comparison.md
â”‚   â”‚
â”‚   â”œâ”€â”€ user_guide/
â”‚   â”‚   â”œâ”€â”€ data_preparation.md
â”‚   â”‚   â”œâ”€â”€ model_training.md
â”‚   â”‚   â”œâ”€â”€ auto_training.md
â”‚   â”‚   â”œâ”€â”€ lora_guide.md
â”‚   â”‚   â”œâ”€â”€ qlora_guide.md
â”‚   â”‚   â”œâ”€â”€ distillation_guide.md
â”‚   â”‚   â”œâ”€â”€ ensemble_guide.md
â”‚   â”‚   â”œâ”€â”€ overfitting_prevention.md
â”‚   â”‚   â”œâ”€â”€ safe_training_practices.md
â”‚   â”‚   â”œâ”€â”€ evaluation.md
â”‚   â”‚   â”œâ”€â”€ local_deployment.md
â”‚   â”‚   â”œâ”€â”€ quota_management.md
â”‚   â”‚   â”œâ”€â”€ platform_optimization.md
â”‚   â”‚   â”œâ”€â”€ prompt_engineering.md
â”‚   â”‚   â””â”€â”€ advanced_techniques.md
â”‚   â”‚
â”‚   â”œâ”€â”€ developer_guide/
â”‚   â”‚   â”œâ”€â”€ architecture.md
â”‚   â”‚   â”œâ”€â”€ adding_models.md
â”‚   â”‚   â”œâ”€â”€ custom_datasets.md
â”‚   â”‚   â”œâ”€â”€ local_api_development.md
â”‚   â”‚   â””â”€â”€ contributing.md
â”‚   â”‚
â”‚   â”œâ”€â”€ api_reference/
â”‚   â”‚   â”œâ”€â”€ rest_api.md
â”‚   â”‚   â”œâ”€â”€ data_api.md
â”‚   â”‚   â”œâ”€â”€ models_api.md
â”‚   â”‚   â”œâ”€â”€ training_api.md
â”‚   â”‚   â”œâ”€â”€ lora_api.md
â”‚   â”‚   â”œâ”€â”€ ensemble_api.md
â”‚   â”‚   â”œâ”€â”€ overfitting_prevention_api.md
â”‚   â”‚   â”œâ”€â”€ platform_api.md
â”‚   â”‚   â”œâ”€â”€ quota_api.md
â”‚   â”‚   â””â”€â”€ evaluation_api.md
â”‚   â”‚
â”‚   â”œâ”€â”€ ide_guides/
â”‚   â”‚   â”œâ”€â”€ vscode_guide.md
â”‚   â”‚   â”œâ”€â”€ pycharm_guide.md
â”‚   â”‚   â”œâ”€â”€ jupyter_guide.md
â”‚   â”‚   â”œâ”€â”€ vim_guide.md
â”‚   â”‚   â”œâ”€â”€ sublime_guide.md
â”‚   â”‚   â””â”€â”€ comparison.md
â”‚   â”‚
â”‚   â”œâ”€â”€ tutorials/
â”‚   â”‚   â”œâ”€â”€ basic_usage.md
â”‚   â”‚   â”œâ”€â”€ xlarge_model_tutorial.md
â”‚   â”‚   â”œâ”€â”€ llm_tutorial.md
â”‚   â”‚   â”œâ”€â”€ distillation_tutorial.md
â”‚   â”‚   â”œâ”€â”€ sota_pipeline_tutorial.md
â”‚   â”‚   â”œâ”€â”€ local_training_tutorial.md
â”‚   â”‚   â”œâ”€â”€ free_deployment_tutorial.md
â”‚   â”‚   â””â”€â”€ best_practices.md
â”‚   â”‚
â”‚   â”œâ”€â”€ best_practices/
â”‚   â”‚   â”œâ”€â”€ model_selection.md
â”‚   â”‚   â”œâ”€â”€ parameter_efficient_finetuning.md
â”‚   â”‚   â”œâ”€â”€ avoiding_overfitting.md
â”‚   â”‚   â”œâ”€â”€ local_optimization.md
â”‚   â”‚   â””â”€â”€ ensemble_building.md
â”‚   â”‚
â”‚   â”œâ”€â”€ examples/
â”‚   â”‚   â”œâ”€â”€ 00_hello_world.md
â”‚   â”‚   â”œâ”€â”€ 01_train_baseline.md
â”‚   â”‚   â”œâ”€â”€ 02_sota_pipeline.md
â”‚   â”‚   â””â”€â”€ 03_custom_model.md
â”‚   â”‚
â”‚   â”œâ”€â”€ cheatsheets/
â”‚   â”‚   â”œâ”€â”€ model_selection_cheatsheet.pdf
â”‚   â”‚   â”œâ”€â”€ overfitting_prevention_checklist.pdf
â”‚   â”‚   â”œâ”€â”€ free_deployment_comparison.pdf
â”‚   â”‚   â”œâ”€â”€ platform_comparison_chart.pdf
â”‚   â”‚   â”œâ”€â”€ auto_train_cheatsheet.pdf
â”‚   â”‚   â”œâ”€â”€ quota_limits_reference.pdf
â”‚   â”‚   â””â”€â”€ cli_commands.pdf
â”‚   â”‚
â”‚   â”œâ”€â”€ troubleshooting/
â”‚   â”‚   â”œâ”€â”€ platform_issues.md
â”‚   â”‚   â””â”€â”€ quota_issues.md
â”‚   â”‚
â”‚   â”œâ”€â”€ architecture/
â”‚   â”‚   â”œâ”€â”€ decisions/
â”‚   â”‚   â”‚   â”œâ”€â”€ 001-model-selection.md
â”‚   â”‚   â”‚   â”œâ”€â”€ 002-ensemble-strategy.md
â”‚   â”‚   â”‚   â”œâ”€â”€ 003-local-first-design.md
â”‚   â”‚   â”‚   â”œâ”€â”€ 004-overfitting-prevention.md
â”‚   â”‚   â”‚   â””â”€â”€ 005-parameter-efficiency.md
â”‚   â”‚   â”œâ”€â”€ diagrams/
â”‚   â”‚   â”‚   â”œâ”€â”€ system-overview.puml
â”‚   â”‚   â”‚   â”œâ”€â”€ data-flow.puml
â”‚   â”‚   â”‚   â”œâ”€â”€ local-deployment.puml
â”‚   â”‚   â”‚   â””â”€â”€ overfitting-prevention-flow.puml
â”‚   â”‚   â””â”€â”€ patterns/
â”‚   â”‚       â”œâ”€â”€ factory-pattern.md
â”‚   â”‚       â””â”€â”€ strategy-pattern.md
â”‚   â”‚
â”‚   â”œâ”€â”€ operations/
â”‚   â”‚   â”œâ”€â”€ runbooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ local_deployment.md
â”‚   â”‚   â”‚   â””â”€â”€ troubleshooting.md
â”‚   â”‚   â””â”€â”€ sops/
â”‚   â”‚       â”œâ”€â”€ model-update.md
â”‚   â”‚       â””â”€â”€ data-refresh.md
â”‚   â”‚
â”‚   â””â”€â”€ _static/
â”‚       â””â”€â”€ custom.css
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ Dockerfile.local
â”‚   â”‚   â”œâ”€â”€ Dockerfile.gpu.local
â”‚   â”‚   â”œâ”€â”€ docker-compose.local.yml
â”‚   â”‚   â””â”€â”€ .dockerignore
â”‚   â”‚
â”‚   â”œâ”€â”€ auto_deploy/
â”‚   â”‚   â”œâ”€â”€ auto_deploy.py
â”‚   â”‚   â”œâ”€â”€ platform_deploy.sh
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ platform_specific/
â”‚   â”‚   â”œâ”€â”€ colab_deploy.md
â”‚   â”‚   â”œâ”€â”€ kaggle_deploy.md
â”‚   â”‚   â””â”€â”€ local_deploy.md
â”‚   â”‚
â”‚   â”œâ”€â”€ huggingface/
â”‚   â”‚   â”œâ”€â”€ spaces_config.yaml
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ streamlit_cloud/
â”‚   â”‚   â”œâ”€â”€ .streamlit/
â”‚   â”‚   â”‚   â””â”€â”€ config.toml
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â””â”€â”€ local/
â”‚       â”œâ”€â”€ systemd/
â”‚       â”‚   â”œâ”€â”€ ag-news-api.service
â”‚       â”‚   â””â”€â”€ ag-news-monitor.service
â”‚       â”œâ”€â”€ nginx/
â”‚       â”‚   â””â”€â”€ ag-news.conf
â”‚       â””â”€â”€ scripts/
â”‚           â”œâ”€â”€ start_all.sh
â”‚           â””â”€â”€ stop_all.sh
â”‚
â”œâ”€â”€ benchmarks/
â”‚   â”œâ”€â”€ accuracy/
â”‚   â”‚   â”œâ”€â”€ model_comparison.json
â”‚   â”‚   â”œâ”€â”€ xlarge_models.json
â”‚   â”‚   â”œâ”€â”€ llm_models.json
â”‚   â”‚   â”œâ”€â”€ ensemble_results.json
â”‚   â”‚   â””â”€â”€ sota_benchmarks.json
â”‚   â”‚
â”‚   â”œâ”€â”€ efficiency/
â”‚   â”‚   â”œâ”€â”€ parameter_efficiency.json
â”‚   â”‚   â”œâ”€â”€ memory_usage.json
â”‚   â”‚   â”œâ”€â”€ training_time.json
â”‚   â”‚   â”œâ”€â”€ inference_speed.json
â”‚   â”‚   â””â”€â”€ platform_comparison.json
â”‚   â”‚
â”‚   â”œâ”€â”€ robustness/
â”‚   â”‚   â”œâ”€â”€ adversarial_results.json
â”‚   â”‚   â”œâ”€â”€ ood_detection.json
â”‚   â”‚   â””â”€â”€ contrast_set_results.json
â”‚   â”‚
â”‚   â””â”€â”€ overfitting/
â”‚       â”œâ”€â”€ train_val_gaps.json
â”‚       â”œâ”€â”€ lora_ranks.json
â”‚       â””â”€â”€ prevention_effectiveness.json
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”‚
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_augmentation.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_dataloader.py
â”‚   â”‚   â”‚   â””â”€â”€ test_contrast_sets.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_transformers.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_ensemble.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_efficient.py
â”‚   â”‚   â”‚   â””â”€â”€ test_prompt_models.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_trainers.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_auto_trainer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_strategies.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_callbacks.py
â”‚   â”‚   â”‚   â””â”€â”€ test_multi_stage.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ deployment/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_platform_detector.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_smart_selector.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_cache_manager.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_checkpoint_manager.py
â”‚   â”‚   â”‚   â””â”€â”€ test_quota_tracker.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_rest_api.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_local_api.py
â”‚   â”‚   â”‚   â””â”€â”€ test_auth.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ overfitting_prevention/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_validators.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_monitors.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_constraints.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_guards.py
â”‚   â”‚   â”‚   â””â”€â”€ test_recommenders.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ test_memory_utils.py
â”‚   â”‚       â””â”€â”€ test_utilities.py
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_full_pipeline.py
â”‚   â”‚   â”œâ”€â”€ test_auto_train_flow.py
â”‚   â”‚   â”œâ”€â”€ test_ensemble_pipeline.py
â”‚   â”‚   â”œâ”€â”€ test_inference_pipeline.py
â”‚   â”‚   â”œâ”€â”€ test_local_api_flow.py
â”‚   â”‚   â”œâ”€â”€ test_prompt_pipeline.py
â”‚   â”‚   â”œâ”€â”€ test_llm_integration.py
â”‚   â”‚   â”œâ”€â”€ test_platform_workflows.py
â”‚   â”‚   â”œâ”€â”€ test_quota_tracking_flow.py
â”‚   â”‚   â””â”€â”€ test_overfitting_prevention_flow.py
â”‚   â”‚
â”‚   â”œâ”€â”€ platform_specific/
â”‚   â”‚   â”œâ”€â”€ test_colab_integration.py
â”‚   â”‚   â”œâ”€â”€ test_kaggle_integration.py
â”‚   â”‚   â””â”€â”€ test_local_integration.py
â”‚   â”‚
â”‚   â”œâ”€â”€ performance/
â”‚   â”‚   â”œâ”€â”€ test_model_speed.py
â”‚   â”‚   â”œâ”€â”€ test_memory_usage.py
â”‚   â”‚   â”œâ”€â”€ test_accuracy_benchmarks.py
â”‚   â”‚   â”œâ”€â”€ test_local_performance.py
â”‚   â”‚   â”œâ”€â”€ test_sla_compliance.py
â”‚   â”‚   â””â”€â”€ test_throughput.py
â”‚   â”‚
â”‚   â”œâ”€â”€ e2e/
â”‚   â”‚   â”œâ”€â”€ test_complete_workflow.py
â”‚   â”‚   â”œâ”€â”€ test_user_scenarios.py
â”‚   â”‚   â”œâ”€â”€ test_local_deployment.py
â”‚   â”‚   â”œâ”€â”€ test_free_deployment.py
â”‚   â”‚   â”œâ”€â”€ test_quickstart_pipeline.py
â”‚   â”‚   â”œâ”€â”€ test_sota_pipeline.py
â”‚   â”‚   â”œâ”€â”€ test_auto_train_colab.py
â”‚   â”‚   â”œâ”€â”€ test_auto_train_kaggle.py
â”‚   â”‚   â””â”€â”€ test_quota_enforcement.py
â”‚   â”‚
â”‚   â”œâ”€â”€ regression/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_model_accuracy.py
â”‚   â”‚   â”œâ”€â”€ test_ensemble_diversity.py
â”‚   â”‚   â”œâ”€â”€ test_inference_speed.py
â”‚   â”‚   â””â”€â”€ baseline_results.json
â”‚   â”‚
â”‚   â”œâ”€â”€ chaos/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_fault_tolerance.py
â”‚   â”‚   â”œâ”€â”€ test_corrupted_config.py
â”‚   â”‚   â”œâ”€â”€ test_oom_handling.py
â”‚   â”‚   â””â”€â”€ test_network_failures.py
â”‚   â”‚
â”‚   â”œâ”€â”€ compatibility/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_torch_versions.py
â”‚   â”‚   â”œâ”€â”€ test_transformers_versions.py
â”‚   â”‚   â””â”€â”€ test_cross_platform.py
â”‚   â”‚
â”‚   â””â”€â”€ fixtures/
â”‚       â”œâ”€â”€ sample_data.py
â”‚       â”œâ”€â”€ mock_models.py
â”‚       â”œâ”€â”€ test_configs.py
â”‚       â””â”€â”€ local_fixtures.py
â”‚
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ ci.yml
â”‚   â”‚   â”œâ”€â”€ tests.yml
â”‚   â”‚   â”œâ”€â”€ documentation.yml
â”‚   â”‚   â”œâ”€â”€ benchmarks.yml
â”‚   â”‚   â”œâ”€â”€ overfitting_checks.yml
â”‚   â”‚   â”œâ”€â”€ docs_sync_check.yml
â”‚   â”‚   â”œâ”€â”€ local_deployment_test.yml
â”‚   â”‚   â”œâ”€â”€ dependency_updates.yml
â”‚   â”‚   â”œâ”€â”€ compatibility_matrix.yml
â”‚   â”‚   â”œâ”€â”€ regression_tests.yml
â”‚   â”‚   â”œâ”€â”€ test_platform_detection.yml
â”‚   â”‚   â”œâ”€â”€ test_auto_train.yml
â”‚   â”‚   â””â”€â”€ platform_compatibility.yml
â”‚   â”‚
â”‚   â”œâ”€â”€ ISSUE_TEMPLATE/
â”‚   â”‚   â”œâ”€â”€ bug_report.md
â”‚   â”‚   â”œâ”€â”€ feature_request.md
â”‚   â”‚   â”œâ”€â”€ ide_support_request.md
â”‚   â”‚   â””â”€â”€ overfitting_report.md
â”‚   â”‚
â”‚   â”œâ”€â”€ PULL_REQUEST_TEMPLATE.md
â”‚   â””â”€â”€ dependabot.yml
â”‚
â””â”€â”€ tools/
    â”‚
    â”œâ”€â”€ profiling/
    â”‚   â”œâ”€â”€ memory_profiler.py
    â”‚   â”œâ”€â”€ speed_profiler.py
    â”‚   â”œâ”€â”€ parameter_counter.py
    â”‚   â””â”€â”€ local_profiler.py
    â”‚
    â”œâ”€â”€ debugging/
    â”‚   â”œâ”€â”€ model_debugger.py
    â”‚   â”œâ”€â”€ overfitting_debugger.py
    â”‚   â”œâ”€â”€ lora_debugger.py
    â”‚   â”œâ”€â”€ data_validator.py
    â”‚   â”œâ”€â”€ platform_debugger.py
    â”‚   â”œâ”€â”€ quota_debugger.py
    â”‚   â””â”€â”€ local_debugger.py
    â”‚
    â”œâ”€â”€ visualization/
    â”‚   â”œâ”€â”€ training_monitor.py
    â”‚   â”œâ”€â”€ lora_weight_plotter.py
    â”‚   â”œâ”€â”€ ensemble_diversity_plotter.py
    â”‚   â””â”€â”€ result_plotter.py
    â”‚
    â”œâ”€â”€ config_tools/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ config_generator.py
    â”‚   â”œâ”€â”€ config_explainer.py
    â”‚   â”œâ”€â”€ config_comparator.py
    â”‚   â”œâ”€â”€ config_optimizer.py
    â”‚   â”œâ”€â”€ sync_manager.py
    â”‚   â”œâ”€â”€ auto_sync.sh
    â”‚   â””â”€â”€ validate_all_configs.py
    â”‚
    â”œâ”€â”€ platform_tools/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ detector_tester.py
    â”‚   â”œâ”€â”€ quota_simulator.py
    â”‚   â””â”€â”€ platform_benchmark.py
    â”‚
    â”œâ”€â”€ cost_tools/
    â”‚   â”œâ”€â”€ cost_estimator.py
    â”‚   â””â”€â”€ cost_comparator.py
    â”‚
    â”œâ”€â”€ ide_tools/
    â”‚   â”œâ”€â”€ pycharm_config_generator.py
    â”‚   â”œâ”€â”€ vscode_tasks_generator.py
    â”‚   â”œâ”€â”€ jupyter_kernel_setup.py
    â”‚   â”œâ”€â”€ vim_plugin_installer.sh
    â”‚   â”œâ”€â”€ universal_ide_generator.py
    â”‚   â””â”€â”€ sync_ide_configs.py
    â”‚
    â”œâ”€â”€ compatibility/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ compatibility_checker.py
    â”‚   â”œâ”€â”€ version_matrix_tester.py
    â”‚   â””â”€â”€ upgrade_path_finder.py
    â”‚
    â”œâ”€â”€ automation/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ health_check_runner.py
    â”‚   â”œâ”€â”€ auto_fix_runner.py
    â”‚   â”œâ”€â”€ batch_config_generator.py
    â”‚   â”œâ”€â”€ platform_health.py
    â”‚   â””â”€â”€ nightly_tasks.sh
    â”‚
    â””â”€â”€ cli_helpers/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ rich_console.py
        â”œâ”€â”€ progress_bars.py
        â”œâ”€â”€ interactive_prompts.py
        â””â”€â”€ ascii_art.py
```

## Usage
