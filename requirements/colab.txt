# ============================================================================
# Google Colab Requirements for AG News Text Classification
# ============================================================================
# Project: AG News Text Classification (ag-news-text-classification)
# Description: Optimized dependencies for Google Colab free tier
# Author: Võ Hải Dũng
# License: MIT
# Python: 3.10 (Colab default)
# ============================================================================
# This file contains packages optimized for:
# - Google Colab free tier (T4 GPU, 12GB RAM, 15GB VRAM)
# - Kaggle kernels (P100 GPU, 16GB RAM)
# - Fast installation (minimize download size)
# - Memory efficiency (QLoRA for large models)
# - Free cloud execution
#
# Pre-installed in Colab (skip):
# - torch, torchvision, torchaudio
# - numpy, pandas, scipy
# - matplotlib, seaborn
# - scikit-learn
# - jupyter, ipython
# - requests, tqdm
#
# This file installs only ADDITIONAL packages needed beyond Colab defaults
# ============================================================================

# ----------------------------------------------------------------------------
# HuggingFace Ecosystem (Essential, not pre-installed in Colab)
# ----------------------------------------------------------------------------
# Transformers library (Colab may have older version)
transformers>=4.36.0,<4.41.0

# Datasets library
datasets>=2.16.0,<2.20.0

# Tokenizers (fast)
tokenizers>=0.15.0,<0.16.0

# Accelerate for mixed precision and device management
accelerate>=0.25.0,<0.31.0

# SafeTensors for model loading
safetensors>=0.4.0,<0.5.0

# HuggingFace Hub
huggingface-hub>=0.20.0,<0.24.0

# ----------------------------------------------------------------------------
# Parameter-Efficient Fine-Tuning (Critical for Colab)
# ----------------------------------------------------------------------------
# PEFT for LoRA/QLoRA
peft>=0.7.0,<0.12.0

# BitsAndBytes for 4-bit/8-bit quantization
bitsandbytes>=0.41.0,<0.44.0

# ----------------------------------------------------------------------------
# Efficient Training (Memory Optimization)
# ----------------------------------------------------------------------------
# Gradient checkpointing and memory utilities
# Built-in to transformers/accelerate

# ----------------------------------------------------------------------------
# Flash Attention (Optional, Linux only on Colab)
# ----------------------------------------------------------------------------
# Flash Attention 2 for faster training
# Install manually if needed:
# pip install flash-attn --no-build-isolation

# xFormers for memory-efficient attention
xformers>=0.0.23,<0.0.27

# ----------------------------------------------------------------------------
# Configuration Management
# ----------------------------------------------------------------------------
# YAML parsing
pyyaml>=6.0.1,<7.0.0

# Environment variables
python-dotenv>=1.0.0,<1.1.0

# OmegaConf for complex configs
omegaconf>=2.3.0,<2.4.0

# Pydantic for validation
pydantic>=2.5.0,<2.8.0

# ----------------------------------------------------------------------------
# Data Processing
# ----------------------------------------------------------------------------
# NLTK (may be pre-installed but ensure version)
nltk>=3.8.0,<3.9.0

# SentencePiece for tokenization
sentencepiece>=0.1.99,<0.3.0

# ----------------------------------------------------------------------------
# Experiment Tracking (Essential for research)
# ----------------------------------------------------------------------------
# Weights & Biases (lightweight)
wandb>=0.16.0,<0.17.0

# TensorBoard (pre-installed but ensure version)
tensorboard>=2.15.0,<2.17.0

# ----------------------------------------------------------------------------
# Evaluation Metrics
# ----------------------------------------------------------------------------
# HuggingFace evaluate
evaluate>=0.4.0,<0.5.0

# Scikit-learn (pre-installed, but include for completeness)
# scikit-learn>=1.3.0,<1.5.0

# ----------------------------------------------------------------------------
# Logging
# ----------------------------------------------------------------------------
# Loguru for better logging
loguru>=0.7.0,<0.8.0

# ----------------------------------------------------------------------------
# Utilities
# ----------------------------------------------------------------------------
# Type hints
typing-extensions>=4.9.0,<4.12.0

# File locking
filelock>=3.13.0,<3.15.0

# Retry logic
tenacity>=8.2.3,<8.4.0

# ----------------------------------------------------------------------------
# Google Drive Integration
# ----------------------------------------------------------------------------
# PyDrive for Drive access (if not using Colab's built-in)
# pydrive>=1.3.1,<1.4.0

# ----------------------------------------------------------------------------
# Cloud Storage (Optional)
# ----------------------------------------------------------------------------
# Google Cloud Storage (for data/model storage)
# google-cloud-storage>=2.14.0,<2.18.0

# ----------------------------------------------------------------------------
# Visualization (Lightweight)
# ----------------------------------------------------------------------------
# Plotly for interactive plots (lighter than full install)
plotly>=5.18.0,<5.23.0

# ----------------------------------------------------------------------------
# Model Compression (For deployment from Colab)
# ----------------------------------------------------------------------------
# ONNX for model export
onnx>=1.15.0,<1.17.0
onnxruntime>=1.16.0,<1.18.0

# ----------------------------------------------------------------------------
# API Client (For deployment)
# ----------------------------------------------------------------------------
# Requests (pre-installed but include for safety)
# requests>=2.31.0,<2.33.0

# HTTPX for async requests
httpx>=0.25.0,<0.28.0

# ----------------------------------------------------------------------------
# Rich Output in Notebooks
# ----------------------------------------------------------------------------
# Rich for beautiful output
rich>=13.7.0,<13.8.0

# ----------------------------------------------------------------------------
# Hyperparameter Optimization (Lightweight)
# ----------------------------------------------------------------------------
# Optuna for HPO
optuna>=3.5.0,<3.7.0

# ----------------------------------------------------------------------------
# Data Augmentation (Optional)
# ----------------------------------------------------------------------------
# NLP Augmentation
nlpaug>=1.1.11,<1.2.0

# ----------------------------------------------------------------------------
# Model Interpretability (Optional)
# ----------------------------------------------------------------------------
# Captum for interpretability
# captum>=0.7.0,<0.8.0

# ----------------------------------------------------------------------------
# UI in Colab (Optional)
# ----------------------------------------------------------------------------
# Gradio for quick demos
gradio>=4.12.0,<4.38.0

# ----------------------------------------------------------------------------
# Efficient Data Loading
# ----------------------------------------------------------------------------
# PyArrow for fast data loading
pyarrow>=14.0.0,<16.2.0

# ----------------------------------------------------------------------------
# Version Control Integration
# ----------------------------------------------------------------------------
# GitPython (for version tracking)
gitpython>=3.1.40,<3.2.0

# ----------------------------------------------------------------------------
# Hash Functions
# ----------------------------------------------------------------------------
# xxhash for fast hashing
xxhash>=3.4.1,<3.5.0

# ----------------------------------------------------------------------------
# Progress Bars (Enhanced)
# ----------------------------------------------------------------------------
# TQDM (pre-installed, but ensure version)
# tqdm>=4.66.0,<4.67.0

# Alive-progress for animated bars
alive-progress>=3.1.5,<3.2.0

# ----------------------------------------------------------------------------
# Serialization
# ----------------------------------------------------------------------------
# Dill for pickling
dill>=0.3.7,<0.4.0

# Joblib for caching
joblib>=1.3.2,<1.5.0

# ----------------------------------------------------------------------------
# Testing (Minimal)
# ----------------------------------------------------------------------------
# Pytest for basic testing
pytest>=7.4.0,<8.3.0

# ============================================================================
# Installation Notes for Google Colab
# ============================================================================
# 1. Install in Colab notebook:
#    !pip install -q -r requirements/colab.txt
#
# 2. Or install from GitHub directly:
#    !pip install -q git+https://github.com/VoHaiDung/ag-news-text-classification.git
#
# 3. Clone repository:
#    !git clone https://github.com/VoHaiDung/ag-news-text-classification.git
#    %cd ag-news-text-classification
#
# 4. Mount Google Drive (for persistent storage):
#    from google.colab import drive
#    drive.mount('/content/drive')
#
# 5. Download NLTK data:
#    import nltk
#    nltk.download('punkt')
#    nltk.download('stopwords')
#    nltk.download('wordnet')
#
# 6. Login to HuggingFace (for gated models):
#    from huggingface_hub import notebook_login
#    notebook_login()
#
# 7. Login to Weights & Biases:
#    import wandb
#    wandb.login()
#
# 8. Setup for training:
#    !python scripts/setup/setup_colab.sh
#
# 9. Verify GPU:
#    import torch
#    print(f"CUDA available: {torch.cuda.is_available()}")
#    print(f"GPU: {torch.cuda.get_device_name(0)}")
#    print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
#
# 10. Quick test:
#     !python quickstart/minimal_example.py

# ============================================================================
# Colab-Specific Configuration
# ============================================================================
# Colab free tier specs:
# - GPU: Tesla T4 (15GB VRAM)
# - RAM: ~12GB
# - Disk: ~100GB (temporary)
# - Session: 12 hours max
# - Python: 3.10
#
# Colab Pro specs:
# - GPU: V100 or A100 (16-40GB VRAM)
# - RAM: ~25GB
# - Disk: ~200GB
# - Session: 24 hours max
#
# Recommended model sizes for Colab free tier:
# - DeBERTa-v3-base (184M): Full fine-tuning or LoRA
# - DeBERTa-v3-large (435M): LoRA rank 16-32
# - DeBERTa-v3-xlarge (900M): LoRA rank 8-16 with gradient checkpointing
# - LLaMA-2-7B: QLoRA 4-bit only
# - LLaMA-2-13B: QLoRA 4-bit with very small batch size
#
# Memory optimization tips:
# - Use QLoRA 4-bit for models >1B parameters
# - Enable gradient checkpointing: model.gradient_checkpointing_enable()
# - Use gradient accumulation for larger effective batch size
# - Reduce sequence length if possible (256-512 instead of 1024)
# - Use smaller LoRA rank (8 instead of 32)
# - Clear cache regularly: torch.cuda.empty_cache()
# - Use mixed precision: fp16 or bf16
#
# Training recommendations:
# - Batch size: 4-8 for large models, 16-32 for base models
# - Gradient accumulation: 4-8 steps
# - LoRA rank: 8-16 for xlarge, 16-32 for large
# - Learning rate: 1e-4 to 5e-4 for LoRA
# - Epochs: 3-5 (Colab sessions timeout after 12 hours)
#
# Saving checkpoints to Google Drive:
# checkpoint_dir = "/content/drive/MyDrive/ag-news-checkpoints"
# trainer.save_model(checkpoint_dir)

# ============================================================================
# Quick Start Examples for Colab
# ============================================================================
# Example 1: Train DeBERTa-base with LoRA
# !python scripts/training/single_model/train_xlarge_lora.py \
#   --model_config configs/models/recommended/tier_1_sota/deberta_v3_base_lora.yaml \
#   --output_dir /content/drive/MyDrive/ag-news-outputs/
#
# Example 2: Train LLaMA-2-7B with QLoRA
# !python scripts/training/single_model/train_llm_qlora.py \
#   --model_config configs/models/recommended/tier_2_llm/llama2_7b_qlora.yaml \
#   --output_dir /content/drive/MyDrive/ag-news-outputs/
#
# Example 3: Quick demo with Gradio
# !python quickstart/demo_app.py
#
# Example 4: Run Jupyter notebook
# See notebooks/01_tutorials/04_lora_tutorial.ipynb
#
# Example 5: Evaluate model
# !python scripts/evaluation/evaluate_all_models.py \
#   --model_path /content/drive/MyDrive/ag-news-outputs/best_model

# ============================================================================
# Data Loading in Colab
# ============================================================================
# Option 1: Download from HuggingFace Hub
# from datasets import load_dataset
# dataset = load_dataset("ag_news")
#
# Option 2: Load from GitHub repo
# !python scripts/data_preparation/prepare_ag_news.py
#
# Option 3: Load from Google Drive
# import pandas as pd
# train_df = pd.read_csv("/content/drive/MyDrive/ag-news-data/train.csv")

# ============================================================================
# Troubleshooting Colab Issues
# ============================================================================
# Issue: Session timeout during training
# Solution: Save checkpoints frequently to Google Drive
#
# Issue: CUDA out of memory
# Solution: Reduce batch size, enable gradient checkpointing, use QLoRA
#
# Issue: Slow installation
# Solution: Use -q flag for quiet installation
#
# Issue: Drive mounting fails
# Solution: Reconnect and remount
#
# Issue: Model download fails
# Solution: Use HF_HUB_CACHE environment variable to cache in Drive
#
# Issue: Import errors after installation
# Solution: Restart runtime: Runtime > Restart runtime

# ============================================================================
# Saving Results to Google Drive
# ============================================================================
# Mount Drive:
# from google.colab import drive
# drive.mount('/content/drive')
#
# Save outputs:
# output_dir = "/content/drive/MyDrive/ag-news-outputs"
# trainer.save_model(output_dir)
#
# Save experiment results:
# import shutil
# shutil.copytree("outputs/results/", "/content/drive/MyDrive/ag-news-results/")

# ============================================================================
# Notebook Examples
# ============================================================================
# Available Colab notebooks:
# - notebooks/00_setup/01_colab_setup.ipynb
# - notebooks/01_tutorials/04_lora_tutorial.ipynb
# - notebooks/01_tutorials/05_qlora_tutorial.ipynb
# - notebooks/03_experiments/02_xlarge_lora_experiments.ipynb
# - notebooks/03_experiments/03_llm_qlora_experiments.ipynb
# - notebooks/06_platform_specific/colab/quick_start_colab.ipynb
# - notebooks/06_platform_specific/colab/full_training_colab.ipynb
# - quickstart/colab_notebook.ipynb

# ============================================================================
# Kaggle Kernels
# ============================================================================
# For Kaggle, use the same requirements with these differences:
# - GPU: P100 or T4
# - RAM: 16GB (more than Colab free)
# - Session: 9 hours (GPU) or 12 hours (CPU)
# - Internet: Optional (can be disabled)
#
# Kaggle-specific setup:
# !pip install -q -r requirements/kaggle.txt
# # Or use requirements/colab.txt (nearly identical)

# ============================================================================
# Performance Expectations on Colab Free Tier
# ============================================================================
# Training times (approximate):
# - DeBERTa-base with LoRA: 20-30 minutes (3 epochs)
# - DeBERTa-large with LoRA: 40-60 minutes (3 epochs)
# - DeBERTa-xlarge with LoRA: 90-120 minutes (3 epochs)
# - LLaMA-2-7B with QLoRA: 120-180 minutes (3 epochs)
#
# Expected accuracy:
# - DeBERTa-base: 94-95%
# - DeBERTa-large: 95-96%
# - DeBERTa-xlarge with LoRA: 96-97%
# - LLaMA-2-7B with QLoRA: 95-96%

# ============================================================================
# For More Information
# ============================================================================
# - Colab setup guide: docs/getting_started/installation.md
# - Colab notebooks: notebooks/06_platform_specific/colab/
# - Quick start: QUICK_START.md
# - Troubleshooting: TROUBLESHOOTING.md
# - Colab deployment guide: FREE_DEPLOYMENT_GUIDE.md
#
# Open in Colab:
# https://colab.research.google.com/github/VoHaiDung/ag-news-text-classification/blob/main/quickstart/colab_notebook.ipynb
# ============================================================================
