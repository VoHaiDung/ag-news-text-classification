# ============================================================================
# Research Requirements for AG News Text Classification
# ============================================================================
# Project: AG News Text Classification (ag-news-text-classification)
# Description: Experiment tracking, hyperparameter optimization, and analysis
# Author: Võ Hải Dũng
# Email: vohaidung.work@gmail.com
# License: MIT
# Python: >=3.8,<3.12
# ============================================================================
# This file contains packages required for:
# - Experiment tracking (Weights & Biases, MLflow, TensorBoard, Neptune)
# - Hyperparameter optimization (Optuna, Ray Tune, Bayesian methods)
# - Ablation studies and sensitivity analysis
# - SOTA experiments and benchmarking
# - Statistical significance testing
# - Reproducibility and result aggregation
# - Academic paper generation and visualization
# - Multi-seed experiments and cross-validation
# ============================================================================

# Include ML requirements
-r ml.txt

# ----------------------------------------------------------------------------
# Experiment Tracking Platforms
# ----------------------------------------------------------------------------
# Weights & Biases for comprehensive experiment tracking
wandb>=0.16.0,<0.17.0

# MLflow for experiment management and model registry
mlflow>=2.9.0,<2.15.0

# TensorBoard for visualization
tensorboard>=2.15.0,<2.17.0
tensorboardX>=2.6.2,<2.7.0

# Neptune for experiment tracking and collaboration
neptune>=1.8.0,<1.11.0

# Comet ML for experiment tracking
comet-ml>=3.35.0,<3.44.0

# ClearML for experiment management
clearml>=1.14.0,<1.17.0

# Sacred for experiment configuration and tracking
sacred>=0.8.4,<0.9.0
pymongo>=4.6.0,<4.8.0

# ----------------------------------------------------------------------------
# Version Control for Data and Models
# ----------------------------------------------------------------------------
# DVC for data and model versioning
dvc>=3.37.0,<3.54.0
dvc-s3>=3.0.0,<3.3.0
dvc-gdrive>=3.0.0,<3.1.0

# Git for code versioning
gitpython>=3.1.40,<3.2.0

# ----------------------------------------------------------------------------
# Hyperparameter Optimization
# ----------------------------------------------------------------------------
# Optuna for Bayesian hyperparameter optimization
optuna>=3.5.0,<3.7.0
optuna-integration>=3.5.0,<3.7.0
optuna-dashboard>=0.15.0,<0.16.0

# Ray Tune for distributed hyperparameter search
ray[tune]>=2.9.0,<2.10.0
ray[default]>=2.9.0,<2.10.0

# Hyperopt for tree-structured Parzen estimators
hyperopt>=0.2.7,<0.3.0

# Scikit-optimize for Bayesian optimization
scikit-optimize>=0.9.0,<0.11.0

# BayesOpt for Gaussian Process optimization
bayesian-optimization>=1.4.3,<1.5.0

# Ax Platform for adaptive experimentation
ax-platform>=0.3.0,<0.4.0

# GPyOpt for Bayesian optimization
gpyopt>=1.2.0,<1.3.0

# SMAC for sequential model-based optimization
smac>=2.0.0,<2.3.0

# ----------------------------------------------------------------------------
# Visualization Libraries
# ----------------------------------------------------------------------------
# Matplotlib for publication-quality plots
matplotlib>=3.8.0,<3.10.0

# Seaborn for statistical data visualization
seaborn>=0.13.0,<0.14.0

# Plotly for interactive visualizations
plotly>=5.18.0,<5.23.0

# Altair for declarative visualizations
altair>=5.2.0,<5.4.0

# Bokeh for interactive web-based visualizations
bokeh>=3.3.0,<3.5.0

# HoloViews for complex data visualization
holoviews>=1.18.0,<1.20.0

# Yellowbrick for ML visualizations
yellowbrick>=1.5.0,<1.6.0

# SciencePlots for publication-ready plots
scienceplots>=2.1.0,<2.2.0

# Tueplots for Tufte-style minimalist plots
tueplots>=0.0.13,<0.1.0

# ----------------------------------------------------------------------------
# Jupyter Ecosystem
# ----------------------------------------------------------------------------
# Jupyter for interactive research
jupyter>=1.0.0,<1.1.0
jupyterlab>=4.0.0,<4.3.0
notebook>=7.0.0,<7.3.0

# IPython for enhanced interactive computing
ipython>=8.12.0,<8.27.0
ipykernel>=6.27.0,<6.30.0

# Jupyter widgets for interactive visualizations
ipywidgets>=8.1.0,<8.2.0

# Jupyter extensions
jupyter-contrib-nbextensions>=0.7.0,<0.8.0
jupyter-nbextensions-configurator>=0.6.0,<0.7.0

# JupyterLab extensions
jupyterlab-git>=0.50.0,<0.51.0
jupyterlab-lsp>=5.0.0,<5.2.0

# Papermill for parameterized notebook execution
papermill>=2.5.0,<2.7.0

# NBConvert for notebook conversion
nbconvert>=7.14.0,<7.17.0

# NBFormat for notebook format handling
nbformat>=5.9.0,<5.11.0

# ----------------------------------------------------------------------------
# Statistical Analysis
# ----------------------------------------------------------------------------
# SciPy for scientific computing
scipy>=1.10.0,<1.13.0

# Statsmodels for statistical modeling
statsmodels>=0.14.0,<0.15.0

# Pingouin for statistical tests
pingouin>=0.5.0,<0.6.0

# Scikit-posthocs for post-hoc tests
scikit-posthocs>=0.8.0,<0.10.0

# ----------------------------------------------------------------------------
# Significance Testing and Multiple Comparisons
# ----------------------------------------------------------------------------
# Permutation tests
# permute>=0.2.0,<0.3.0

# Bootstrap confidence intervals
arch>=6.2.0,<7.1.0

# Multiple testing correction via statsmodels
# statsmodels already included above

# ----------------------------------------------------------------------------
# Model Interpretation and Ablation
# ----------------------------------------------------------------------------
# Captum for PyTorch model interpretation
captum>=0.7.0,<0.8.0

# SHAP for model explanations
shap>=0.44.0,<0.46.0

# LIME for local interpretable model-agnostic explanations
lime>=0.2.0,<0.3.0

# Alibi for ML model inspection and interpretation
alibi>=0.9.0,<0.10.0

# InterpretML for glass-box models
interpret>=0.5.0,<0.7.0

# ----------------------------------------------------------------------------
# Structured Training Framework
# ----------------------------------------------------------------------------
# PyTorch Lightning for structured deep learning
pytorch-lightning>=2.1.0,<2.4.0

# Lightning Fabric for flexible training
lightning-fabric>=2.1.0,<2.4.0

# ----------------------------------------------------------------------------
# Profiling and Benchmarking
# ----------------------------------------------------------------------------
# Memory profiler for memory usage analysis
memory-profiler>=0.61.0,<0.62.0

# Line profiler for line-by-line profiling
line-profiler>=4.1.0,<4.2.0

# Py-spy for sampling profiler
py-spy>=0.3.0,<0.4.0

# Scalene for CPU and GPU profiling
scalene>=1.5.0,<1.6.0

# Pytest-benchmark for performance benchmarking
pytest-benchmark>=4.0.0,<4.1.0

# ASV for continuous performance tracking
asv>=0.6.0,<0.7.0

# ----------------------------------------------------------------------------
# Data Analysis and Aggregation
# ----------------------------------------------------------------------------
# Pandas for data manipulation (already in base.txt)
# pandas>=2.0.0,<2.3.0

# Tabulate for formatted tables
tabulate>=0.9.0,<0.10.0

# PrettyTable for ASCII tables
prettytable>=3.9.0,<3.11.0

# ----------------------------------------------------------------------------
# Academic Paper Tools
# ----------------------------------------------------------------------------
# Pandoc wrapper for document conversion
pypandoc>=1.12,<1.14

# BibTeX parser for citation management
bibtexparser>=1.4.0,<2.1.0

# PyBTeX for BibTeX processing
pybtex>=0.24.0,<0.25.0

# ----------------------------------------------------------------------------
# LaTeX Integration
# ----------------------------------------------------------------------------
# PyLaTeX for programmatic LaTeX generation
pylatex>=1.4.0,<1.5.0

# ----------------------------------------------------------------------------
# Exploratory Data Analysis
# ----------------------------------------------------------------------------
# Pandas profiling for automated EDA
ydata-profiling>=4.6.0,<4.10.0

# Sweetviz for comparative EDA
sweetviz>=2.3.0,<2.4.0

# ----------------------------------------------------------------------------
# Model Registry and Checkpointing
# ----------------------------------------------------------------------------
# HuggingFace Hub for model sharing
huggingface-hub>=0.20.0,<0.24.0

# ----------------------------------------------------------------------------
# Configuration Management
# ----------------------------------------------------------------------------
# Hydra for hierarchical configuration
hydra-core>=1.3.0,<1.4.0
hydra-colorlog>=1.2.0,<1.3.0
hydra-optuna-sweeper>=1.2.0,<1.3.0

# OmegaConf for configuration management
omegaconf>=2.3.0,<2.4.0

# ----------------------------------------------------------------------------
# Distributed Training for Large-Scale Experiments
# ----------------------------------------------------------------------------
# Horovod for distributed training
# horovod>=0.28.0,<0.29.0

# DeepSpeed for efficient large model training
# deepspeed>=0.12.0,<0.15.0

# FairScale for efficient training
# fairscale>=0.4.13,<0.5.0

# ----------------------------------------------------------------------------
# Reproducibility Tools
# ----------------------------------------------------------------------------
# NumPy for random seeding (already in base.txt)
# numpy>=1.24.0,<1.27.0

# PyTorch for seeding (already in base.txt)
# torch>=2.1.0,<2.5.0

# Python random module (built-in)
# Custom implementation in src/utils/reproducibility.py

# ----------------------------------------------------------------------------
# Cross-Validation
# ----------------------------------------------------------------------------
# Scikit-learn for CV (already in base.txt)
# scikit-learn>=1.3.0,<1.5.0

# Custom nested CV implementation
# See src/data/validation/nested_cross_validator.py

# ----------------------------------------------------------------------------
# Error Analysis
# ----------------------------------------------------------------------------
# Custom error analysis implementation
# See src/evaluation/analysis/error_analysis.py

# Confusion matrix utilities
# See src/evaluation/visualizations/confusion_matrix.py

# ----------------------------------------------------------------------------
# Model Serving for Research
# ----------------------------------------------------------------------------
# TorchServe for model deployment
torchserve>=0.9.0,<0.10.0
torch-model-archiver>=0.9.0,<0.10.0

# ----------------------------------------------------------------------------
# AutoML for Baseline Comparison
# ----------------------------------------------------------------------------
# AutoGluon for automated machine learning
autogluon.tabular>=1.0.0,<1.2.0
autogluon.text>=1.0.0,<1.2.0

# AutoKeras for neural architecture search
# autokeras>=1.1.0,<1.2.0

# FLAML for fast and lightweight AutoML
flaml>=2.1.0,<2.3.0

# ----------------------------------------------------------------------------
# Neural Architecture Search
# ----------------------------------------------------------------------------
# NNI for neural network intelligence
nni>=3.0,<3.1

# ----------------------------------------------------------------------------
# Meta-Learning
# ----------------------------------------------------------------------------
# Learn2Learn for meta-learning
learn2learn>=0.2.0,<0.3.0

# Higher for higher-order gradients in meta-learning
higher>=0.2.1,<0.3.0

# ----------------------------------------------------------------------------
# Continual Learning
# ----------------------------------------------------------------------------
# Avalanche for continual learning
# avalanche-lib>=0.4.0,<0.5.0

# ----------------------------------------------------------------------------
# Active Learning
# ----------------------------------------------------------------------------
# modAL for active learning
modAL>=0.4.1,<0.5.0

# ALiPy for active learning
# alipy>=1.3.0,<1.4.0

# ----------------------------------------------------------------------------
# Model Calibration
# ----------------------------------------------------------------------------
# Netcal for calibration metrics
netcal>=1.3.5,<1.4.0

# Uncertainty quantification
uncertainty-toolbox>=0.1.1,<0.2.0

# ----------------------------------------------------------------------------
# Color Palettes for Research Visualizations
# ----------------------------------------------------------------------------
# Palettable for color palettes
palettable>=3.3.0,<3.4.0

# Colorcet for perceptually accurate color maps
colorcet>=3.0.0,<3.2.0

# ----------------------------------------------------------------------------
# Graph Visualization
# ----------------------------------------------------------------------------
# NetworkX for graph analysis
networkx>=3.2.0,<3.4.0

# PyVis for interactive network visualization
pyvis>=0.3.0,<0.4.0

# ----------------------------------------------------------------------------
# Clustering for Analysis
# ----------------------------------------------------------------------------
# Scikit-learn clustering (already in base.txt)
# scikit-learn>=1.3.0,<1.5.0

# HDBSCAN for density-based clustering
hdbscan>=0.8.0,<0.9.0

# ----------------------------------------------------------------------------
# Dimensionality Reduction
# ----------------------------------------------------------------------------
# UMAP for dimension reduction and visualization
umap-learn>=0.5.0,<0.6.0

# PaCMAP for pair-wise controlled manifold approximation
pacmap>=0.7.0,<0.8.0

# TriMap for large-scale dimension reduction
trimap>=1.1.0,<1.2.0

# ----------------------------------------------------------------------------
# Time Series Analysis for Training Dynamics
# ----------------------------------------------------------------------------
# Statsmodels for time series (already included above)
# statsmodels>=0.14.0,<0.15.0

# ----------------------------------------------------------------------------
# Report Generation
# ----------------------------------------------------------------------------
# Jinja2 for template rendering (already in base.txt via Flask)
# jinja2>=3.1.0,<3.2.0

# Markdown for report generation
markdown>=3.5.0,<3.7.0

# ----------------------------------------------------------------------------
# Documentation Generation
# ----------------------------------------------------------------------------
# Sphinx for documentation
sphinx>=7.2.0,<7.4.0
sphinx-rtd-theme>=2.0.0,<2.1.0
sphinx-autodoc-typehints>=1.25.0,<2.3.0

# MkDocs for documentation
mkdocs>=1.5.0,<1.7.0
mkdocs-material>=9.5.0,<9.6.0

# ----------------------------------------------------------------------------
# Code Quality for Research Code
# ----------------------------------------------------------------------------
# Black for code formatting (already in dev.txt if needed)
# black>=23.12.0,<24.5.0

# Flake8 for linting (already in dev.txt if needed)
# flake8>=7.0.0,<7.2.0

# ----------------------------------------------------------------------------
# Testing for Research Code
# ----------------------------------------------------------------------------
# Pytest for testing (already in base.txt)
# pytest>=7.4.0,<8.3.0

# ----------------------------------------------------------------------------
# Database for Experiment Tracking
# ----------------------------------------------------------------------------
# SQLite (built-in to Python)
# SQLAlchemy for database ORM
sqlalchemy>=2.0.0,<2.1.0

# ----------------------------------------------------------------------------
# Parallel Processing for Experiments
# ----------------------------------------------------------------------------
# Joblib for parallel processing (already in ml.txt)
# joblib>=1.3.0,<1.5.0

# Dask for parallel computing
dask>=2023.12.0,<2024.8.0
dask[dataframe]>=2023.12.0,<2024.8.0

# ----------------------------------------------------------------------------
# Cloud Storage Integration
# ----------------------------------------------------------------------------
# Google Cloud Storage
# google-cloud-storage>=2.14.0,<2.19.0

# AWS S3
# boto3>=1.34.0,<1.35.0

# Azure Blob Storage
# azure-storage-blob>=12.19.0,<12.22.0

# ============================================================================
# Installation Instructions for Research
# ============================================================================
#
# 1. Install research dependencies:
#    pip install -r requirements/research.txt
#
# 2. Setup experiment tracking platforms:
#
#    a) Weights & Biases:
#       wandb login
#       wandb init
#
#    b) MLflow:
#       mlflow ui --port 5000
#       Access at http://localhost:5000
#
#    c) TensorBoard:
#       tensorboard --logdir outputs/logs/tensorboard --port 6006
#       Access at http://localhost:6006
#
#    d) Neptune:
#       export NEPTUNE_API_TOKEN=your_api_token
#       export NEPTUNE_PROJECT=your_username/project_name
#
# 3. Launch Jupyter Lab for interactive research:
#    jupyter lab --port 8888
#    Access at http://localhost:8888
#
# 4. Run hyperparameter optimization:
#
#    a) Optuna search:
#       python experiments/hyperparameter_search/optuna_search.py
#
#    b) Ray Tune search:
#       ray start --head
#       python experiments/hyperparameter_search/ray_tune_search.py
#
#    c) LoRA rank search:
#       python experiments/hyperparameter_search/lora_rank_search.py
#
#    d) Ensemble weight search:
#       python experiments/hyperparameter_search/ensemble_weight_search.py
#
# 5. Run ablation studies:
#
#    a) Model size ablation:
#       python experiments/ablation_studies/model_size_ablation.py
#
#    b) LoRA rank ablation:
#       python experiments/ablation_studies/lora_rank_ablation.py
#
#    c) QLoRA bits ablation:
#       python experiments/ablation_studies/qlora_bits_ablation.py
#
#    d) Regularization ablation:
#       python experiments/ablation_studies/regularization_ablation.py
#
#    e) Prompt ablation:
#       python experiments/ablation_studies/prompt_ablation.py
#
# 6. Run SOTA experiments (phased approach):
#
#    Phase 1 - XLarge models with LoRA:
#    python experiments/sota_experiments/phase1_xlarge_lora.py
#
#    Phase 2 - LLM models with QLoRA:
#    python experiments/sota_experiments/phase2_llm_qlora.py
#
#    Phase 3 - LLM distillation:
#    python experiments/sota_experiments/phase3_llm_distillation.py
#
#    Phase 4 - Ensemble of XLarge models:
#    python experiments/sota_experiments/phase4_ensemble_xlarge.py
#
#    Phase 5 - Ultimate SOTA:
#    python experiments/sota_experiments/phase5_ultimate_sota.py
#
#    Compare all approaches:
#    python experiments/sota_experiments/compare_all_approaches.py
#
# 7. Run benchmarks:
#
#    a) SOTA comparison:
#       python experiments/benchmarks/sota_comparison.py
#
#    b) Overfitting benchmark:
#       python experiments/benchmarks/overfitting_benchmark.py
#
#    c) Parameter efficiency benchmark:
#       python experiments/benchmarks/parameter_efficiency_benchmark.py
#
# 8. Generate experiment reports:
#
#    a) Individual reports:
#       python scripts/evaluation/generate_reports.py
#
#    b) Leaderboard:
#       python scripts/evaluation/create_leaderboard.py
#
#    c) Statistical analysis:
#       python scripts/evaluation/statistical_analysis.py
#
# 9. Visualize training curves:
#    python tools/visualization/training_monitor.py
#
# 10. Track experiment results:
#     python experiments/results/experiment_tracker.py
#     python experiments/results/result_aggregator.py
#     python experiments/results/leaderboard_generator.py
#
# ============================================================================
# Research Workflow
# ============================================================================
#
# 1. Experiment Setup:
#    - Define research question
#    - Set up experiment configuration in configs/experiments/
#    - Define hyperparameter search space
#    - Set random seeds for reproducibility
#
# 2. Baseline Experiments:
#    - Train classical ML baselines
#    - Train simple transformer baselines
#    - Establish performance lower bounds
#    See: experiments/baselines/
#
# 3. Hyperparameter Search:
#    - LoRA rank and alpha
#    - QLoRA quantization bits
#    - Learning rate and batch size
#    - Warmup steps and weight decay
#    See: experiments/hyperparameter_search/
#
# 4. Ablation Studies:
#    - Component ablation (remove/add features)
#    - Data ablation (vary dataset size)
#    - Model size ablation (base/large/xlarge)
#    - Regularization strength
#    - Ensemble size
#    See: experiments/ablation_studies/
#
# 5. SOTA Experiments:
#    - Train best single models
#    - Train ensemble models
#    - Apply knowledge distillation
#    - Optimize for production
#    See: experiments/sota_experiments/
#
# 6. Statistical Analysis:
#    - Significance testing (t-test, permutation test)
#    - Multiple comparison correction (Bonferroni)
#    - Effect size calculation (Cohen's d)
#    - Confidence intervals (bootstrap)
#    See: scripts/evaluation/statistical_analysis.py
#
# 7. Error Analysis:
#    - Analyze failure cases
#    - Identify patterns in errors
#    - Generate contrast sets
#    - Test robustness
#    See: src/evaluation/analysis/error_analysis.py
#
# 8. Visualization and Reporting:
#    - Training curves
#    - Confusion matrices
#    - Attention visualizations
#    - Performance comparisons
#    See: src/evaluation/visualizations/
#
# 9. Paper Writing:
#    - Generate tables and figures
#    - Create LaTeX tables
#    - Export results to CSV
#    - Cite relevant work with BibTeX
#
# 10. Reproducibility:
#     - Log all hyperparameters
#     - Save model checkpoints
#     - Version control data and code
#     - Document hardware and software
#     See: src/utils/reproducibility.py
#
# ============================================================================
# Hyperparameter Search Spaces
# ============================================================================
#
# LoRA Configuration:
# - rank: [4, 8, 16, 32, 64, 128]
# - alpha: [8, 16, 32, 64, 128]
# - dropout: [0.0, 0.1, 0.2]
# - target_modules: ["q", "v"], ["q", "k", "v"], ["q", "k", "v", "o"]
#
# QLoRA Configuration:
# - bits: [4, 8]
# - quant_type: ["nf4", "fp4"]
# - double_quant: [True, False]
#
# Training Hyperparameters:
# - learning_rate: [1e-5, 5e-5, 1e-4, 5e-4]
# - batch_size: [4, 8, 16, 32]
# - num_epochs: [3, 5, 10]
# - warmup_steps: [100, 500, 1000]
# - weight_decay: [0.0, 0.01, 0.1]
# - gradient_accumulation_steps: [1, 2, 4, 8]
#
# Regularization:
# - dropout: [0.0, 0.1, 0.2, 0.3]
# - label_smoothing: [0.0, 0.05, 0.1]
# - attention_dropout: [0.0, 0.1, 0.2]
#
# Ensemble:
# - num_models: [3, 5, 7]
# - voting_strategy: ["soft", "hard", "weighted", "rank"]
# - diversity_weight: [0.0, 0.1, 0.2]
#
# ============================================================================
# Statistical Testing Guidelines
# ============================================================================
#
# Significance Testing:
# - Use t-test for comparing two models
# - Use ANOVA for comparing multiple models
# - Use McNemar test for paired predictions
# - Use permutation test for non-parametric comparison
# - Apply Bonferroni correction for multiple comparisons
#
# Effect Size:
# - Calculate Cohen's d for practical significance
# - Report confidence intervals
# - Use bootstrap for robust estimation
#
# Cross-Validation:
# - Use stratified k-fold CV (k=5 or k=10)
# - Use nested CV for hyperparameter search
# - Report mean and standard deviation
#
# Multiple Seeds:
# - Run experiments with at least 3-5 random seeds
# - Report mean, std, min, max across seeds
# - Use different seeds for train/val/test splits
#
# ============================================================================
# Experiment Tracking Best Practices
# ============================================================================
#
# What to Log:
# - Hyperparameters (all config values)
# - Metrics (train/val/test accuracy, F1, loss)
# - System info (GPU, CPU, RAM, PyTorch version)
# - Dataset info (size, splits, preprocessing)
# - Model info (architecture, parameters, FLOPs)
# - Training time (wall time, GPU hours)
# - Memory usage (peak GPU/RAM)
# - Overfitting metrics (train-val gap)
# - Parameter efficiency (trainable params %)
#
# Naming Conventions:
# - Experiment: project_model_date_seed
# - Run: config_hyperparam_value
# - Tags: model_type, dataset, technique
#
# Checkpointing:
# - Save best model (highest val accuracy)
# - Save final model (end of training)
# - Save optimizer state for resuming
# - Save training history
#
# Artifacts:
# - Model weights
# - Configuration files
# - Predictions (train/val/test)
# - Attention visualizations
# - Error analysis reports
#
# For detailed research guidelines:
# - See docs/level_3_advanced/03_research_workflow.md
# - See experiments/README.md
# - See SOTA_MODELS_GUIDE.md
#
# ============================================================================
