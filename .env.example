# ============================================================================
# Environment Variables Template for AG News Text Classification
# ============================================================================
# Project: AG News Text Classification (ag-news-text-classification)
# Description: Template for environment-specific configuration variables
# Author: Võ Hải Dũng
# Email: vohaidung.work@gmail.com
# License: MIT
# ============================================================================
#
# Academic Rationale:
#   Following the Twelve-Factor App methodology (https://12factor.net/config),
#   this file separates configuration from code, enabling:
#   - Environment-specific deployments without code changes
#   - Secure credential management through environment variables
#   - Reproducible experiments through documented configuration
#   - Platform portability (local, Colab, Kaggle, cloud)
#
# Usage Instructions:
#   1. Copy this file to .env for local development:
#      cp .env.example .env
#   
#   2. Fill in your specific values (API keys, paths, settings)
#   
#   3. Never commit .env to version control (already in .gitignore)
#   
#   4. For production, use secure secret management:
#      - Docker secrets
#      - Kubernetes secrets
#      - Cloud provider secret managers (AWS Secrets Manager, GCP Secret Manager)
#   
#   5. Load in Python:
#      from dotenv import load_dotenv
#      load_dotenv()
#      import os
#      project_name = os.getenv("PROJECT_NAME")
#
# Security Guidelines:
#   - Replace all placeholder values with actual credentials
#   - Use strong, unique API keys and secrets
#   - Rotate credentials regularly
#   - Never share .env files containing real credentials
#   - Use different credentials for development, testing, production
#
# Validation:
#   python -c "from dotenv import dotenv_values; print(dotenv_values('.env'))"
#
# References:
#   - Twelve-Factor App: https://12factor.net/
#   - python-dotenv: https://github.com/theskumar/python-dotenv
#   - OWASP Configuration Guide: https://cheatsheetseries.owasp.org/
#
# ============================================================================

# ============================================================================
# Project Metadata
# ============================================================================
# Core project identification and versioning information.

PROJECT_NAME="AG News Text Classification"
PROJECT_SLUG="ag-news-text-classification"
PROJECT_VERSION="1.0.0"
PROJECT_DESCRIPTION="State-of-the-art text classification with overfitting prevention"
PROJECT_URL="https://github.com/VoHaiDung/ag-news-text-classification"

# ============================================================================
# Environment Configuration
# ============================================================================
# Deployment environment specification (development, staging, production).

ENVIRONMENT="development"
DEBUG=true
VERBOSE=false
LOG_LEVEL="INFO"

# ============================================================================
# Directory Structure
# ============================================================================
# Paths to project directories following the established structure.
# Using relative paths for portability across environments.

ROOT_DIR="."
SRC_DIR="./src"
DATA_DIR="./data"
CONFIG_DIR="./configs"
SCRIPTS_DIR="./scripts"
TOOLS_DIR="./tools"
NOTEBOOKS_DIR="./notebooks"
DOCS_DIR="./docs"

# Data subdirectories
DATA_RAW_DIR="./data/raw"
DATA_PROCESSED_DIR="./data/processed"
DATA_AUGMENTED_DIR="./data/augmented"
DATA_EXTERNAL_DIR="./data/external"
DATA_CACHE_DIR="./data/cache"
DATA_PLATFORM_CACHE_DIR="./data/platform_cache"
DATA_QUOTA_TRACKING_DIR="./data/quota_tracking"

# Output directories
OUTPUT_DIR="./outputs"
MODEL_DIR="./outputs/models"
CHECKPOINT_DIR="./outputs/models/checkpoints"
RESULTS_DIR="./outputs/results"
LOG_DIR="./outputs/logs"
ANALYSIS_DIR="./outputs/analysis"
ARTIFACTS_DIR="./outputs/artifacts"

# Model subdirectories
PRETRAINED_DIR="./outputs/models/pretrained"
FINETUNED_DIR="./outputs/models/fine_tuned"
LORA_DIR="./outputs/models/lora_adapters"
QLORA_DIR="./outputs/models/qlora_adapters"
ENSEMBLE_DIR="./outputs/models/ensembles"
DISTILLED_DIR="./outputs/models/distilled"
OPTIMIZED_DIR="./outputs/models/optimized"
EXPORTED_DIR="./outputs/models/exported"

# Logging subdirectories
LOG_TRAINING_DIR="./outputs/logs/training"
LOG_TENSORBOARD_DIR="./outputs/logs/tensorboard"
LOG_MLFLOW_DIR="./outputs/logs/mlflow"
LOG_WANDB_DIR="./outputs/logs/wandb"

# Cache directories
CACHE_DIR="./.cache"
TEMP_DIR="./tmp"
HF_CACHE_DIR="./.cache/huggingface"
TRANSFORMERS_CACHE_DIR="./.cache/transformers"
DATASETS_CACHE_DIR="./.cache/datasets"

# ============================================================================
# Model Configuration
# ============================================================================
# Default model architecture and hyperparameters.

# Transformer Model Settings
DEFAULT_MODEL="microsoft/deberta-v3-base"
TRANSFORMER_MODEL_TYPE="deberta"
TRANSFORMER_MODEL_NAME="microsoft/deberta-v3-base"
TRANSFORMER_NUM_LABELS=4

# Alternative model options (uncomment to use)
# DEFAULT_MODEL="roberta-large"
# DEFAULT_MODEL="microsoft/deberta-v3-large"
# DEFAULT_MODEL="google/electra-large-discriminator"
# DEFAULT_MODEL="xlnet-large-cased"

# LLM Settings (for advanced experiments)
LLM_MODEL_TYPE="llama2"
LLM_MODEL_NAME="meta-llama/Llama-2-7b-hf"
LLM_USE_4BIT=true
LLM_USE_8BIT=false

# Sequence Processing
MAX_SEQUENCE_LENGTH=512
MAX_TOKEN_LENGTH=512
PADDING_STRATEGY="max_length"
TRUNCATION_STRATEGY="longest_first"
RETURN_ATTENTION_MASK=true
RETURN_TOKEN_TYPE_IDS=false

# Model Architecture
NUM_LABELS=4
HIDDEN_DROPOUT_PROB=0.1
ATTENTION_DROPOUT_PROB=0.1
CLASSIFIER_DROPOUT=0.1

# ============================================================================
# Training Configuration
# ============================================================================
# Hyperparameters for model training following best practices.

# Batch Sizes
BATCH_SIZE=16
TRAIN_BATCH_SIZE=16
EVAL_BATCH_SIZE=32
GRADIENT_ACCUMULATION_STEPS=2
EFFECTIVE_BATCH_SIZE=32

# Training Duration
NUM_TRAIN_EPOCHS=5
MAX_STEPS=-1
WARMUP_STEPS=500
WARMUP_RATIO=0.1

# Optimization
LEARNING_RATE=2e-5
WEIGHT_DECAY=0.01
ADAM_BETA1=0.9
ADAM_BETA2=0.999
ADAM_EPSILON=1e-8
MAX_GRAD_NORM=1.0

# Learning Rate Scheduling
LR_SCHEDULER_TYPE="cosine"
SCHEDULER_WARMUP_STEPS=500
SCHEDULER_NUM_CYCLES=0.5

# Regularization
DROPOUT_RATE=0.1
LAYER_NORM_EPS=1e-7
INITIALIZER_RANGE=0.02

# Evaluation and Checkpointing
EVAL_STRATEGY="epoch"
EVAL_STEPS=500
SAVE_STRATEGY="epoch"
SAVE_STEPS=500
SAVE_TOTAL_LIMIT=3
LOAD_BEST_MODEL_AT_END=true
METRIC_FOR_BEST_MODEL="eval_accuracy"
GREATER_IS_BETTER=true

# Logging
LOGGING_STRATEGY="steps"
LOGGING_STEPS=100
LOGGING_FIRST_STEP=true
REPORT_TO="tensorboard,wandb"

# ============================================================================
# Data Configuration
# ============================================================================
# Dataset loading and preprocessing settings.

# Dataset Selection
DATASET_NAME="ag_news"
DATASET_SPLIT_TRAIN="train"
DATASET_SPLIT_TEST="test"
DATASET_CONFIG_NAME=""

# Data Sampling (for quick experiments)
USE_SAMPLE_DATA=false
SAMPLE_SIZE=1000
TRAIN_SAMPLE_SIZE=800
VAL_SAMPLE_SIZE=100
TEST_SAMPLE_SIZE=100

# Data Splitting
TRAIN_RATIO=0.8
VAL_RATIO=0.1
TEST_RATIO=0.1
STRATIFIED_SPLIT=true

# Data Loading
NUM_WORKERS=4
PREFETCH_FACTOR=2
PIN_MEMORY=true
PERSISTENT_WORKERS=true

# Preprocessing
LOWERCASE=false
REMOVE_PUNCTUATION=false
REMOVE_STOPWORDS=false
LEMMATIZATION=false

# Data Augmentation
DATA_AUGMENTATION_ENABLED=false
AUGMENTATION_PROBABILITY=0.1
BACK_TRANSLATION_ENABLED=false
PARAPHRASE_ENABLED=false
SYNONYM_REPLACEMENT_ENABLED=false

# Data Validation
DATA_VALIDATION_ENABLED=true
CHECK_DUPLICATES=true
CHECK_MISSING_VALUES=true
CHECK_LABEL_DISTRIBUTION=true

# ============================================================================
# Overfitting Prevention System
# ============================================================================
# Configuration for the comprehensive anti-overfitting framework.

# Enable Overfitting Prevention
OVERFITTING_PREVENTION_ENABLED=true
OVERFITTING_MONITOR_ENABLED=true
OVERFITTING_THRESHOLD=0.15
OVERFITTING_PATIENCE=3

# Early Stopping
EARLY_STOPPING_ENABLED=true
EARLY_STOPPING_PATIENCE=3
EARLY_STOPPING_THRESHOLD=0.001
EARLY_STOPPING_MIN_DELTA=0.0001

# Validation Guards
VALIDATION_GUARD_ENABLED=true
TEST_SET_GUARD_ENABLED=true
TEST_SET_PROTECTION=true
TEST_SET_HASH_VERIFICATION=true

# Complexity Monitoring
COMPLEXITY_MONITOR_ENABLED=true
PARAMETER_EFFICIENCY_CHECK=true
MODEL_SIZE_LIMIT_MB=5000

# Constraints
MAX_MODEL_PARAMETERS=1000000000
MAX_TRAINABLE_PARAMETERS=100000000
LORA_RANK_LIMIT=64
QLORA_BITS_LIMIT=4

# Regularization Enforcement
DROPOUT_REQUIRED=true
WEIGHT_DECAY_REQUIRED=true
MIN_DROPOUT_RATE=0.1
MIN_WEIGHT_DECAY=0.001

# ============================================================================
# Efficient Fine-Tuning Methods
# ============================================================================
# Parameter-efficient fine-tuning configurations.

# LoRA Configuration
LORA_ENABLED=false
LORA_R=16
LORA_ALPHA=32
LORA_DROPOUT=0.1
LORA_TARGET_MODULES="q_proj,v_proj,k_proj,o_proj"
LORA_BIAS="none"
LORA_TASK_TYPE="CAUSAL_LM"
LORA_INFERENCE_MODE=false

# QLoRA Configuration
QLORA_ENABLED=false
QLORA_BITS=4
QLORA_USE_4BIT=true
QLORA_USE_8BIT=false
QLORA_COMPUTE_DTYPE="float16"
QLORA_QUANT_TYPE="nf4"
QLORA_USE_DOUBLE_QUANT=true

# Adapter Configuration
ADAPTER_ENABLED=false
ADAPTER_TYPE="houlsby"
ADAPTER_SIZE=64
ADAPTER_DROPOUT=0.1

# Prefix Tuning
PREFIX_TUNING_ENABLED=false
PREFIX_LENGTH=20
PREFIX_DROPOUT=0.1

# Prompt Tuning
PROMPT_TUNING_ENABLED=false
NUM_VIRTUAL_TOKENS=20
PROMPT_TUNING_INIT="random"

# ============================================================================
# Ensemble Configuration
# ============================================================================
# Settings for ensemble model training and inference.

ENSEMBLE_ENABLED=false
ENSEMBLE_SIZE=3
ENSEMBLE_METHOD="soft_voting"
ENSEMBLE_WEIGHTS="uniform"
ENSEMBLE_MODELS="deberta-v3-base,roberta-large,electra-large"

# Ensemble Advanced Settings
ENSEMBLE_DIVERSITY_WEIGHT=0.3
ENSEMBLE_PRUNING_ENABLED=false
ENSEMBLE_OPTIMIZATION="bayesian"

# ============================================================================
# Knowledge Distillation Configuration
# ============================================================================
# Teacher-student framework for model compression.

DISTILLATION_ENABLED=false
DISTILLATION_TEMPERATURE=3.0
DISTILLATION_ALPHA=0.5
DISTILLATION_BETA=0.5

# Teacher Model
TEACHER_MODEL_NAME="meta-llama/Llama-2-13b-hf"
TEACHER_MODEL_PATH=""
TEACHER_CHECKPOINT=""

# Student Model
STUDENT_MODEL_NAME="microsoft/deberta-v3-base"
STUDENT_MODEL_PATH=""

# Distillation Methods
FEATURE_DISTILLATION=false
ATTENTION_DISTILLATION=false
HIDDEN_DISTILLATION=false

# ============================================================================
# Platform-Specific Settings
# ============================================================================
# Automatic platform detection and optimization.

# Platform Detection
PLATFORM="auto"
PLATFORM_AUTO_DETECT=true
PLATFORM_OPTIMIZATION_ENABLED=true

# Colab Settings
COLAB_DETECTION=true
COLAB_PRO=false
COLAB_GPU_TYPE="T4"
COLAB_MOUNT_DRIVE=false

# Kaggle Settings
KAGGLE_DETECTION=true
KAGGLE_GPU_ENABLED=true
KAGGLE_TPU_ENABLED=false

# Local Settings
LOCAL_GPU_ENABLED=true
LOCAL_GPU_COUNT=1
LOCAL_CPU_COUNT=8

# Quota Management
QUOTA_TRACKING_ENABLED=true
QUOTA_LIMIT_ENFORCEMENT=true
QUOTA_WARNING_THRESHOLD=0.8
SESSION_TIMEOUT_HOURS=12

# ============================================================================
# Hardware Configuration
# ============================================================================
# Device and compute settings.

# Device Selection
DEVICE="cuda"
CUDA_VISIBLE_DEVICES="0"
USE_GPU=true
USE_CPU=false
USE_TPU=false

# Multi-GPU Training
NUM_GPUS=1
DISTRIBUTED_TRAINING=false
DISTRIBUTED_BACKEND="nccl"
LOCAL_RANK=-1

# Mixed Precision
MIXED_PRECISION=true
FP16=true
BF16=false
FP16_OPT_LEVEL="O1"
FP16_BACKEND="auto"

# Memory Optimization
GRADIENT_CHECKPOINTING=false
GRADIENT_CHECKPOINTING_KWARGS="{}"
OPTIM_MEMORY_EFFICIENT=true
MAX_MEMORY_MB=16000

# ============================================================================
# Experiment Tracking
# ============================================================================
# Integration with experiment tracking platforms.

# Weights & Biases
WANDB_ENABLED=false
WANDB_PROJECT="ag-news-text-classification"
WANDB_ENTITY=""
WANDB_API_KEY=""
WANDB_MODE="online"
WANDB_DIR="./outputs/logs/wandb"
WANDB_SILENT=false
WANDB_TAGS="experiment,text-classification"

# MLflow
MLFLOW_ENABLED=false
MLFLOW_TRACKING_URI="file:./outputs/logs/mlflow"
MLFLOW_EXPERIMENT_NAME="ag-news-classification"
MLFLOW_ARTIFACT_LOCATION=""
MLFLOW_REGISTRY_URI=""

# TensorBoard
TENSORBOARD_ENABLED=true
TENSORBOARD_LOG_DIR="./outputs/logs/tensorboard"

# Neptune
NEPTUNE_ENABLED=false
NEPTUNE_PROJECT=""
NEPTUNE_API_TOKEN=""

# Comet
COMET_ENABLED=false
COMET_API_KEY=""
COMET_PROJECT_NAME=""

# ============================================================================
# Hugging Face Integration
# ============================================================================
# Hugging Face Hub authentication and caching.

HF_TOKEN=""
HF_HUB_CACHE_DIR="./.cache/huggingface/hub"
HF_DATASETS_CACHE="./.cache/huggingface/datasets"
HF_METRICS_CACHE="./.cache/huggingface/metrics"
HF_MODULES_CACHE="./.cache/huggingface/modules"

# Hugging Face Model Hub
HF_MODEL_UPLOAD=false
HF_MODEL_REPO=""
HF_PUSH_TO_HUB=false
HF_HUB_MODEL_ID=""

# Offline Mode
HF_DATASETS_OFFLINE=false
TRANSFORMERS_OFFLINE=false

# ============================================================================
# External API Keys
# ============================================================================
# API keys for external services (leave empty if not using).

# OpenAI
OPENAI_API_KEY=""
OPENAI_ORGANIZATION=""
OPENAI_MODEL="gpt-3.5-turbo"
OPENAI_MAX_TOKENS=2048

# Anthropic
ANTHROPIC_API_KEY=""
ANTHROPIC_MODEL="claude-2"

# Cohere
COHERE_API_KEY=""
COHERE_MODEL="command"

# Google Cloud
GOOGLE_APPLICATION_CREDENTIALS=""
GOOGLE_PROJECT_ID=""

# AWS
AWS_ACCESS_KEY_ID=""
AWS_SECRET_ACCESS_KEY=""
AWS_DEFAULT_REGION="us-east-1"

# Azure
AZURE_OPENAI_API_KEY=""
AZURE_OPENAI_ENDPOINT=""

# ============================================================================
# Database Configuration
# ============================================================================
# Database connection for experiment metadata and results.

DATABASE_BACKEND="sqlite"
DATABASE_URL="sqlite:///./ag_news.db"
DATABASE_POOL_SIZE=10
DATABASE_MAX_OVERFLOW=20
DATABASE_ECHO=false
DATABASE_AUTO_MIGRATE=true

# PostgreSQL (alternative)
# DATABASE_BACKEND="postgresql"
# DATABASE_URL="postgresql://user:password@localhost:5432/ag_news"

# MySQL (alternative)
# DATABASE_BACKEND="mysql"
# DATABASE_URL="mysql://user:password@localhost:3306/ag_news"

# ============================================================================
# Cache Configuration
# ============================================================================
# Caching layer for improved performance.

CACHE_BACKEND="redis"
CACHE_ENABLED=true
CACHE_TTL=3600
CACHE_MAX_SIZE=1000

# Redis
REDIS_URL="redis://localhost:6379/0"
REDIS_HOST="localhost"
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=""
REDIS_PREFIX="ag_news"

# In-Memory Cache (alternative)
# CACHE_BACKEND="memory"
# CACHE_TYPE="simple"

# ============================================================================
# API Configuration
# ============================================================================
# REST API server settings.

API_ENABLED=true
API_HOST="0.0.0.0"
API_PORT=8000
API_WORKERS=4
API_RELOAD=false
API_DEBUG=false

# API Documentation
API_TITLE="AG News Text Classification API"
API_VERSION="1.0.0"
API_DESCRIPTION="State-of-the-art text classification API"
API_DOCS_URL="/docs"
API_REDOC_URL="/redoc"
API_OPENAPI_URL="/openapi.json"

# API Security
API_KEY=""
API_RATE_LIMIT=100
API_RATE_LIMIT_PERIOD=60
API_TIMEOUT=30

# CORS
API_CORS_ENABLED=true
API_CORS_ORIGINS="http://localhost:3000,http://localhost:8080"
API_CORS_METHODS="GET,POST,PUT,DELETE"
API_CORS_HEADERS="*"

# ============================================================================
# Security Configuration
# ============================================================================
# Security and authentication settings.

# Secret Keys (generate strong random values)
SECRET_KEY="change-me-to-a-strong-random-secret-key"
JWT_SECRET="change-me-to-a-strong-jwt-secret"
JWT_ALGORITHM="HS256"
JWT_EXPIRATION_MINUTES=60
JWT_REFRESH_EXPIRATION_DAYS=7

# Access Control
ALLOWED_HOSTS="localhost,127.0.0.1"
CORS_ALLOWED_ORIGINS="http://localhost:3000"
ALLOWED_METHODS="GET,POST,PUT,DELETE,OPTIONS"

# Encryption
HASH_ALGORITHM="bcrypt"
SALT_ROUNDS=12
PASSWORD_MIN_LENGTH=8

# ============================================================================
# Monitoring and Alerting
# ============================================================================
# System monitoring and alerting configuration.

# Prometheus
PROMETHEUS_ENABLED=false
PROMETHEUS_PORT=9090
PROMETHEUS_METRICS_PATH="/metrics"

# Grafana
GRAFANA_ENABLED=false
GRAFANA_PORT=3000
GRAFANA_ADMIN_PASSWORD=""

# Alerts
ALERT_ENABLED=false
ALERT_EMAIL=""
ALERT_SLACK_WEBHOOK=""
ALERT_THRESHOLD_ERROR_RATE=0.05

# ============================================================================
# Logging Configuration
# ============================================================================
# Comprehensive logging settings.

LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
LOG_DATE_FORMAT="%Y-%m-%d %H:%M:%S"
LOG_FILE="./outputs/logs/ag_news.log"
LOG_MAX_BYTES=10485760
LOG_BACKUP_COUNT=5
LOG_ROTATION="time"
LOG_ROTATION_WHEN="midnight"
LOG_RETENTION_DAYS=30

# Log Levels
LOG_LEVEL_ROOT="INFO"
LOG_LEVEL_APP="INFO"
LOG_LEVEL_TRANSFORMERS="WARNING"
LOG_LEVEL_DATASETS="WARNING"
LOG_LEVEL_TORCH="WARNING"

# Log Destinations
LOG_TO_CONSOLE=true
LOG_TO_FILE=true
LOG_TO_SYSLOG=false
LOG_JSON_FORMAT=false

# ============================================================================
# Performance and Optimization
# ============================================================================
# Performance tuning and optimization settings.

# Threading
MAX_WORKERS=8
THREAD_POOL_SIZE=16
PROCESS_POOL_SIZE=4

# Connection Pooling
CONNECTION_POOL_SIZE=10
CONNECTION_MAX_OVERFLOW=20
CONNECTION_POOL_TIMEOUT=30

# Timeouts
REQUEST_TIMEOUT=30
CONNECT_TIMEOUT=10
READ_TIMEOUT=30

# Resource Limits
MAX_MEMORY_GB=16
MAX_CPU_PERCENT=80
MAX_DISK_USAGE_PERCENT=90

# ============================================================================
# Feature Flags
# ============================================================================
# Enable or disable specific features.

ENABLE_EXPERIMENTAL_FEATURES=false
ENABLE_PROMPT_ENGINEERING=true
ENABLE_INSTRUCTION_TUNING=false
ENABLE_CHAIN_OF_THOUGHT=false
ENABLE_FEW_SHOT_LEARNING=false

ENABLE_DATA_AUGMENTATION=false
ENABLE_ACTIVE_LEARNING=false
ENABLE_CURRICULUM_LEARNING=false
ENABLE_ADVERSARIAL_TRAINING=false
ENABLE_MULTI_TASK_LEARNING=false

ENABLE_MODEL_COMPRESSION=false
ENABLE_QUANTIZATION=false
ENABLE_PRUNING=false
ENABLE_KNOWLEDGE_DISTILLATION=false

# ============================================================================
# Reproducibility
# ============================================================================
# Settings for reproducible experiments.

RANDOM_SEED=42
NUMPY_SEED=42
TORCH_SEED=42
PYTHON_SEED=42
TRANSFORMERS_SEED=42

DETERMINISTIC_MODE=false
CUDNN_DETERMINISTIC=false
CUDNN_BENCHMARK=true

# ============================================================================
# Development and Debugging
# ============================================================================
# Development-specific settings.

DEV_MODE=true
AUTO_RELOAD=false
PROFILING_ENABLED=false
MEMORY_PROFILING=false
DEBUG_BREAKPOINTS=false

# Testing
RUN_TESTS_ON_START=false
SKIP_SLOW_TESTS=true
TEST_COVERAGE_THRESHOLD=80

# ============================================================================
# Deployment Configuration
# ============================================================================
# Production deployment settings.

DEPLOYMENT_MODE="local"
CONTAINER_RUNTIME="docker"
ORCHESTRATION_PLATFORM="kubernetes"

# Docker
DOCKER_IMAGE_NAME="ag-news-text-classification"
DOCKER_IMAGE_TAG="latest"
DOCKER_REGISTRY=""

# Kubernetes
K8S_NAMESPACE="default"
K8S_SERVICE_ACCOUNT=""
K8S_CONFIG_MAP=""

# Cloud Provider
CLOUD_PROVIDER="aws"
CLOUD_REGION="us-east-1"
CLOUD_ZONE=""

# ============================================================================
# Backup and Recovery
# ============================================================================
# Backup configuration for models and data.

BACKUP_ENABLED=true
BACKUP_FREQUENCY="daily"
BACKUP_RETENTION_DAYS=30
BACKUP_DESTINATION="./backup"
BACKUP_COMPRESS=true

# ============================================================================
# Custom Settings
# ============================================================================
# Project-specific custom configurations.

# Experiment Naming
EXPERIMENT_NAME="baseline"
EXPERIMENT_TAG="v1.0"
EXPERIMENT_DESCRIPTION="Baseline experiment with DeBERTa-v3-base"

# Model Naming
MODEL_NICKNAME="deberta-baseline"
MODEL_VERSION="1.0.0"

# Results
SAVE_PREDICTIONS=true
SAVE_ATTENTION_WEIGHTS=false
SAVE_EMBEDDINGS=false
SAVE_CONFUSION_MATRIX=true
SAVE_CLASSIFICATION_REPORT=true

# ============================================================================
# Notes
# ============================================================================
#
# Configuration Management:
#   - Keep sensitive values (API keys, passwords) in .env (gitignored)
#   - Use .env.example for documentation and templates
#   - Create environment-specific files: .env.dev, .env.staging, .env.prod
#   - Validate configuration before deployment
#
# Security Best Practices:
#   - Rotate API keys and secrets regularly
#   - Use strong, unique passwords for each environment
#   - Enable encryption for sensitive data
#   - Implement proper access controls
#   - Monitor for unauthorized access
#
# Platform-Specific Notes:
#   - Colab: Use mounted Google Drive for persistent storage
#   - Kaggle: Use Kaggle datasets for data management
#   - Local: Ensure adequate disk space and GPU memory
#   - Cloud: Use managed services for databases and caching
#
# Reproducibility Guidelines:
#   - Set all random seeds for deterministic results
#   - Document exact package versions in requirements/lock files
#   - Version control configuration files
#   - Track hyperparameters in experiment tracking tools
#
# Troubleshooting:
#   - Verify configuration: python -c "from dotenv import load_dotenv; load_dotenv(); import os; print(os.getenv('PROJECT_NAME'))"
#   - Check for missing variables: grep -v '^#' .env | grep -v '^$' | cut -d= -f1
#   - Validate paths: ensure all directories exist or create them
#   - Test API connections: curl http://localhost:8000/health
#
# ============================================================================
